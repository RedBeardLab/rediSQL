{
    "docs": [
        {
            "location": "/",
            "text": "RediSQL\n\n\nRediSQL\n is a Redis module that embeds a fully functional SQLite database.\n\n\nAt the best of our knowledge is the only system that provides SQL capabilities while being very fast so to be used as a cache, simple to integrate with any programming language, since it can be used by every redis client, and with very very low maintenance.\n\n\nMoreover, it can also be used as the main database, it can store data not only in memory but also on file and it can also use the same persistence mechanisms of redis itself.\n\n\nGet Started\n\n\nYou can download the module directly \nfrom github releases\n.\n\n\nYou can start the module with:\n\n\n./redis-server --loadmodule rediSQL_<version>.so\n\n\n\n\nAfter starting redis with the rediSQL module it will be just the redis you learn to love:\n\n\n$ ~/redis-4.0-rc1/src/redis-cli \n127.0.0.1:6379> \n127.0.0.1:6379> SET A 3\nOK\n127.0.0.1:6379> GET A\n\"3\"\n\n\n\n\nBut you will also able to use all the API described below:\n\n\n127.0.0.1:6379> REDISQL.CREATE_DB DB\nOK\n# Start creating a table on the default DB\n127.0.0.1:6379> REDISQL.EXEC DB \"CREATE TABLE foo(A INT, B TEXT);\"\nDONE\n# Insert some data into the table\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO foo VALUES(3, 'bar');\"\nOK\n# Retrieve the data you just inserted\n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT * FROM foo;\"\n1) 1) (integer) 3\n   2) \"bar\"\n# Of course you can make multiple tables\n127.0.0.1:6379> REDISQL.EXEC DB \"CREATE TABLE baz(C INT, B TEXT);\"\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO baz VALUES(3, 'aaa');\"\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO baz VALUES(3, 'bbb');\"\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO baz VALUES(3, 'ccc');\"\nOK\n# And of course you can use joins\n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT * FROM foo, baz WHERE foo.A = baz.C;\"\n\n1) 1) (integer) 3\n   2) \"bar\"\n   3) (integer) 3\n   4) \"aaa\"\n2) 1) (integer) 3\n   2) \"bar\"\n   3) (integer) 3\n   4) \"bbb\"\n3) 1) (integer) 3\n   2) \"bar\"\n   3) (integer) 3\n   4) \"ccc\"\n127.0.0.1:6379> \n\n\n\n\nAlso the \nLIKE\n operator is included:\n\n\n127.0.0.1:6379> REDISQL.EXEC DB \"CREATE TABLE text_search(t TEXT);\"\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO text_search VALUES('hello');\"\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO text_search VALUES('banana');\"\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO text_search VALUES('apple');\"\nOK\n127.0.0.1:6379> \n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT * FROM text_search WHERE t LIKE 'h_llo';\"\n1) 1) \"hello\"\n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT * FROM text_search WHERE t LIKE '%anana';\"\n1) 1) \"banana\"\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO text_search VALUES('anana');\"\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT * FROM text_search;\"\n1) 1) \"hello\"\n2) 1) \"banana\"\n3) 1) \"apple\"\n4) 1) \"anana\"\n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT * FROM text_search WHERE t LIKE 'a%';\"\n1) 1) \"apple\"\n2) 1) \"anana\"\n\n\n\n\nNow you can create tables, insert data on those tables, make queries, remove elements, everything.\n\n\nOverview\n\n\nIn this section, we are going to explore the main concepts in the module.\n\n\nThere is another section of the website, \nthe reference\n, that explore every single command that the module provides giving a deeper explanation of every detail.\n\n\nDatabases\n\n\nRediSQL provides the concept of database.\n\n\nIt is possible to create a new database with the command \nREDISQL.CREATE_DB\n.\n\n\nThe database is associated with a Redis key and so it is possible to have multiple SQL databases in a single Redis instance.\n\n\nAlso, it is possible to use in-memory database, which is the default, or databases backed by a real file. In-memory databases are generally a little faster but they are limited by the amount of memory your server has. Database backed by files are a little slower but they can grow basically indefinitely.\n\n\nExec\n\n\nREDISQL.EXEC\n is the command that let you execute command against a SQL database.\n\n\nIt is useful when you are testing the module or when you are changing the settings of the databases through SQLite \nPRAGMA\ns.\n\n\nHowever, I would not suggest to use them in production since there are better tools like \nStatements\n.\n\n\nStatements\n\n\nQueries and statements can be precompiled and stores inside the Redis key in order to provide a faster execution and more agility in your application.\n\n\nWhen you execute an SQLite query, the text is compiled to a binary code, this binary code is then executed against the database and the result provide an answer.\nThe phase of compilation can be quite expensive, but if you always execute the same statements (think about \ninserts\n), it can be avoided.\n\n\nWhen you use \nREDISQL.CREATE_STATEMENT\n your statement is compiled, then when you execute it using \nREDISQL.EXEC_STATEMENT\n it is not re-compiled but we use the pre-compiled one. It seems a trivial change but it will really speed up some workload.\n\n\nStatements can also be used as an interface for different applications using the same RediSQL instance.\n\n\nOnce you define the interface of the statement and its behaviour, then you are free to change it's implementation while maintaining all the legacy code working.\nThis is quite useful especially if you have several services using the same RediSQL instance.\n\n\nQuery\n\n\nIn most databases there are statements that modify the data and queries that simply read.\n\n\nOf course, just reading, is usually a faster and simpler operation than modify the data. In order to take advantages of this, we provide a different command \nREDISQL.QUERY\n and \nREDISQL.QUERY_STATEMENT\n that constraint you to don't modify the data.\n\n\nThese commands allow you to have slaves/replicas serves query and to balance some load off the master node for better speed and reliability.\n\n\nPersistency\n\n\nThe module in the community version implements only RDB. However, the PRO version provides also AOF and replication.\n\n\nRDB\n\n\nThe module implements RDB persistency.\n\n\nWhen Redis starts to save the RDB file the status of the database get serialized and written, along with all the other information, in the RDB file.\n\n\nAOF\n\n\nAOF replication is provided only in the PRO edition.\n\n\nAll the commands are replicated, but the read-only ones.\n\n\nWith AOF replication you also get instance replication that allows replicating the same dataset into different Redis instances in a master/slave fashion.\n\n\nObtain\n\n\nThere are \ntwo version\n of the software, a \"community\", completely open source version and a PRO version that comes with \nmore features and support plan.\n\n\nBoth versions can be \nobtained in the store.\n\n\nFor the community version, you can just download it, we ask for a small donation if you can support the project but feel free to just input 0\u20ac and download it.\n\n\nFor the PRO version you need to \nsign up here\n, after you signed up you will be able to download the software.\n\n\nA detailed coverage of the PRO version \nis provided here\n\n\nFinally you can also obtain the software from \ngithub releases\n\n\nMotivation\n\n\nThe main motivation behind the project is to provide a quick and hands-off environment to store structured data.\n\n\nIt also turns out that RediSQL is a great way to cache your content and data in a more structured way.\n\n\nThe main history and motivation of the project are explained \nin this page.\n\n\nPRO\n\n\nThe PRO edition is based on the Open Source one, however, it provides one more class of commands that are necessary for business or where rediSQL is a critical piece of the infrastructure.\n\n\nEvery command, but \nREDISQL.CREATE_DB\n, blocks the clients and it is executed in the background by a different thread.\n\n\nWith the PRO version, we also provide the \n.NOW\n commands that are executed immediately without blocking the client.\n\n\nEvery command in the PRO version provides the \n.NOW\n variant, but please refer to the \nreference\n.\n\n\nMoreover, the PRO version also provides AOF replication, that, indeed, necessitate of commands that don't block the clients.\n\n\nMore information about the PRO version are available \nhere.",
            "title": "Overview"
        },
        {
            "location": "/#redisql",
            "text": "RediSQL  is a Redis module that embeds a fully functional SQLite database.  At the best of our knowledge is the only system that provides SQL capabilities while being very fast so to be used as a cache, simple to integrate with any programming language, since it can be used by every redis client, and with very very low maintenance.  Moreover, it can also be used as the main database, it can store data not only in memory but also on file and it can also use the same persistence mechanisms of redis itself.",
            "title": "RediSQL"
        },
        {
            "location": "/#get-started",
            "text": "You can download the module directly  from github releases .  You can start the module with:  ./redis-server --loadmodule rediSQL_<version>.so  After starting redis with the rediSQL module it will be just the redis you learn to love:  $ ~/redis-4.0-rc1/src/redis-cli \n127.0.0.1:6379> \n127.0.0.1:6379> SET A 3\nOK\n127.0.0.1:6379> GET A\n\"3\"  But you will also able to use all the API described below:  127.0.0.1:6379> REDISQL.CREATE_DB DB\nOK\n# Start creating a table on the default DB\n127.0.0.1:6379> REDISQL.EXEC DB \"CREATE TABLE foo(A INT, B TEXT);\"\nDONE\n# Insert some data into the table\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO foo VALUES(3, 'bar');\"\nOK\n# Retrieve the data you just inserted\n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT * FROM foo;\"\n1) 1) (integer) 3\n   2) \"bar\"\n# Of course you can make multiple tables\n127.0.0.1:6379> REDISQL.EXEC DB \"CREATE TABLE baz(C INT, B TEXT);\"\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO baz VALUES(3, 'aaa');\"\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO baz VALUES(3, 'bbb');\"\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO baz VALUES(3, 'ccc');\"\nOK\n# And of course you can use joins\n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT * FROM foo, baz WHERE foo.A = baz.C;\"\n\n1) 1) (integer) 3\n   2) \"bar\"\n   3) (integer) 3\n   4) \"aaa\"\n2) 1) (integer) 3\n   2) \"bar\"\n   3) (integer) 3\n   4) \"bbb\"\n3) 1) (integer) 3\n   2) \"bar\"\n   3) (integer) 3\n   4) \"ccc\"\n127.0.0.1:6379>   Also the  LIKE  operator is included:  127.0.0.1:6379> REDISQL.EXEC DB \"CREATE TABLE text_search(t TEXT);\"\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO text_search VALUES('hello');\"\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO text_search VALUES('banana');\"\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO text_search VALUES('apple');\"\nOK\n127.0.0.1:6379> \n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT * FROM text_search WHERE t LIKE 'h_llo';\"\n1) 1) \"hello\"\n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT * FROM text_search WHERE t LIKE '%anana';\"\n1) 1) \"banana\"\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO text_search VALUES('anana');\"\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT * FROM text_search;\"\n1) 1) \"hello\"\n2) 1) \"banana\"\n3) 1) \"apple\"\n4) 1) \"anana\"\n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT * FROM text_search WHERE t LIKE 'a%';\"\n1) 1) \"apple\"\n2) 1) \"anana\"  Now you can create tables, insert data on those tables, make queries, remove elements, everything.",
            "title": "Get Started"
        },
        {
            "location": "/#overview",
            "text": "In this section, we are going to explore the main concepts in the module.  There is another section of the website,  the reference , that explore every single command that the module provides giving a deeper explanation of every detail.",
            "title": "Overview"
        },
        {
            "location": "/#databases",
            "text": "RediSQL provides the concept of database.  It is possible to create a new database with the command  REDISQL.CREATE_DB .  The database is associated with a Redis key and so it is possible to have multiple SQL databases in a single Redis instance.  Also, it is possible to use in-memory database, which is the default, or databases backed by a real file. In-memory databases are generally a little faster but they are limited by the amount of memory your server has. Database backed by files are a little slower but they can grow basically indefinitely.",
            "title": "Databases"
        },
        {
            "location": "/#exec",
            "text": "REDISQL.EXEC  is the command that let you execute command against a SQL database.  It is useful when you are testing the module or when you are changing the settings of the databases through SQLite  PRAGMA s.  However, I would not suggest to use them in production since there are better tools like  Statements .",
            "title": "Exec"
        },
        {
            "location": "/#statements",
            "text": "Queries and statements can be precompiled and stores inside the Redis key in order to provide a faster execution and more agility in your application.  When you execute an SQLite query, the text is compiled to a binary code, this binary code is then executed against the database and the result provide an answer.\nThe phase of compilation can be quite expensive, but if you always execute the same statements (think about  inserts ), it can be avoided.  When you use  REDISQL.CREATE_STATEMENT  your statement is compiled, then when you execute it using  REDISQL.EXEC_STATEMENT  it is not re-compiled but we use the pre-compiled one. It seems a trivial change but it will really speed up some workload.  Statements can also be used as an interface for different applications using the same RediSQL instance.  Once you define the interface of the statement and its behaviour, then you are free to change it's implementation while maintaining all the legacy code working.\nThis is quite useful especially if you have several services using the same RediSQL instance.",
            "title": "Statements"
        },
        {
            "location": "/#query",
            "text": "In most databases there are statements that modify the data and queries that simply read.  Of course, just reading, is usually a faster and simpler operation than modify the data. In order to take advantages of this, we provide a different command  REDISQL.QUERY  and  REDISQL.QUERY_STATEMENT  that constraint you to don't modify the data.  These commands allow you to have slaves/replicas serves query and to balance some load off the master node for better speed and reliability.",
            "title": "Query"
        },
        {
            "location": "/#persistency",
            "text": "The module in the community version implements only RDB. However, the PRO version provides also AOF and replication.",
            "title": "Persistency"
        },
        {
            "location": "/#rdb",
            "text": "The module implements RDB persistency.  When Redis starts to save the RDB file the status of the database get serialized and written, along with all the other information, in the RDB file.",
            "title": "RDB"
        },
        {
            "location": "/#aof",
            "text": "AOF replication is provided only in the PRO edition.  All the commands are replicated, but the read-only ones.  With AOF replication you also get instance replication that allows replicating the same dataset into different Redis instances in a master/slave fashion.",
            "title": "AOF"
        },
        {
            "location": "/#obtain",
            "text": "There are  two version  of the software, a \"community\", completely open source version and a PRO version that comes with  more features and support plan.  Both versions can be  obtained in the store.  For the community version, you can just download it, we ask for a small donation if you can support the project but feel free to just input 0\u20ac and download it.  For the PRO version you need to  sign up here , after you signed up you will be able to download the software.  A detailed coverage of the PRO version  is provided here  Finally you can also obtain the software from  github releases",
            "title": "Obtain"
        },
        {
            "location": "/#motivation",
            "text": "The main motivation behind the project is to provide a quick and hands-off environment to store structured data.  It also turns out that RediSQL is a great way to cache your content and data in a more structured way.  The main history and motivation of the project are explained  in this page.",
            "title": "Motivation"
        },
        {
            "location": "/#pro",
            "text": "The PRO edition is based on the Open Source one, however, it provides one more class of commands that are necessary for business or where rediSQL is a critical piece of the infrastructure.  Every command, but  REDISQL.CREATE_DB , blocks the clients and it is executed in the background by a different thread.  With the PRO version, we also provide the  .NOW  commands that are executed immediately without blocking the client.  Every command in the PRO version provides the  .NOW  variant, but please refer to the  reference .  Moreover, the PRO version also provides AOF replication, that, indeed, necessitate of commands that don't block the clients.  More information about the PRO version are available  here.",
            "title": "PRO"
        },
        {
            "location": "/references/",
            "text": "References\n\n\nThis document explains all the API that RediSQL provide to the users.\n\n\nFor each command, it exposes first the name and then the syntax and finally a brief explanation of what is going on inside the code.\n\n\nWhere is possible, it provides also an estimate of the complexity but since we are talking about databases not all queries have the same time and spatial complexity.\n\n\nFinally, if it is appropriate the document also provides several references to external material that the interested reader can use to understand better the dynamics of every and each command.\n\n\nREDISQL.CREATE_DB\n\n\nREDISQL.CREATE_DB db_key [path]\n\n\nThis command creates a new DB and associates it with the key.\n\n\nThe path argument is optional and, if provided is the file that SQLite will use.\nIt can be an existing SQLite file or it can be a not existing file.\n\n\nIf the file actually exists and if it is a regular SQLite file that database will be used.\nIf the file does not exist a new file will be created.\n\n\nIf the path is not provided it will open an in-memory database. Not providing a path is equivalent to provide the special string \n:memory:\n as path argument.\n\n\nAfter opening the database it inserts metadata into it and then starts a thread loop.\n\n\nComplexity\n: O(1), it means constant, it does not necessarily mean \nfast\n. However is fast enough for any use case facing human users (eg create a new database for every user logging in a website.)\n\n\nSee also\n: \n\n\n\n\nSQLite \nsqlite3_open_v2\n\n\n\n\nDEL\n\n\nDEL db_key [key ...]\n\n\nThis command is a generic command from Redis.\n\n\nIt eliminates keys from Redis itself, as well if the key is a RediSQL database create with \nREDISQL.CREATE_DB\n it will eliminate the SQLite database, stop the thread loop and clean up everything left.\n\n\nIf the database is backed by a file the file will be close.\n\n\nComplexity\n: DEL is O(N) on the number of keys, if you are only eliminating the key associated with the SQLite database will be constant, O(1).\n\n\nSee also\n: \n\n\n\n\nSQLite \nsqlite3_close\n\n\nRedis \nDEL\n\n\n\n\nREDISQL.EXEC\n\n\nREDISQL.EXEC[.NOW] db_key \"statement\"\n\n\nThis command takes as input a Redis key created with \nREDISQL.CREATE_DB\n and a statement string.\n\n\nInternally it transform the string into a \nsqlite statement\n using \nsqlite3_prepare_v2\n, execute it against the database, \nsqlite3_step\n, and finally returns the results to the client.\n\n\nThe compilation of the string into a statement and its execution happens in a different thread from the one used by Redis and so this command has a minimum impact on the overall Redis performance, however, it does block the client.\n\n\nThis command is quite useful to execute \nPRAGMA Statements\n, for normal operations against the database is suggested to use \nSTATEMENTS\n.\n\n\nAlso, remember that there is only a single thread for database, execution of multiple \nREDISQL.EXEC\n against the same database will result in a serialization of the executions, one will be executed before the others.\n\n\nIf you only need to query the database without modifying the data is a better idea to use \nREDISQL.QUERY\n.\n\n\nComplexity\n: It depends entirely on the statement string. The use of a single thread for database is been chosen after several tests where the single thread configuration was faster than a multi-thread one. This is true in a write-intensive application and in a mixed write/read application.\n\n\nSee also\n:\n\n\n\n\nSQLite \nsqlite3_prepare_v2\n\n\nSQLite \nstatement\n aka \nsqlite3_stmt\n\n\nSQLite \nsqlite3_step\n\n\nSQLite \nPRAGMA\ns\n\n\nRedis Blocking Command\n\n\n\n\nREDISQL.QUERY\n\n\nREDISQL.QUERY[.NOW] db_key \"statement\"\n\n\nThis command behaves similarly to \nREDISQL.EXEC\n but it imposes an additional constraint on the statement it executes.\n\n\nIt only executes the statement if it is a read-only operation, otherwise, it returns an error.\n\n\nA read-only operation is defined by the result of calling \nsqlite3_stmt_readonly\n on the compiled statement.\n\n\nThe statement is executed if and only if \nsqlite3_stmt_readonly\n returns true.\n\n\nIf you need to execute the same query over and over it is a good idea to create a statement and use \nREDISQL.QUERY_STATEMENT\n.\n\n\nComplexity\n: Similar to \nREDISQL.EXEC\n, however, if a statement is not read-only it is aborted immediately and it does return an appropriate error.\n\n\nSee also\n:\n\n\n\n\nSQLite \nsqlite3_prepare_v2\n\n\nSQLite \nstatement\n aka \nsqlite3_stmt\n\n\nSQLite \nsqlite3_step\n\n\nSQLite \nPRAGMA\ns\n\n\nRedis Blocking Command\n \n\n\nREDISQL.EXEC\n\n\nSQLite \nsqlite3_stmt_readonly\n\n\nREDISQL.QUERY_STATEMENT\n \n\n\n\n\nREDISQL.QUERY.INTO\n\n\nREDISQL.QUERY.INTO[.NOW] stream_name db_key \"query\"\n\n\nThis command is similar to \nREDISQL.QUERY\n but instead of returning the result of the query, it append each row to the \nstream\n \nstream_name\n passed as first argument. \n\n\nThe query must be a read-only one, exactly as \nREDISQL.QUERY\n.\n\n\nThe command executes \nXADD\n to the stream, hence if the stream does not exists a new one is created. On the other hand, if the stream already exists the rows are simply appended.\n\n\nThe command itself is eager, hence it compute the whole result, append it into the stream, and then it returns. Once the command returns, the whole result set is already in the Redis stream.\n\n\nThe return value of the command depends on the result of the query:\n\n\n\n\nIf the result of the query is empty, it simply returns \n[\"DONE\", 0]\n, exactly like \nREDISQL.QUERY\n.\n\n\nIf at least one row is returnend by the query the command returns the name of the stream where it appended the resulting rows, which is exactly the one passed as input, the first and the last ID added to the stream and the total number of entries added to the stream.\n\n\n\n\nThe stream will use autogeneratated IDs.\n\n\nEach entry in a stream is a set of field-value (key-value) pairs. The field (key) will be the type of the row and its name separated by a colon. It cpuld be something like \nint:users\n or \ntext:user_name\n or even \nreal:x_coordinate\n.\n\n\nThe value will simply store the value of the column untouched. \n\n\n127.0.0.1:6379> REDISQL.CREATE_DB DB\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"CREATE TABLE foo(a int, b int);\"\n1) DONE\n2) (integer) 0\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO foo(a) VALUES(1)\"\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO foo VALUES(3, 4)\"\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO foo VALUES(5, 6)\"\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO foo VALUES(10, 19)\"\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.QUERY.INTO {DB}:all_foo DB \"SELECT * FROM foo\"\n1) 1) \"{DB}:all_foo\"\n   2) \"1549811093979-0\"\n   3) \"1549811093979-3\"\n   4) (integer) 4\n127.0.0.1:6379> XRANGE {DB}:all_foo - +\n1) 1) \"1549811093979-0\"\n   2) 1) \"int:a\"\n      2) \"1\"\n      3) \"null:b\"\n      4) \"(null)\"\n2) 1) \"1549811093979-1\"\n   2) 1) \"int:a\"\n      2) \"3\"\n      3) \"int:b\"\n      4) \"4\"\n3) 1) \"1549811093979-2\"\n   2) 1) \"int:a\"\n      2) \"5\"\n      3) \"int:b\"\n      4) \"6\"\n4) 1) \"1549811093979-3\"\n   2) 1) \"int:a\"\n      2) \"10\"\n      3) \"int:b\"\n      4) \"19\"\n\n\n\n\nUsing a standard Redis Stream all the standard consideration applies.\n\n\n\n\nThe stream is not deleted by RediSQL, hence it can definitely be used for caching, on the other hand too many streams will use memory.\n\n\nThe stream use a standard Redis key, in a cluster environment you should be sure that the database that is executing the query and the stream that will accomodate the result are on the same cluster node. \nThis can be accomplished easily by forcing the stream name to hash to the same cluster node of the database, it is sufficiento to use a \nstream_name\n composed as such \n{db_key}:what:ever:here\n. Redis will hash only the part between the \n{\n and \n}\n in order to compute the cluster node.\n\n\nThe result can be consumed using the standard \nRedis streams commands\n, two good starting points are \nXREAD\n and \nXRANGE\n.\n\n\n\n\nComplexity\n: The complexity of the command is \nO(n)\n where \nn\n is the amount of row returned by the query.\n\n\nSee also\n:\n\n\n\n\nREDISQL.QUERY\n \n\n\nREDISQL.QUERY_STATEMENT.INTO\n \n\n\nRedis Streams Intro\n\n\nRedis Streams Commands\n\n\nXADD\n\n\nXREAD\n\n\nXRANGE\n\n\n\n\nREDISQL.CREATE_STATEMENT\n\n\nREDISQL.CREATE_STATEMENT[.NOW] db_key stmt_identifier \"statement\"\n\n\nThis command compiles a statement string into a \nsqlite statement\n and associate such statement to an identifier.\n\n\nUsing this command you can insert parameters using the special symbol \n?NNN\n, those parameters will be bind to the statements when you are executing the statement itself.\n\n\nFor now only the \n?NNN\n syntax is supported, where \nN\n is a digit (Ex. \n?1\n, \n?2\n, \n?3\n ...)\n\n\nThis command does not execute anything against the database, but simply store the sqlite statements into a dictionary associated with the identifier provided (\nstmt_identifier\n). Then it stores the information regarding the statement in the metadata table in order to provide a simple way to restore also the statements.\n\n\nThe statement is associated with a database, a statement created for one database cannot be used for another database, you need to create a different one. This allows a simple and fast way to provide persistence.\n\n\nYou can execute the statement with \nREDISQL.EXEC_STATEMENT\n.\n\n\nYou cannot overwrite a statement using this command.\n\n\nIf you need to change the implementation of a statement you have two options:\n\n\n\n\nDelete the statement using \nREDISQL.DELETE_STATEMENT\n and the create a new one.\n\n\nUse \nREDISQL.UPDATE_STATEMENT\n\n\n\n\nSuppose that a service needs a particular statement to be defined in order to work, this safety measure allows the users to simply go ahead, try to create it, and in case catch the error.\n\n\nAlso, this command is not blocking, meaning that all the work happens in a separate thread respect the redis one.\n\n\nPlease keep in mind that the parameters should be named in order and that there should not be any gap.\n\n\nINSERT INTO foo VALUES(?1, ?2, ?3); -- this one is fine and we work as you expect\n\nINSERT INTO foo VALUES(?1, ?123, ?564); -- this one will be more problematic, and you should avoid it\n\n\n\n\nKeep in mind that SQLite start to count the bounding parameters from 1 and not from 0, using \n?0\n is an error.\n\n\nComplexity\n: If we assume that the time necessary to compile a string into a sqlite statement is constant, overall the complexity is O(1), again constant, not necessarily \nfast\n.\n\n\nSee also\n:\n\n\n\n\nSQLite \nsqlite3_prepare_v2\n\n\nSQLite \nstatement\n aka \nsqlite3_stmt\n\n\nSQLite bindings, \nsqlite3_bind_text\n\n\nREDISQL.EXEC_STATEMENT\n\n\nREDISQL.DELETE_STATEMENT\n\n\nREDISQL.UPDATE_STATEMENT\n\n\nRedis Blocking Command\n\n\n\n\nREDISQL.EXEC_STATEMENT\n\n\nREDISQL.EXEC_STATEMENT[.NOW] db_key stmt_identifier [binding_parameters ...]\n\n\nThis command binds all the parameters to the statement created using \nREDISQL.CREATE_STATEMENT\n and identified by \nstmt_identifier\n. Then the module executes the statement against the database associated to \ndb_key\n.\n\n\nFor each parameter in the query of the form \n?nnn\n the engine will look for the \nnnn-th\n binding_parameters.\nSo if the statements is from the following query:\n\n\nINSERT INTO foo VALUES(?1, ?2, ?3);\n\n\n\n\nYou will only need to provide 3 parameters and they will be bound, in order to \n?1\n, \n?2\n and \n?3\n.\n\n\nIf your statements looks like this:\n\n\nINSERT INTO foo VALUES(?1, ?123, ?564);\n\n\n\n\nYou will need to provide 564 parameters and only the first, the 123-rd and the 564-th will be considered.\n\n\nSQLite starts to count the binding parameters from 0, not from 1. Using \n?0\n is an error.\n\n\nRedis works using a text protocol, all the arguments are encoded as text, hence the module is forced to use the procedure \nsqlite3_bind_text\n, however, SQLite is smart enough to recognize numbers and treat them correctly. Numbers will be treated as numbers and text will be treated as text.\n\n\nFinally, once completed the binding part the statement is executed and its result is returned to the client.\n\n\nThis command as well is not blocking, all the work happens in a different thread from the one of Redis.\n\n\nIf you need to query your database, without modifying the data is a better idea to use \nREDISQL.QUERY_STATEMENT\n.\n\n\nComplexity\n: The complexity to retrieve and to bind the parameters is roughly constant for any practical purpose, however, the overall complexity will be dominated by the time to execute the query.\n\n\nSee also\n:\n\n\n\n\nSQLite \nstatement\n aka \nsqlite3_stmt\n\n\nSQLite bindings, \nsqlite3_bind_text\n\n\nREDISQL.CREATE_STATEMENT\n\n\nRedis Blocking Command\n\n\nREDISQL.QUERY_STATEMENT\n \n\n\n\n\nREDISQL.QUERY_STATEMENT\n\n\nREDISQL.QUERY_STATEMENT[.NOW] db_key stmt_identifier [binding_parameters ...]\n\n\nThis command behaves similarly to \nREDISQL.EXEC_STATEMENT\n however it does impose an additional constraint.\n\n\nIt executes the statement if it is a read-only operation, otherwise, it returns an error.\n\n\nA read-only operation is defined by the result of calling \nsqlite3_stmt_readonly\n on the compiled statement.\n\n\nThe statement is executed if and only if \nsqlite3_stmt_readonly\n returns true.\n\n\nThe result of \nsqlite3_stmt_readonly\n is cached.\n\n\nIf you don't want to create a statement to run a query just once you can use \nREDISQL.QUERY\n.\n\n\nComplexity\n: Similar to \nREDISQL.EXEC_STATEMENT\n, however, if a statement is not read-only it is aborted immediately and it does return an appropriate error.\n\n\nSee also\n:\n\n\n\n\nSQLite \nsqlite3_prepare_v2\n\n\nSQLite \nstatement\n aka \nsqlite3_stmt\n\n\nSQLite \nsqlite3_step\n\n\nSQLite \nPRAGMA\ns\n\n\nRedis Blocking Command\n \n\n\nREDISQL.EXEC_STATEMENT\n\n\nSQLite \nsqlite3_stmt_readonly\n\n\nREDISQL.QUERY\n \n\n\n\n\nREDISQL.QUERY_STATEMENT.INTO\n\n\nREDISQL.QUERY_STATEMENT.INTO[.NOW] stream_name db_key stmt_identifier [binding_parameters ...]\n\n\nThis command behave like \nREDISQL.QUERY.INTO\n but instead of a query it takes as input a read-only statement and its binding paramenters.\n\n\nComplexity\n: The complexity of the command is \nO(n)\n where \nn\n is the amount of row returned by the query.\n\n\nSee also\n:\n\n\n\n\nREDISQL.QUERY.INTO\n \n\n\nREDISQL.QUERY_STATEMENT\n \n\n\nRedis Streams Intro\n\n\nRedis Streams Commands\n\n\nXADD\n\n\nXREAD\n\n\nXRANGE\n\n\n\n\nREDISQL.DELETE_STATEMENT\n\n\nREDISQL.DELETE_STATEMENT[.NOW] db_key stmt_identifier\n\n\nThis command eliminates a statement from the database.\n\n\nIt first looks it up into the internal hash table, if it finds the statement the command removes it from the internal hash table and then remove it from an internal SQLite table.\n\n\nAlso, this command is not blocking and work in a different thread from the main Redis one.\n\n\nComplexity\n: The complexity is constant and it can be considered \nfast\n for most practical application.\n\n\nSee also\n:\n\n\n\n\nSQLite \nstatement\n aka \nsqlite3_stmt\n\n\nREDISQL.CREATE_STATEMENT\n\n\nREDISQL.EXEC_STATEMENT\n\n\nREDISQL.UPDATE_STATEMENT\n\n\nRedis Blocking Command\n\n\n\n\nREDISQL.UPDATE_STATEMENT\n\n\nREDISQL.UPDATE_STATEMENT[.NOW] db_key stmt_identifier \"statement\"\n\n\nThe command update and \nexisting\n statement changing its internal implementation to the one provide as string.\n\n\nIf the statement does not exist the command will fail and return an error, again this is a safety measure, you must be completely aware that you are changing the implementation of a statement and updating a not existing statement or creating an existing one will result in an error.\n\n\nInternally the command starts checking if the statement is already defined, then it tries to compile the string into a \nsqlite3_stmt\n and if everything went right it finally updates the metadata table and finally returns to the client.\n\n\nThis command is not blocking as well.\n\n\nComplexity\n: The complexity is constant and it can be considered \nfast\n for most practical application.\n\n\nSee also\n:\n\n\n\n\nSQLite \nstatement\n aka \nsqlite3_stmt\n\n\nREDISQL.CREATE_STATEMENT\n\n\nREDISQL.EXEC_STATEMENT\n\n\nREDISQL.DELETE_STATEMENT\n\n\nRedis Blocking Command\n\n\n\n\nREDISQL.COPY\n\n\nREDISQL.COPY[.NOW] db_key_source db_key_destination\n\n\nThe command copies the source database into the destination database.\n\n\nThe content of the destination databases is completely ignored and lost.\n\n\nIt is not important if the databases are stored in memory or backed by disk, the \nCOPY\n command will work nevertheless.\n\n\nThis command is useful to:\n\n\n\n\nCreate backups of databases\n\n\nLoad data from a slow, disk based, databases into a fast in-memory one\n\n\nTo persist data from a in-memory database into a disk based database\n\n\nInitialize a database with a predefined status\n\n\n\n\nUsually the destination database is an empty database just created, while the source one is a databases where we have been working for a while.\n\n\nThis command use the \nbackup API\n of sqlite.\n\n\nComplexity\n: The complexity is linear on the number of page (dimension) of the source database, beware it can be \"slow\" if the source database is big, during the copy the \nsource\n database is busy and it cannot serve other queries. \n\n\nSee also\n:\n\n\n\n\nBackup API\n\n\n\n\nREDISQL.STATISTICS\n\n\nREDISQL.STATISTICS\n\n\nThe command print the internal statistics of RediSQL.\n\n\nThere are 3 counter associated to each command. \nThe first one for counting the number of times the command is been invoked.\nThe second (\nOK\n counter) keep tracks of how many times the command returned successfully.\nThe third (\nERR\n counter) memorize the amount of times the command returned an error. \n\n\nThe counters are implemented as atomic counters, they don't use locks nor introduces any notiaceble slowdown to the application.\n\n\n127.0.0.1:6379> REDISQL.STATISTICS\n 1) 1) \"CREATE_DB\"\n    2) (integer) 1\n 2) 1) \"CREATE_DB OK\"\n    2) (integer) 1\n 3) 1) \"CREATE_DB ERR\"\n    2) (integer) 0\n 4) 1) \"EXEC\"\n    2) (integer) 4\n 5) 1) \"EXEC OK\"\n    2) (integer) 4\n 6) 1) \"EXEC ERR\"\n    2) (integer) 0\n 7) 1) \"QUERY\"\n    2) (integer) 0\n 8) 1) \"QUERY OK\"\n    2) (integer) 0\n 9) 1) \"QUERY ERR\"\n    2) (integer) 0\n10) 1) \"QUERY.INTO\"\n    2) (integer) 0\n11) 1) \"QUERY.INTO OK\"\n    2) (integer) 0\n12) 1) \"QUERY.INTO ERR\"\n    2) (integer) 0\n13) 1) \"CREATE_STATEMENT\"\n    2) (integer) 3\n14) 1) \"CREATE_STATEMENT OK\"\n    2) (integer) 1\n15) 1) \"CREATE_STATEMENT ERR\"\n    2) (integer) 2\n16) 1) \"EXEC_STATEMENT\"\n    2) (integer) 2\n17) 1) \"EXEC_STATEMENT OK\"\n    2) (integer) 2\n18) 1) \"EXEC_STATEMENT ERR\"\n    2) (integer) 0\n19) 1) \"UPDATE_STATEMENT\"\n    2) (integer) 2\n20) 1) \"UPDATE_STATEMENT OK\"\n    2) (integer) 1\n21) 1) \"UPDATE_STATEMENT ERR\"\n    2) (integer) 1\n22) 1) \"DELETE_STATEMENT\"\n    2) (integer) 0\n23) 1) \"DELETE_STATEMENT OK\"\n    2) (integer) 0\n24) 1) \"DELETE_STATEMENT ERR\"\n    2) (integer) 0\n25) 1) \"QUERY_STATEMENT\"\n    2) (integer) 0\n26) 1) \"QUERY_STATEMENT OK\"\n    2) (integer) 0\n27) 1) \"QUERY_STATEMENT ERR\"\n    2) (integer) 0\n28) 1) \"QUERY_STATEMENT.INTO\"\n    2) (integer) 0\n29) 1) \"QUERY_STATEMENT.INTO OK\"\n    2) (integer) 0\n30) 1) \"QUERY_STATEMENT.INTO ERR\"\n    2) (integer) 0\n31) 1) \"COPY\"\n    2) (integer) 0\n32) 1) \"COPY OK\"\n    2) (integer) 0\n33) 1) \"COPY ERR\"\n    2) (integer) 0\n\n\n\n\nComplexity\n: The complexity is constant.\n\n\nREDISQL.COPY\n\n\nREDISQL.COPY[.NOW] db_key_source db_key_destination\n\n\nThe command copies the source database into the destination database.\n\n\nThe content of the destination databases is completely ignored and lost.\n\n\nIt is not important if the databases are stored in memory or backed by disk, the \nCOPY\n command will work nevertheless.\n\n\nThis command is useful to:\n\n\n\n\nCreate backups of databases\n\n\nLoad data from a slow, disk based, databases into a fast in-memory one\n\n\nTo persist data from a in-memory database into a disk based database\n\n\nInitialize a database with a predefined status\n\n\n\n\nUsually the destination database is an empty database just created, while the source one is a databases where we have been working for a while.\n\n\nThis command use the \nbackup API\n of sqlite.\n\n\nComplexity\n: The complexity is linear on the number of page (dimension) of the source database, beware it can be \"slow\" if the source database is big, during the copy the \nsource\n database is busy and it cannot serve other queries. \n\n\nSee also\n:\n\n\n\n\nBackup API\n\n\n\n\nVirtual Tables\n\n\nWhat follows is not a RediSQL command but an SQLite virtual table introduced by the module.\n\n\nVirtual tables behave similarly to normal tables but have some limitations, for a deeper explanation please visit the \nofficial SQLite documentation about virtual tables.\n\n\nAt the moment the module provides a single read-only virtual table: \nREDISQL_TABLES_BRUTE_HASH\n.\n\n\nREDISQL_TABLES_BRUTE_HASH\n\n\nThis virtual table allows you to query \nRedis Hashes\n that follow a similar pattern.\n\n\nA redis hash is composed by a key, that identifies the structure in the whole database, and several sub-keys that map to different string fields.\n\n\nThis structure can easily be mapped to a standard table, where the key identifies the row and the sub-keys the columns.\n\n\nRedis does not impose any limitation to the format of the hash key, however, in order to use the virtual table you need to follow a specific syntax that happens to be the de-facto standard for hash keys.\n\n\nThe key must be in the following format \n$tableName:$id\n where \n$id\n must be an integer. There are no limitations on the sub-keys.\n\n\n127.0.0.1:6379> HSET cats:1 name romeo location rome hungry 3\n(integer) 3\n127.0.0.1:6379> HSET cats:2 name garfield location london hungry 10\n(integer) 3\n127.0.0.1:6379> HSET cats:3 name \"simon's cat\" location \"simon's house\" hungry 8\n(integer) 3\n\n\n\n\nIn this examples we have a table of cats, each with a name, a location, and a hungry level.\n\n\nRedis is perfect if we want to know how hungry is \nromeo\n or where is located \ngarfield\n.\n\n\nHowever is a little more difficult to answer query like: who is the hungriest cat? Are there any cats in London? \n\n\nOf course, the use of different data structures could alleviate these issues but then there will be the necessity to keep the several data structures in sync one with the other.\n\n\nAnother alternative can be the use of the \nREDISQL_TABLE_BRUTE_HASH\n virtual table.\n\n\n127.0.0.1:6379> REDISQL.EXEC DB \"CREATE VIRTUAL TABLE funny_cats USING REDISQL_TABLES_BRUTE_HASH(cats, name, location, hungry);\"\n1) DONE\n2) (integer) 0\n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT * FROM funny_cats\"\n1) 1) \"cats:2\"\n   2) \"garfield\"\n   3) \"london\"\n   4) \"10\"\n2) 1) \"cats:1\"\n   2) \"romeo\"\n   3) \"rome\"\n   4) \"3\"\n3) 1) \"cats:3\"\n   2) \"simon's cat\"\n   3) \"simon's house\"\n   4) \"8\"\n\n\n\n\nThis virtual table allows querying the redis hashes using a more convenient SQL syntax. It does require a constant amount of space but it operates in linear time with the respect of the elements in the \"hash table\".\n\n\nThe syntax of the virtual table is quite simple, \nREDISQL_TABLES_BRUTE_HASH(cats, name, location, hungry)\n, as first we need the \n$tableName\n, so the key of every row without the \n:$id\n part. \nThen the columns of the table. Please note that you do \nnot\n provide the type of the column in the declaration.\n\n\nIs not necessary that every key defines all the columns (sub-keys), if a key does not have a specific sub-key, it will simply be returned as (nil).\n\n\nThis virtual table is a read-only virtual table, it means that -- at the moment -- you can only \nselect\n from this table, so you cannot \ninsert\n, \nupdate\n or \ndelete\n from this table.\n\n\nAnother limitation is that Redis Hashes can store only strings, not integers or floats. This implies that by default we will return only strings when you query a table, of course, you could cast them to integers or float via SQLite.\n\n\n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT name, location, CAST(hungry AS INTEGER) FROM cats\"\n1) 1) \"garfield\"\n   2) \"london\"\n   3) (integer) 10\n2) 1) \"romeo\"\n   2) \"rome\"\n   3) (integer) 3\n3) 1) \"simon's cat\"\n   2) \"simon's house\"\n   3) (integer) 8\n\n\n\n\nThis specific virtual table works by continuously querying Redis itself.\n\n\nWhen you execute a \nSELECT\n against it, the first step is to \nSCAN\n all the possible keys, for each key then we retrieve the associated values in each sub-key using \nHGET\n and finally we return the result.\n\n\nComplexity\n.\n\n\nThis implementation comes with several trade-offs.\n\n\nThe space complexity is constant and negligible, no data is duplicated and are necessary only few bytes for the SQLite data structures.\n\n\nThe time complexity for a query is linear \nO(m*n)\n where \nm\n is the number of rows and \nn\n is the number of columns.\n\n\nThis virtual table does not support \nINSERT\n, \nUPDATE\n or \nDELETE\n.\n\n\nSee also\n:\n\n\n\n\nSQLite virtual tables\n\n\nRedis Hashes\n\n\nSCAN\n\n\nHGET",
            "title": "References"
        },
        {
            "location": "/references/#references",
            "text": "This document explains all the API that RediSQL provide to the users.  For each command, it exposes first the name and then the syntax and finally a brief explanation of what is going on inside the code.  Where is possible, it provides also an estimate of the complexity but since we are talking about databases not all queries have the same time and spatial complexity.  Finally, if it is appropriate the document also provides several references to external material that the interested reader can use to understand better the dynamics of every and each command.",
            "title": "References"
        },
        {
            "location": "/references/#redisqlcreate_db",
            "text": "REDISQL.CREATE_DB db_key [path]  This command creates a new DB and associates it with the key.  The path argument is optional and, if provided is the file that SQLite will use.\nIt can be an existing SQLite file or it can be a not existing file.  If the file actually exists and if it is a regular SQLite file that database will be used.\nIf the file does not exist a new file will be created.  If the path is not provided it will open an in-memory database. Not providing a path is equivalent to provide the special string  :memory:  as path argument.  After opening the database it inserts metadata into it and then starts a thread loop.  Complexity : O(1), it means constant, it does not necessarily mean  fast . However is fast enough for any use case facing human users (eg create a new database for every user logging in a website.)  See also :    SQLite  sqlite3_open_v2",
            "title": "REDISQL.CREATE_DB"
        },
        {
            "location": "/references/#del",
            "text": "DEL db_key [key ...]  This command is a generic command from Redis.  It eliminates keys from Redis itself, as well if the key is a RediSQL database create with  REDISQL.CREATE_DB  it will eliminate the SQLite database, stop the thread loop and clean up everything left.  If the database is backed by a file the file will be close.  Complexity : DEL is O(N) on the number of keys, if you are only eliminating the key associated with the SQLite database will be constant, O(1).  See also :    SQLite  sqlite3_close  Redis  DEL",
            "title": "DEL"
        },
        {
            "location": "/references/#redisqlexec",
            "text": "REDISQL.EXEC[.NOW] db_key \"statement\"  This command takes as input a Redis key created with  REDISQL.CREATE_DB  and a statement string.  Internally it transform the string into a  sqlite statement  using  sqlite3_prepare_v2 , execute it against the database,  sqlite3_step , and finally returns the results to the client.  The compilation of the string into a statement and its execution happens in a different thread from the one used by Redis and so this command has a minimum impact on the overall Redis performance, however, it does block the client.  This command is quite useful to execute  PRAGMA Statements , for normal operations against the database is suggested to use  STATEMENTS .  Also, remember that there is only a single thread for database, execution of multiple  REDISQL.EXEC  against the same database will result in a serialization of the executions, one will be executed before the others.  If you only need to query the database without modifying the data is a better idea to use  REDISQL.QUERY .  Complexity : It depends entirely on the statement string. The use of a single thread for database is been chosen after several tests where the single thread configuration was faster than a multi-thread one. This is true in a write-intensive application and in a mixed write/read application.  See also :   SQLite  sqlite3_prepare_v2  SQLite  statement  aka  sqlite3_stmt  SQLite  sqlite3_step  SQLite  PRAGMA s  Redis Blocking Command",
            "title": "REDISQL.EXEC"
        },
        {
            "location": "/references/#redisqlquery",
            "text": "REDISQL.QUERY[.NOW] db_key \"statement\"  This command behaves similarly to  REDISQL.EXEC  but it imposes an additional constraint on the statement it executes.  It only executes the statement if it is a read-only operation, otherwise, it returns an error.  A read-only operation is defined by the result of calling  sqlite3_stmt_readonly  on the compiled statement.  The statement is executed if and only if  sqlite3_stmt_readonly  returns true.  If you need to execute the same query over and over it is a good idea to create a statement and use  REDISQL.QUERY_STATEMENT .  Complexity : Similar to  REDISQL.EXEC , however, if a statement is not read-only it is aborted immediately and it does return an appropriate error.  See also :   SQLite  sqlite3_prepare_v2  SQLite  statement  aka  sqlite3_stmt  SQLite  sqlite3_step  SQLite  PRAGMA s  Redis Blocking Command    REDISQL.EXEC  SQLite  sqlite3_stmt_readonly  REDISQL.QUERY_STATEMENT",
            "title": "REDISQL.QUERY"
        },
        {
            "location": "/references/#redisqlqueryinto",
            "text": "REDISQL.QUERY.INTO[.NOW] stream_name db_key \"query\"  This command is similar to  REDISQL.QUERY  but instead of returning the result of the query, it append each row to the  stream   stream_name  passed as first argument.   The query must be a read-only one, exactly as  REDISQL.QUERY .  The command executes  XADD  to the stream, hence if the stream does not exists a new one is created. On the other hand, if the stream already exists the rows are simply appended.  The command itself is eager, hence it compute the whole result, append it into the stream, and then it returns. Once the command returns, the whole result set is already in the Redis stream.  The return value of the command depends on the result of the query:   If the result of the query is empty, it simply returns  [\"DONE\", 0] , exactly like  REDISQL.QUERY .  If at least one row is returnend by the query the command returns the name of the stream where it appended the resulting rows, which is exactly the one passed as input, the first and the last ID added to the stream and the total number of entries added to the stream.   The stream will use autogeneratated IDs.  Each entry in a stream is a set of field-value (key-value) pairs. The field (key) will be the type of the row and its name separated by a colon. It cpuld be something like  int:users  or  text:user_name  or even  real:x_coordinate .  The value will simply store the value of the column untouched.   127.0.0.1:6379> REDISQL.CREATE_DB DB\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"CREATE TABLE foo(a int, b int);\"\n1) DONE\n2) (integer) 0\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO foo(a) VALUES(1)\"\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO foo VALUES(3, 4)\"\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO foo VALUES(5, 6)\"\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO foo VALUES(10, 19)\"\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.QUERY.INTO {DB}:all_foo DB \"SELECT * FROM foo\"\n1) 1) \"{DB}:all_foo\"\n   2) \"1549811093979-0\"\n   3) \"1549811093979-3\"\n   4) (integer) 4\n127.0.0.1:6379> XRANGE {DB}:all_foo - +\n1) 1) \"1549811093979-0\"\n   2) 1) \"int:a\"\n      2) \"1\"\n      3) \"null:b\"\n      4) \"(null)\"\n2) 1) \"1549811093979-1\"\n   2) 1) \"int:a\"\n      2) \"3\"\n      3) \"int:b\"\n      4) \"4\"\n3) 1) \"1549811093979-2\"\n   2) 1) \"int:a\"\n      2) \"5\"\n      3) \"int:b\"\n      4) \"6\"\n4) 1) \"1549811093979-3\"\n   2) 1) \"int:a\"\n      2) \"10\"\n      3) \"int:b\"\n      4) \"19\"  Using a standard Redis Stream all the standard consideration applies.   The stream is not deleted by RediSQL, hence it can definitely be used for caching, on the other hand too many streams will use memory.  The stream use a standard Redis key, in a cluster environment you should be sure that the database that is executing the query and the stream that will accomodate the result are on the same cluster node. \nThis can be accomplished easily by forcing the stream name to hash to the same cluster node of the database, it is sufficiento to use a  stream_name  composed as such  {db_key}:what:ever:here . Redis will hash only the part between the  {  and  }  in order to compute the cluster node.  The result can be consumed using the standard  Redis streams commands , two good starting points are  XREAD  and  XRANGE .   Complexity : The complexity of the command is  O(n)  where  n  is the amount of row returned by the query.  See also :   REDISQL.QUERY    REDISQL.QUERY_STATEMENT.INTO    Redis Streams Intro  Redis Streams Commands  XADD  XREAD  XRANGE",
            "title": "REDISQL.QUERY.INTO"
        },
        {
            "location": "/references/#redisqlcreate_statement",
            "text": "REDISQL.CREATE_STATEMENT[.NOW] db_key stmt_identifier \"statement\"  This command compiles a statement string into a  sqlite statement  and associate such statement to an identifier.  Using this command you can insert parameters using the special symbol  ?NNN , those parameters will be bind to the statements when you are executing the statement itself.  For now only the  ?NNN  syntax is supported, where  N  is a digit (Ex.  ?1 ,  ?2 ,  ?3  ...)  This command does not execute anything against the database, but simply store the sqlite statements into a dictionary associated with the identifier provided ( stmt_identifier ). Then it stores the information regarding the statement in the metadata table in order to provide a simple way to restore also the statements.  The statement is associated with a database, a statement created for one database cannot be used for another database, you need to create a different one. This allows a simple and fast way to provide persistence.  You can execute the statement with  REDISQL.EXEC_STATEMENT .  You cannot overwrite a statement using this command.  If you need to change the implementation of a statement you have two options:   Delete the statement using  REDISQL.DELETE_STATEMENT  and the create a new one.  Use  REDISQL.UPDATE_STATEMENT   Suppose that a service needs a particular statement to be defined in order to work, this safety measure allows the users to simply go ahead, try to create it, and in case catch the error.  Also, this command is not blocking, meaning that all the work happens in a separate thread respect the redis one.  Please keep in mind that the parameters should be named in order and that there should not be any gap.  INSERT INTO foo VALUES(?1, ?2, ?3); -- this one is fine and we work as you expect\n\nINSERT INTO foo VALUES(?1, ?123, ?564); -- this one will be more problematic, and you should avoid it  Keep in mind that SQLite start to count the bounding parameters from 1 and not from 0, using  ?0  is an error.  Complexity : If we assume that the time necessary to compile a string into a sqlite statement is constant, overall the complexity is O(1), again constant, not necessarily  fast .  See also :   SQLite  sqlite3_prepare_v2  SQLite  statement  aka  sqlite3_stmt  SQLite bindings,  sqlite3_bind_text  REDISQL.EXEC_STATEMENT  REDISQL.DELETE_STATEMENT  REDISQL.UPDATE_STATEMENT  Redis Blocking Command",
            "title": "REDISQL.CREATE_STATEMENT"
        },
        {
            "location": "/references/#redisqlexec_statement",
            "text": "REDISQL.EXEC_STATEMENT[.NOW] db_key stmt_identifier [binding_parameters ...]  This command binds all the parameters to the statement created using  REDISQL.CREATE_STATEMENT  and identified by  stmt_identifier . Then the module executes the statement against the database associated to  db_key .  For each parameter in the query of the form  ?nnn  the engine will look for the  nnn-th  binding_parameters.\nSo if the statements is from the following query:  INSERT INTO foo VALUES(?1, ?2, ?3);  You will only need to provide 3 parameters and they will be bound, in order to  ?1 ,  ?2  and  ?3 .  If your statements looks like this:  INSERT INTO foo VALUES(?1, ?123, ?564);  You will need to provide 564 parameters and only the first, the 123-rd and the 564-th will be considered.  SQLite starts to count the binding parameters from 0, not from 1. Using  ?0  is an error.  Redis works using a text protocol, all the arguments are encoded as text, hence the module is forced to use the procedure  sqlite3_bind_text , however, SQLite is smart enough to recognize numbers and treat them correctly. Numbers will be treated as numbers and text will be treated as text.  Finally, once completed the binding part the statement is executed and its result is returned to the client.  This command as well is not blocking, all the work happens in a different thread from the one of Redis.  If you need to query your database, without modifying the data is a better idea to use  REDISQL.QUERY_STATEMENT .  Complexity : The complexity to retrieve and to bind the parameters is roughly constant for any practical purpose, however, the overall complexity will be dominated by the time to execute the query.  See also :   SQLite  statement  aka  sqlite3_stmt  SQLite bindings,  sqlite3_bind_text  REDISQL.CREATE_STATEMENT  Redis Blocking Command  REDISQL.QUERY_STATEMENT",
            "title": "REDISQL.EXEC_STATEMENT"
        },
        {
            "location": "/references/#redisqlquery_statement",
            "text": "REDISQL.QUERY_STATEMENT[.NOW] db_key stmt_identifier [binding_parameters ...]  This command behaves similarly to  REDISQL.EXEC_STATEMENT  however it does impose an additional constraint.  It executes the statement if it is a read-only operation, otherwise, it returns an error.  A read-only operation is defined by the result of calling  sqlite3_stmt_readonly  on the compiled statement.  The statement is executed if and only if  sqlite3_stmt_readonly  returns true.  The result of  sqlite3_stmt_readonly  is cached.  If you don't want to create a statement to run a query just once you can use  REDISQL.QUERY .  Complexity : Similar to  REDISQL.EXEC_STATEMENT , however, if a statement is not read-only it is aborted immediately and it does return an appropriate error.  See also :   SQLite  sqlite3_prepare_v2  SQLite  statement  aka  sqlite3_stmt  SQLite  sqlite3_step  SQLite  PRAGMA s  Redis Blocking Command    REDISQL.EXEC_STATEMENT  SQLite  sqlite3_stmt_readonly  REDISQL.QUERY",
            "title": "REDISQL.QUERY_STATEMENT"
        },
        {
            "location": "/references/#redisqlquery_statementinto",
            "text": "REDISQL.QUERY_STATEMENT.INTO[.NOW] stream_name db_key stmt_identifier [binding_parameters ...]  This command behave like  REDISQL.QUERY.INTO  but instead of a query it takes as input a read-only statement and its binding paramenters.  Complexity : The complexity of the command is  O(n)  where  n  is the amount of row returned by the query.  See also :   REDISQL.QUERY.INTO    REDISQL.QUERY_STATEMENT    Redis Streams Intro  Redis Streams Commands  XADD  XREAD  XRANGE",
            "title": "REDISQL.QUERY_STATEMENT.INTO"
        },
        {
            "location": "/references/#redisqldelete_statement",
            "text": "REDISQL.DELETE_STATEMENT[.NOW] db_key stmt_identifier  This command eliminates a statement from the database.  It first looks it up into the internal hash table, if it finds the statement the command removes it from the internal hash table and then remove it from an internal SQLite table.  Also, this command is not blocking and work in a different thread from the main Redis one.  Complexity : The complexity is constant and it can be considered  fast  for most practical application.  See also :   SQLite  statement  aka  sqlite3_stmt  REDISQL.CREATE_STATEMENT  REDISQL.EXEC_STATEMENT  REDISQL.UPDATE_STATEMENT  Redis Blocking Command",
            "title": "REDISQL.DELETE_STATEMENT"
        },
        {
            "location": "/references/#redisqlupdate_statement",
            "text": "REDISQL.UPDATE_STATEMENT[.NOW] db_key stmt_identifier \"statement\"  The command update and  existing  statement changing its internal implementation to the one provide as string.  If the statement does not exist the command will fail and return an error, again this is a safety measure, you must be completely aware that you are changing the implementation of a statement and updating a not existing statement or creating an existing one will result in an error.  Internally the command starts checking if the statement is already defined, then it tries to compile the string into a  sqlite3_stmt  and if everything went right it finally updates the metadata table and finally returns to the client.  This command is not blocking as well.  Complexity : The complexity is constant and it can be considered  fast  for most practical application.  See also :   SQLite  statement  aka  sqlite3_stmt  REDISQL.CREATE_STATEMENT  REDISQL.EXEC_STATEMENT  REDISQL.DELETE_STATEMENT  Redis Blocking Command",
            "title": "REDISQL.UPDATE_STATEMENT"
        },
        {
            "location": "/references/#redisqlcopy",
            "text": "REDISQL.COPY[.NOW] db_key_source db_key_destination  The command copies the source database into the destination database.  The content of the destination databases is completely ignored and lost.  It is not important if the databases are stored in memory or backed by disk, the  COPY  command will work nevertheless.  This command is useful to:   Create backups of databases  Load data from a slow, disk based, databases into a fast in-memory one  To persist data from a in-memory database into a disk based database  Initialize a database with a predefined status   Usually the destination database is an empty database just created, while the source one is a databases where we have been working for a while.  This command use the  backup API  of sqlite.  Complexity : The complexity is linear on the number of page (dimension) of the source database, beware it can be \"slow\" if the source database is big, during the copy the  source  database is busy and it cannot serve other queries.   See also :   Backup API",
            "title": "REDISQL.COPY"
        },
        {
            "location": "/references/#redisqlstatistics",
            "text": "REDISQL.STATISTICS  The command print the internal statistics of RediSQL.  There are 3 counter associated to each command. \nThe first one for counting the number of times the command is been invoked.\nThe second ( OK  counter) keep tracks of how many times the command returned successfully.\nThe third ( ERR  counter) memorize the amount of times the command returned an error.   The counters are implemented as atomic counters, they don't use locks nor introduces any notiaceble slowdown to the application.  127.0.0.1:6379> REDISQL.STATISTICS\n 1) 1) \"CREATE_DB\"\n    2) (integer) 1\n 2) 1) \"CREATE_DB OK\"\n    2) (integer) 1\n 3) 1) \"CREATE_DB ERR\"\n    2) (integer) 0\n 4) 1) \"EXEC\"\n    2) (integer) 4\n 5) 1) \"EXEC OK\"\n    2) (integer) 4\n 6) 1) \"EXEC ERR\"\n    2) (integer) 0\n 7) 1) \"QUERY\"\n    2) (integer) 0\n 8) 1) \"QUERY OK\"\n    2) (integer) 0\n 9) 1) \"QUERY ERR\"\n    2) (integer) 0\n10) 1) \"QUERY.INTO\"\n    2) (integer) 0\n11) 1) \"QUERY.INTO OK\"\n    2) (integer) 0\n12) 1) \"QUERY.INTO ERR\"\n    2) (integer) 0\n13) 1) \"CREATE_STATEMENT\"\n    2) (integer) 3\n14) 1) \"CREATE_STATEMENT OK\"\n    2) (integer) 1\n15) 1) \"CREATE_STATEMENT ERR\"\n    2) (integer) 2\n16) 1) \"EXEC_STATEMENT\"\n    2) (integer) 2\n17) 1) \"EXEC_STATEMENT OK\"\n    2) (integer) 2\n18) 1) \"EXEC_STATEMENT ERR\"\n    2) (integer) 0\n19) 1) \"UPDATE_STATEMENT\"\n    2) (integer) 2\n20) 1) \"UPDATE_STATEMENT OK\"\n    2) (integer) 1\n21) 1) \"UPDATE_STATEMENT ERR\"\n    2) (integer) 1\n22) 1) \"DELETE_STATEMENT\"\n    2) (integer) 0\n23) 1) \"DELETE_STATEMENT OK\"\n    2) (integer) 0\n24) 1) \"DELETE_STATEMENT ERR\"\n    2) (integer) 0\n25) 1) \"QUERY_STATEMENT\"\n    2) (integer) 0\n26) 1) \"QUERY_STATEMENT OK\"\n    2) (integer) 0\n27) 1) \"QUERY_STATEMENT ERR\"\n    2) (integer) 0\n28) 1) \"QUERY_STATEMENT.INTO\"\n    2) (integer) 0\n29) 1) \"QUERY_STATEMENT.INTO OK\"\n    2) (integer) 0\n30) 1) \"QUERY_STATEMENT.INTO ERR\"\n    2) (integer) 0\n31) 1) \"COPY\"\n    2) (integer) 0\n32) 1) \"COPY OK\"\n    2) (integer) 0\n33) 1) \"COPY ERR\"\n    2) (integer) 0  Complexity : The complexity is constant.",
            "title": "REDISQL.STATISTICS"
        },
        {
            "location": "/references/#redisqlcopy_1",
            "text": "REDISQL.COPY[.NOW] db_key_source db_key_destination  The command copies the source database into the destination database.  The content of the destination databases is completely ignored and lost.  It is not important if the databases are stored in memory or backed by disk, the  COPY  command will work nevertheless.  This command is useful to:   Create backups of databases  Load data from a slow, disk based, databases into a fast in-memory one  To persist data from a in-memory database into a disk based database  Initialize a database with a predefined status   Usually the destination database is an empty database just created, while the source one is a databases where we have been working for a while.  This command use the  backup API  of sqlite.  Complexity : The complexity is linear on the number of page (dimension) of the source database, beware it can be \"slow\" if the source database is big, during the copy the  source  database is busy and it cannot serve other queries.   See also :   Backup API",
            "title": "REDISQL.COPY"
        },
        {
            "location": "/references/#virtual-tables",
            "text": "What follows is not a RediSQL command but an SQLite virtual table introduced by the module.  Virtual tables behave similarly to normal tables but have some limitations, for a deeper explanation please visit the  official SQLite documentation about virtual tables.  At the moment the module provides a single read-only virtual table:  REDISQL_TABLES_BRUTE_HASH .",
            "title": "Virtual Tables"
        },
        {
            "location": "/references/#redisql_tables_brute_hash",
            "text": "This virtual table allows you to query  Redis Hashes  that follow a similar pattern.  A redis hash is composed by a key, that identifies the structure in the whole database, and several sub-keys that map to different string fields.  This structure can easily be mapped to a standard table, where the key identifies the row and the sub-keys the columns.  Redis does not impose any limitation to the format of the hash key, however, in order to use the virtual table you need to follow a specific syntax that happens to be the de-facto standard for hash keys.  The key must be in the following format  $tableName:$id  where  $id  must be an integer. There are no limitations on the sub-keys.  127.0.0.1:6379> HSET cats:1 name romeo location rome hungry 3\n(integer) 3\n127.0.0.1:6379> HSET cats:2 name garfield location london hungry 10\n(integer) 3\n127.0.0.1:6379> HSET cats:3 name \"simon's cat\" location \"simon's house\" hungry 8\n(integer) 3  In this examples we have a table of cats, each with a name, a location, and a hungry level.  Redis is perfect if we want to know how hungry is  romeo  or where is located  garfield .  However is a little more difficult to answer query like: who is the hungriest cat? Are there any cats in London?   Of course, the use of different data structures could alleviate these issues but then there will be the necessity to keep the several data structures in sync one with the other.  Another alternative can be the use of the  REDISQL_TABLE_BRUTE_HASH  virtual table.  127.0.0.1:6379> REDISQL.EXEC DB \"CREATE VIRTUAL TABLE funny_cats USING REDISQL_TABLES_BRUTE_HASH(cats, name, location, hungry);\"\n1) DONE\n2) (integer) 0\n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT * FROM funny_cats\"\n1) 1) \"cats:2\"\n   2) \"garfield\"\n   3) \"london\"\n   4) \"10\"\n2) 1) \"cats:1\"\n   2) \"romeo\"\n   3) \"rome\"\n   4) \"3\"\n3) 1) \"cats:3\"\n   2) \"simon's cat\"\n   3) \"simon's house\"\n   4) \"8\"  This virtual table allows querying the redis hashes using a more convenient SQL syntax. It does require a constant amount of space but it operates in linear time with the respect of the elements in the \"hash table\".  The syntax of the virtual table is quite simple,  REDISQL_TABLES_BRUTE_HASH(cats, name, location, hungry) , as first we need the  $tableName , so the key of every row without the  :$id  part. \nThen the columns of the table. Please note that you do  not  provide the type of the column in the declaration.  Is not necessary that every key defines all the columns (sub-keys), if a key does not have a specific sub-key, it will simply be returned as (nil).  This virtual table is a read-only virtual table, it means that -- at the moment -- you can only  select  from this table, so you cannot  insert ,  update  or  delete  from this table.  Another limitation is that Redis Hashes can store only strings, not integers or floats. This implies that by default we will return only strings when you query a table, of course, you could cast them to integers or float via SQLite.  127.0.0.1:6379> REDISQL.EXEC DB \"SELECT name, location, CAST(hungry AS INTEGER) FROM cats\"\n1) 1) \"garfield\"\n   2) \"london\"\n   3) (integer) 10\n2) 1) \"romeo\"\n   2) \"rome\"\n   3) (integer) 3\n3) 1) \"simon's cat\"\n   2) \"simon's house\"\n   3) (integer) 8  This specific virtual table works by continuously querying Redis itself.  When you execute a  SELECT  against it, the first step is to  SCAN  all the possible keys, for each key then we retrieve the associated values in each sub-key using  HGET  and finally we return the result.  Complexity .  This implementation comes with several trade-offs.  The space complexity is constant and negligible, no data is duplicated and are necessary only few bytes for the SQLite data structures.  The time complexity for a query is linear  O(m*n)  where  m  is the number of rows and  n  is the number of columns.  This virtual table does not support  INSERT ,  UPDATE  or  DELETE .  See also :   SQLite virtual tables  Redis Hashes  SCAN  HGET",
            "title": "REDISQL_TABLES_BRUTE_HASH"
        },
        {
            "location": "/pro/",
            "text": "RediSQL PRO\n\n\nThis document explains the architecture and principle of working of RediSQL PRO.\n\n\nYou can purchase RediSQL PRO, along with support \nhere.\n\n\nMain difference\n\n\nThe PRO version comes without telemetrics.\n\n\nThe community version requires RediSQL to periodically send telemetrics information to our server otherwise RediSQL shut itself down.\nThis is not require by the PRO version.\n\n\nTelemetrics data\n\n\nThe data send to our servers are definitely not critical data, indeed we ship the result of the \nREDISQL.STATISTICS\n commands.\nMoreover we took all the precaution to make sure that our user are not impacted by possible errors on our side replicating all pieces of our infrastructure. \nMore details about the technical implementation on our blog.\n\n\nMore details behind our motivation in our blog post.",
            "title": "Pro"
        },
        {
            "location": "/pro/#redisql-pro",
            "text": "This document explains the architecture and principle of working of RediSQL PRO.  You can purchase RediSQL PRO, along with support  here.",
            "title": "RediSQL PRO"
        },
        {
            "location": "/pro/#main-difference",
            "text": "The PRO version comes without telemetrics.  The community version requires RediSQL to periodically send telemetrics information to our server otherwise RediSQL shut itself down.\nThis is not require by the PRO version.",
            "title": "Main difference"
        },
        {
            "location": "/pro/#telemetrics-data",
            "text": "The data send to our servers are definitely not critical data, indeed we ship the result of the  REDISQL.STATISTICS  commands.\nMoreover we took all the precaution to make sure that our user are not impacted by possible errors on our side replicating all pieces of our infrastructure.  More details about the technical implementation on our blog.  More details behind our motivation in our blog post.",
            "title": "Telemetrics data"
        },
        {
            "location": "/motivations/",
            "text": "Motivation\n\n\nThis document explains the motivations behind this redis module.\n\n\nMy personal use case\n\n\nAs a lot of different open source projects, this module is born out of a personal issue that I was trying to solve.\n\n\nI was developing a very simple application using a microservice architecture, each service needed to be stopped and updated at will so it was mandatory to store all the state in an external application.\n\n\nRedis was perfect for this use case since it is very simple to operate, you could get away simply setting your level of persistence, extremely stable, very performant and there are bindings ready for basically any programming language.\n\n\nHowever, the application started to grow in terms of complexity and soon I realized that having a small SQL engine would have saved me a lot of complexity in my code while delivering better performances.\n\n\nAt that time I had only the following options:\n\n\n\n\nKeep all the state in Redis, implementing by hand, or using some external library, whatever SQL-like transformation I needed.\n\n\nBring in another piece inside my architecture, namely an SQL database.\n\n\n\n\nFor some project it may be worth to immediately include an external dependency in the form of a database, but it brings up the cost of operating the infrastructure.\n\n\nOperating a database is quite complex, operating it in any organization costs in terms of human resources or, if you use managed services, directly in terms of money.\n\n\nAlso, since all my state was kept only in Redis, introducing another \"source of truth\" would have complicated the code base.\n\n\nMy project definitely didn't need the whole computing power of Postgresql or of MySQL, I didn't need the burden of operating it and definitely I wasn't in the condition to pay for managed services.\n\n\nWhy RediSQL\n\n\nThe goal of the module is to create a third alternative to the two mentioned above.\n\n\nI wanted this alternative to be as low maintenance as possible, keep a great level of security on the persistency of the data stored and to be easily deployed in most architectures.\n\n\nSQLite easily checks both the low maintenance and the high level of persistency requirements. Redis is already deployed in most architectures, either as a cache layer or as a database.\n\n\nFinally, merging the two project was just made possible by the introduction of the Redis modules.\n\n\nHence, RediSQL was born.\n\n\nPossible uses\n\n\nRediSQL has been thought to be used as an in-memory SQL database, shared between multiple (micro-)services.\n\n\nHowever, RediSQL inherits the persistency capabilities of Redis, supporting RDB and AOF, and of SQLite, with the possibility to write directly on disk.\n\n\nMoreover, it basically never uses the main thread of Redis, hence it will not affect the performance of Redis itself.\n\n\nThis makes RediSQL a reasonable solution to store and persist data in a small to a medium modern project.",
            "title": "Motivations"
        },
        {
            "location": "/motivations/#motivation",
            "text": "This document explains the motivations behind this redis module.",
            "title": "Motivation"
        },
        {
            "location": "/motivations/#my-personal-use-case",
            "text": "As a lot of different open source projects, this module is born out of a personal issue that I was trying to solve.  I was developing a very simple application using a microservice architecture, each service needed to be stopped and updated at will so it was mandatory to store all the state in an external application.  Redis was perfect for this use case since it is very simple to operate, you could get away simply setting your level of persistence, extremely stable, very performant and there are bindings ready for basically any programming language.  However, the application started to grow in terms of complexity and soon I realized that having a small SQL engine would have saved me a lot of complexity in my code while delivering better performances.  At that time I had only the following options:   Keep all the state in Redis, implementing by hand, or using some external library, whatever SQL-like transformation I needed.  Bring in another piece inside my architecture, namely an SQL database.   For some project it may be worth to immediately include an external dependency in the form of a database, but it brings up the cost of operating the infrastructure.  Operating a database is quite complex, operating it in any organization costs in terms of human resources or, if you use managed services, directly in terms of money.  Also, since all my state was kept only in Redis, introducing another \"source of truth\" would have complicated the code base.  My project definitely didn't need the whole computing power of Postgresql or of MySQL, I didn't need the burden of operating it and definitely I wasn't in the condition to pay for managed services.",
            "title": "My personal use case"
        },
        {
            "location": "/motivations/#why-redisql",
            "text": "The goal of the module is to create a third alternative to the two mentioned above.  I wanted this alternative to be as low maintenance as possible, keep a great level of security on the persistency of the data stored and to be easily deployed in most architectures.  SQLite easily checks both the low maintenance and the high level of persistency requirements. Redis is already deployed in most architectures, either as a cache layer or as a database.  Finally, merging the two project was just made possible by the introduction of the Redis modules.  Hence, RediSQL was born.",
            "title": "Why RediSQL"
        },
        {
            "location": "/motivations/#possible-uses",
            "text": "RediSQL has been thought to be used as an in-memory SQL database, shared between multiple (micro-)services.  However, RediSQL inherits the persistency capabilities of Redis, supporting RDB and AOF, and of SQLite, with the possibility to write directly on disk.  Moreover, it basically never uses the main thread of Redis, hence it will not affect the performance of Redis itself.  This makes RediSQL a reasonable solution to store and persist data in a small to a medium modern project.",
            "title": "Possible uses"
        },
        {
            "location": "/blog/tutorial/",
            "text": "Tutorial for RediSQL\n\n\nIf you want to start exploring RediSQL, this tutorial will walk you through the most important commands to know and how to use them.\n\n\nThe tutorial can be followed also connecting on our demo machine @ demo.redisql.com:\n\n\nredis-cli -h demo.redisql.com\n\n\n\n\nIf you connect to the demo machine, please remember that it is a shared machine and other users can be using it at the same time. Also note that we clean up the machine every hour.\n\n\n\n\n\n\n\nCreate your database\n\n\nThe first fundamental concept in RediSQL is the concept of database.\n\n\nOne database is a SQLite database that is associated with a Redis key, creating a new database also means to spawn a new thread that will be the one that actually does the work leaving the main Redis thread available to answer standard Redis queries.\n\n\nTo create a new RediSQL database just run:\n\n\nREDISQL.CREATE_DB TUTORIAL\n\nOK\n\n\n\n\nThis will create a new in-memory database associated with the name \nTUTORIAL\n.\n\n\n(If you receive an error at this stage, most likely someone else is following the tutorial, no worries, instead of \nTUTORIAL\n simply use another name).\n\n\nFirst interaction\n\n\nNow that we have create a new database, we can interact with it.\n\n\nThe simplest command to use is the \nREDISQL.EXEC\n command that will execute one query against our newly created database, try:\n\n\nREDISQL.EXEC TUTORIAL \"SELECT 1;\"\n\n1) 1) (integer) 1\n\n\n\n\nThis command should simply return 1.\n\n\nWhat we can do, is to create a simple SQL table.\n\n\nREDISQL.EXEC TUTORIAL \"CREATE TABLE first_table(a integer, b string);\"\n\n1) DONE\n2) (integer) 0\n\n\n\n\nCongrats, you have just created a new table.\n\n\nInsert values\n\n\nAfter we create our first table, we can insert some value into it.\n\n\nREDISQL.EXEC TUTORIAL \"INSERT INTO first_table VALUES(1, 'the first row'), (2, 'the second row');\"\n\n1) DONE\n2) (integer) 2\n\n\n\n\nThis command will return 2, the number of rows inserted.\n\n\nQuery values\n\n\nNow we can try to select some values from our table, as an example:\n\n\nREDISQL.EXEC TUTORIAL \"SELECT * FROM first_table;\"\n\n1) 1) (integer) 1\n   2) \"the first row\"\n2) 1) (integer) 2\n   2) \"the second row\"\n\n\n\n\nAnother way to select values is to use the \nQUERY\n command, this command works only if the query you send is a read-only query.\n\n\nREDISQL.QUERY TUTORIAL \"SELECT * FROM first_table WHERE a = 1;\"\n\n1) 1) (integer) 1\n   2) \"the first row\"\n\n\n\n\nStatements\n\n\nWriting this commands all over again get tedious, moreover, it is inefficient since the SQL engine needs to parse and compile the SQL query every time. The solution, in this case, is the use of statements.\n\n\nREDISQL.CREATE_STATEMENT TUTORIAL filter_on_a \"SELECT * FROM first_table WHERE a = ?1;\"\n\n\nOK\n\n\n\n\nThe statements can both query (as above) or insert rows:\n\n\nREDISQL.CREATE_STATEMENT TUTORIAL new_row \"INSERT INTO first_table VALUES(?1, 'insert_from_statement');\"\n\nOK\n\n\n\n\nStatements can be invoked using:\n\n\nREDISQL.EXEC_STATEMENT TUTORIAL new_row 5\n\n1) DONE\n2) (integer) 1\n\n\n\n\nOr if they are read-only statements:\n\n\nREDISQL.QUERY_STATEMENT TUTORIAL filter_on_a 5\n\n1) 1) (integer) 5\n   2) \"insert_from_statement\"\n\n\n\n\nPush to streams\n\n\nSometimes you may want to store the result of your queries in Redis itself, to consume it little by little, or for caching. In such cases, the solution is to push the results into a Redis stream.\n\n\nREDISQL.QUERY.INTO tutorial_stream TUTORIAL \"SELECT * FROM first_table;\"\n\n1) 1) \"tutorial_stream\"\n   2) \"1569174107783-0\"\n   3) \"1569174107783-2\"\n   4) (integer) 3\n\n\n\n\nThis will push the result of the query into the stream \ntutorial_stream\n and it will return:\n1. The name of the stream\n2. The first ID\n3. The last ID\n4. The total number of elements added\n\n\nIn order to retrieve the values from the Redis stream, you can use the standard Redis API:\n\n\nXRANGE tutorial_stream - +\n\n1) 1) \"1569174107783-0\"\n   2) 1) \"int:a\"\n      2) \"1\"\n      3) \"text:b\"\n      4) \"the first row\"\n2) 1) \"1569174107783-1\"\n   2) 1) \"int:a\"\n      2) \"2\"\n      3) \"text:b\"\n      4) \"the second row\"\n3) 1) \"1569174107783-2\"\n   2) 1) \"int:a\"\n      2) \"5\"\n      3) \"text:b\"\n      4) \"insert_from_statement\"\n\n\n\n\nEnd\n\n\nI hope that this tutorial was helpful :)\n\n\nIf you have any question, feel free to contact me simone@redbeardlab.com or on github: \nRedBeardLab/rediSQL",
            "title": "Tutorial"
        },
        {
            "location": "/blog/tutorial/#tutorial-for-redisql",
            "text": "If you want to start exploring RediSQL, this tutorial will walk you through the most important commands to know and how to use them.  The tutorial can be followed also connecting on our demo machine @ demo.redisql.com:  redis-cli -h demo.redisql.com  If you connect to the demo machine, please remember that it is a shared machine and other users can be using it at the same time. Also note that we clean up the machine every hour.",
            "title": "Tutorial for RediSQL"
        },
        {
            "location": "/blog/tutorial/#create-your-database",
            "text": "The first fundamental concept in RediSQL is the concept of database.  One database is a SQLite database that is associated with a Redis key, creating a new database also means to spawn a new thread that will be the one that actually does the work leaving the main Redis thread available to answer standard Redis queries.  To create a new RediSQL database just run:  REDISQL.CREATE_DB TUTORIAL\n\nOK  This will create a new in-memory database associated with the name  TUTORIAL .  (If you receive an error at this stage, most likely someone else is following the tutorial, no worries, instead of  TUTORIAL  simply use another name).",
            "title": "Create your database"
        },
        {
            "location": "/blog/tutorial/#first-interaction",
            "text": "Now that we have create a new database, we can interact with it.  The simplest command to use is the  REDISQL.EXEC  command that will execute one query against our newly created database, try:  REDISQL.EXEC TUTORIAL \"SELECT 1;\"\n\n1) 1) (integer) 1  This command should simply return 1.  What we can do, is to create a simple SQL table.  REDISQL.EXEC TUTORIAL \"CREATE TABLE first_table(a integer, b string);\"\n\n1) DONE\n2) (integer) 0  Congrats, you have just created a new table.",
            "title": "First interaction"
        },
        {
            "location": "/blog/tutorial/#insert-values",
            "text": "After we create our first table, we can insert some value into it.  REDISQL.EXEC TUTORIAL \"INSERT INTO first_table VALUES(1, 'the first row'), (2, 'the second row');\"\n\n1) DONE\n2) (integer) 2  This command will return 2, the number of rows inserted.",
            "title": "Insert values"
        },
        {
            "location": "/blog/tutorial/#query-values",
            "text": "Now we can try to select some values from our table, as an example:  REDISQL.EXEC TUTORIAL \"SELECT * FROM first_table;\"\n\n1) 1) (integer) 1\n   2) \"the first row\"\n2) 1) (integer) 2\n   2) \"the second row\"  Another way to select values is to use the  QUERY  command, this command works only if the query you send is a read-only query.  REDISQL.QUERY TUTORIAL \"SELECT * FROM first_table WHERE a = 1;\"\n\n1) 1) (integer) 1\n   2) \"the first row\"",
            "title": "Query values"
        },
        {
            "location": "/blog/tutorial/#statements",
            "text": "Writing this commands all over again get tedious, moreover, it is inefficient since the SQL engine needs to parse and compile the SQL query every time. The solution, in this case, is the use of statements.  REDISQL.CREATE_STATEMENT TUTORIAL filter_on_a \"SELECT * FROM first_table WHERE a = ?1;\"\n\n\nOK  The statements can both query (as above) or insert rows:  REDISQL.CREATE_STATEMENT TUTORIAL new_row \"INSERT INTO first_table VALUES(?1, 'insert_from_statement');\"\n\nOK  Statements can be invoked using:  REDISQL.EXEC_STATEMENT TUTORIAL new_row 5\n\n1) DONE\n2) (integer) 1  Or if they are read-only statements:  REDISQL.QUERY_STATEMENT TUTORIAL filter_on_a 5\n\n1) 1) (integer) 5\n   2) \"insert_from_statement\"",
            "title": "Statements"
        },
        {
            "location": "/blog/tutorial/#push-to-streams",
            "text": "Sometimes you may want to store the result of your queries in Redis itself, to consume it little by little, or for caching. In such cases, the solution is to push the results into a Redis stream.  REDISQL.QUERY.INTO tutorial_stream TUTORIAL \"SELECT * FROM first_table;\"\n\n1) 1) \"tutorial_stream\"\n   2) \"1569174107783-0\"\n   3) \"1569174107783-2\"\n   4) (integer) 3  This will push the result of the query into the stream  tutorial_stream  and it will return:\n1. The name of the stream\n2. The first ID\n3. The last ID\n4. The total number of elements added  In order to retrieve the values from the Redis stream, you can use the standard Redis API:  XRANGE tutorial_stream - +\n\n1) 1) \"1569174107783-0\"\n   2) 1) \"int:a\"\n      2) \"1\"\n      3) \"text:b\"\n      4) \"the first row\"\n2) 1) \"1569174107783-1\"\n   2) 1) \"int:a\"\n      2) \"2\"\n      3) \"text:b\"\n      4) \"the second row\"\n3) 1) \"1569174107783-2\"\n   2) 1) \"int:a\"\n      2) \"5\"\n      3) \"text:b\"\n      4) \"insert_from_statement\"",
            "title": "Push to streams"
        },
        {
            "location": "/blog/tutorial/#end",
            "text": "I hope that this tutorial was helpful :)  If you have any question, feel free to contact me simone@redbeardlab.com or on github:  RedBeardLab/rediSQL",
            "title": "End"
        },
        {
            "location": "/blog/release_0.9.0/",
            "text": "Release 0.9.0 of RediSQL, SQL steroids for Redis\n\n\nRediSQL, Redis on SQL steroids.\n\n\nRediSQL is a Redis module that provides full SQL capabilities to Redis, it is the simplest and fastest way to get an SQL database up and running, without incurring in difficult operational issues and it can scale quite well with your business.\n\n\nThe fastest introduction to RediSQL is \nour homepage\n\n\ntl;dr\n This release introduce one simple new command \nREDISQL.STATISTICS\n.\nThe new command returns the amount of time each command is been called and how many of those calls were successfully and how many returned errors.\nThe command does not introduce noticeable slowdowns.\n\n\nThis release is the smallest, however it provide the foundation for the next major releases.\n\n\nMotivation\n\n\nThe infrastucture behind the \nREDISQL.STATISTICS\n commands is needed for the next major release of RediSQL.\n\n\nMoreover it provides an useful tool for the administrator of the instance allowing them to spot inefficiencies.\n\n\nHow to use\n\n\nJust invoke the command without any arguments to get an array of all the counters, extra arguments are ignored for the moment.\n\n\nAfter using RediSQL for few commands, the output of \nREDISQL.STATISTICS\n could be the following.\n\n\n127.0.0.1:6379> REDISQL.STATISTICS\n 1) 1) \"CREATE_DB\"\n    2) (integer) 1\n 2) 1) \"CREATE_DB OK\"\n    2) (integer) 1\n 3) 1) \"CREATE_DB ERR\"\n    2) (integer) 0\n 4) 1) \"EXEC\"\n    2) (integer) 4\n 5) 1) \"EXEC OK\"\n    2) (integer) 4\n 6) 1) \"EXEC ERR\"\n    2) (integer) 0\n 7) 1) \"QUERY\"\n    2) (integer) 0\n 8) 1) \"QUERY OK\"\n    2) (integer) 0\n 9) 1) \"QUERY ERR\"\n    2) (integer) 0\n10) 1) \"QUERY.INTO\"\n    2) (integer) 0\n11) 1) \"QUERY.INTO OK\"\n    2) (integer) 0\n12) 1) \"QUERY.INTO ERR\"\n    2) (integer) 0\n13) 1) \"CREATE_STATEMENT\"\n    2) (integer) 3\n14) 1) \"CREATE_STATEMENT OK\"\n    2) (integer) 1\n15) 1) \"CREATE_STATEMENT ERR\"\n    2) (integer) 2\n16) 1) \"EXEC_STATEMENT\"\n    2) (integer) 2\n17) 1) \"EXEC_STATEMENT OK\"\n    2) (integer) 2\n18) 1) \"EXEC_STATEMENT ERR\"\n    2) (integer) 0\n19) 1) \"UPDATE_STATEMENT\"\n    2) (integer) 2\n20) 1) \"UPDATE_STATEMENT OK\"\n    2) (integer) 1\n21) 1) \"UPDATE_STATEMENT ERR\"\n    2) (integer) 1\n22) 1) \"DELETE_STATEMENT\"\n    2) (integer) 0\n23) 1) \"DELETE_STATEMENT OK\"\n    2) (integer) 0\n24) 1) \"DELETE_STATEMENT ERR\"\n    2) (integer) 0\n25) 1) \"QUERY_STATEMENT\"\n    2) (integer) 0\n26) 1) \"QUERY_STATEMENT OK\"\n    2) (integer) 0\n27) 1) \"QUERY_STATEMENT ERR\"\n    2) (integer) 0\n28) 1) \"QUERY_STATEMENT.INTO\"\n    2) (integer) 0\n29) 1) \"QUERY_STATEMENT.INTO OK\"\n    2) (integer) 0\n30) 1) \"QUERY_STATEMENT.INTO ERR\"\n    2) (integer) 0\n31) 1) \"COPY\"\n    2) (integer) 0\n32) 1) \"COPY OK\"\n    2) (integer) 0\n33) 1) \"COPY ERR\"\n    2) (integer) 0\n\n\n\n\nThe \nCERATE_DB\n line means that the \nREDISQL.CREATE_DB\n command is been invoked once. The \nCREATE_DB OK\n lines means that the command succeeded once.\n\n\nLet's analyze the \nCREATE_STATEMENT\n lines as well.\n\n\n13) 1) \"CREATE_STATEMENT\"\n    2) (integer) 3\n\n\n\n\nThis line says that the command is been invoked 3 times.\n\n\n14) 1) \"CREATE_STATEMENT OK\"\n    2) (integer) 1\n\n\n\n\nThe next line specify that the commands completed successfully 1 time out of 3.\n\n\n15) 1) \"CREATE_STATEMENT ERR\"\n    2) (integer) 2\n\n\n\n\nThe last line confirms that out of the 3 times we invoked the command, 2 of them failed for some reason.\n\n\nOf course the math need to check out and the sum of successful and erroneous runs should match with the number of invocation.\n\n\nImplementation\n\n\nThis command is implemented with atomic counters, they are fast and provide a simple and easy way to manage concurrent access.\n\n\nWe careful tested the performance to make sure that the slowdown introduces by the counter is not noticeable.",
            "title": "Release 0.9.0"
        },
        {
            "location": "/blog/release_0.9.0/#release-090-of-redisql-sql-steroids-for-redis",
            "text": "RediSQL, Redis on SQL steroids.  RediSQL is a Redis module that provides full SQL capabilities to Redis, it is the simplest and fastest way to get an SQL database up and running, without incurring in difficult operational issues and it can scale quite well with your business.  The fastest introduction to RediSQL is  our homepage  tl;dr  This release introduce one simple new command  REDISQL.STATISTICS .\nThe new command returns the amount of time each command is been called and how many of those calls were successfully and how many returned errors.\nThe command does not introduce noticeable slowdowns.  This release is the smallest, however it provide the foundation for the next major releases.",
            "title": "Release 0.9.0 of RediSQL, SQL steroids for Redis"
        },
        {
            "location": "/blog/release_0.9.0/#motivation",
            "text": "The infrastucture behind the  REDISQL.STATISTICS  commands is needed for the next major release of RediSQL.  Moreover it provides an useful tool for the administrator of the instance allowing them to spot inefficiencies.",
            "title": "Motivation"
        },
        {
            "location": "/blog/release_0.9.0/#how-to-use",
            "text": "Just invoke the command without any arguments to get an array of all the counters, extra arguments are ignored for the moment.  After using RediSQL for few commands, the output of  REDISQL.STATISTICS  could be the following.  127.0.0.1:6379> REDISQL.STATISTICS\n 1) 1) \"CREATE_DB\"\n    2) (integer) 1\n 2) 1) \"CREATE_DB OK\"\n    2) (integer) 1\n 3) 1) \"CREATE_DB ERR\"\n    2) (integer) 0\n 4) 1) \"EXEC\"\n    2) (integer) 4\n 5) 1) \"EXEC OK\"\n    2) (integer) 4\n 6) 1) \"EXEC ERR\"\n    2) (integer) 0\n 7) 1) \"QUERY\"\n    2) (integer) 0\n 8) 1) \"QUERY OK\"\n    2) (integer) 0\n 9) 1) \"QUERY ERR\"\n    2) (integer) 0\n10) 1) \"QUERY.INTO\"\n    2) (integer) 0\n11) 1) \"QUERY.INTO OK\"\n    2) (integer) 0\n12) 1) \"QUERY.INTO ERR\"\n    2) (integer) 0\n13) 1) \"CREATE_STATEMENT\"\n    2) (integer) 3\n14) 1) \"CREATE_STATEMENT OK\"\n    2) (integer) 1\n15) 1) \"CREATE_STATEMENT ERR\"\n    2) (integer) 2\n16) 1) \"EXEC_STATEMENT\"\n    2) (integer) 2\n17) 1) \"EXEC_STATEMENT OK\"\n    2) (integer) 2\n18) 1) \"EXEC_STATEMENT ERR\"\n    2) (integer) 0\n19) 1) \"UPDATE_STATEMENT\"\n    2) (integer) 2\n20) 1) \"UPDATE_STATEMENT OK\"\n    2) (integer) 1\n21) 1) \"UPDATE_STATEMENT ERR\"\n    2) (integer) 1\n22) 1) \"DELETE_STATEMENT\"\n    2) (integer) 0\n23) 1) \"DELETE_STATEMENT OK\"\n    2) (integer) 0\n24) 1) \"DELETE_STATEMENT ERR\"\n    2) (integer) 0\n25) 1) \"QUERY_STATEMENT\"\n    2) (integer) 0\n26) 1) \"QUERY_STATEMENT OK\"\n    2) (integer) 0\n27) 1) \"QUERY_STATEMENT ERR\"\n    2) (integer) 0\n28) 1) \"QUERY_STATEMENT.INTO\"\n    2) (integer) 0\n29) 1) \"QUERY_STATEMENT.INTO OK\"\n    2) (integer) 0\n30) 1) \"QUERY_STATEMENT.INTO ERR\"\n    2) (integer) 0\n31) 1) \"COPY\"\n    2) (integer) 0\n32) 1) \"COPY OK\"\n    2) (integer) 0\n33) 1) \"COPY ERR\"\n    2) (integer) 0  The  CERATE_DB  line means that the  REDISQL.CREATE_DB  command is been invoked once. The  CREATE_DB OK  lines means that the command succeeded once.  Let's analyze the  CREATE_STATEMENT  lines as well.  13) 1) \"CREATE_STATEMENT\"\n    2) (integer) 3  This line says that the command is been invoked 3 times.  14) 1) \"CREATE_STATEMENT OK\"\n    2) (integer) 1  The next line specify that the commands completed successfully 1 time out of 3.  15) 1) \"CREATE_STATEMENT ERR\"\n    2) (integer) 2  The last line confirms that out of the 3 times we invoked the command, 2 of them failed for some reason.  Of course the math need to check out and the sum of successful and erroneous runs should match with the number of invocation.",
            "title": "How to use"
        },
        {
            "location": "/blog/release_0.9.0/#implementation",
            "text": "This command is implemented with atomic counters, they are fast and provide a simple and easy way to manage concurrent access.  We careful tested the performance to make sure that the slowdown introduces by the counter is not noticeable.",
            "title": "Implementation"
        },
        {
            "location": "/blog/release_0.8.0/",
            "text": "Release 0.8.0 of RediSQL, SQL steroids for Redis\n\n\nRediSQL, Redis on SQL steroids.\n\n\nRediSQL is a Redis module that provides full SQL capabilities to Redis, it is the simplest and fastest way to get an SQL database up and running, without incurring in difficult operational issues and it can scale quite well with your business.\n\n\nThe fastest introduction to RediSQL is \nour homepage\n\n\ntl;dr\n This release introduce two new commands \nREDISQL.QUERY.INTO[.NOW]\n and \nREDISQL.QUERY_STATEMENT.INTO[.NOW]\n. \nThe new commands behave similary to \nREDISQL.QUERY\n and \nREDISQL.QUERY_STATEMENT\n but they \nXADD\n the results to a \nRedis Stream\n passed as first argument.\n\n\nMotivation\n\n\nBeing able to write the result of a query into a stream opens several possibilities.\nFirst off all allow to easily cache the result of expensive queries.\nThen, it separate the creation of a result with its consuption which is a very important step forward especially for big results.\n\n\nIndeed, while the computation of a query is not done by the main redis thread but it is off-load to another thread to allow redis to keep serving the client. Returning the result must be done in the main Redis thread. \nHence a long result can take a lot of time to be returned to the client and in that time Redis cannot serve other requests.\nWriting the result into a stream make it much more efficient use of the main Redis thread time.\n\n\nMoreover, on the other side of the network, a small consumer might not expect a big result and could be overlwhelmed by the size.\n\n\nIn standard databases this problem is usually solved using cursors, however Redis itself does not provide this facility.\nRedis provide lists, but they are simply flat list and can store only strings, it would be complex to create the cursors on top of them.\n\n\nThe streams however are a better fit. While also them can store only strings, they store them into entries, which are small key-values objects.\nEach entry represent a row of our result set.\nWhere we encode the column name and type into the key, and we use the value field to store the actual value of the column.\n\n\nAn example will be easier to follow.\n\n\nHow to use\n\n\nAn example of \nREDISQL.QUERY.INTO\n is the following:\n\n\nREDISQL.QUERY.INTO result_stream DB \"SELECT foo, bar FROM baz WHERE n > 42\"\n\n\n\n\nThe command will execute the query \nSELECT foo, bar FROM baz WHERE n > 42\n agains the database \nDB\n and it will \nXADD\n each row of the result to the stream \nresult_stream\n.\n\n\nIf the result is empty, the command will return \n[\"DONE\", 0]\n to the Redis client.\n\n\nIf the result is not empty, the command will return, to the Redis client, the name of the stream used (hence \nresult_stream\n in this example) along with the first ID added and the last ID added and the size of the cursor (the number of entries added to the stream.)\n\n\nIn the following example we start by creating a database, then we create a new table \nfoo\n in the database, and we store 4 rows into the table.\n\n\nThen we use the new \nREDISQL.QUERY.NOW\n command to store the result of the query \nSELECT * FROM foo\n agains the database \nDB\n in the stream \n{DB}:all_foo\n.\n\n\n127.0.0.1:6379> REDISQL.CREATE_DB DB\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"CREATE TABLE foo(a int, b int);\"\n1) DONE\n2) (integer) 0\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO foo(a) VALUES(1)\"\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO foo VALUES(3, 4)\"\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO foo VALUES(5, 6)\"\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO foo VALUES(10, 19)\"\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.QUERY.INTO {DB}:all_foo DB \"SELECT * FROM foo\"\n1) 1) \"{DB}:all_foo\"\n   2) \"1549811093979-0\"\n   3) \"1549811093979-3\"\n   4) (integer) 4\n127.0.0.1:6379> XRANGE {DB}:all_foo - +\n1) 1) \"1549811093979-0\"\n   2) 1) \"int:a\"\n      2) \"1\"\n      3) \"null:b\"\n      4) \"(null)\"\n2) 1) \"1549811093979-1\"\n   2) 1) \"int:a\"\n      2) \"3\"\n      3) \"int:b\"\n      4) \"4\"\n3) 1) \"1549811093979-2\"\n   2) 1) \"int:a\"\n      2) \"5\"\n      3) \"int:b\"\n      4) \"6\"\n4) 1) \"1549811093979-3\"\n   2) 1) \"int:a\"\n      2) \"10\"\n      3) \"int:b\"\n      4) \"19\"\n\n\n\n\nThe first thing to notice is that the stream entity contains both the type of the column and it's name as well. The format is \n$column_type:$column_name\n. This is necessary because stream support only strings.\n\n\nIn the example above the string \nint:a\n means that, for this row, the column \na\n is of type \nint\n. Usually the type of a column is constant, however, it may be null, in that case it would be something like: \nnull:b\n.\n\n\nAnother interesting thing to notice is the name of the stream used which can look peculiar. Indeed it is the same name of the database \nDB\n, between curly braces \n{DB}\n and then a useful identifier \n{DB}:all_foo\n. The name of the stream can be any name, so is not important to use this schema, however this schema is useful if you use redis cluster.\n\n\nIndeed, both keys, the target stream \n{DB}:all_foo\n and the source database \nDB\n, need to be on the same redis cluster node. Since redis use the part of the key between curly bracket to decide in which node a key should resize, this schema allow us to make sure that this invariant is always respected.\n\n\nMoreover this schema is also quite nice, allowing with a glance to know what stream refer to what database. But again, it is not necessary at all.",
            "title": "Release 0.8.0"
        },
        {
            "location": "/blog/release_0.8.0/#release-080-of-redisql-sql-steroids-for-redis",
            "text": "RediSQL, Redis on SQL steroids.  RediSQL is a Redis module that provides full SQL capabilities to Redis, it is the simplest and fastest way to get an SQL database up and running, without incurring in difficult operational issues and it can scale quite well with your business.  The fastest introduction to RediSQL is  our homepage  tl;dr  This release introduce two new commands  REDISQL.QUERY.INTO[.NOW]  and  REDISQL.QUERY_STATEMENT.INTO[.NOW] . \nThe new commands behave similary to  REDISQL.QUERY  and  REDISQL.QUERY_STATEMENT  but they  XADD  the results to a  Redis Stream  passed as first argument.",
            "title": "Release 0.8.0 of RediSQL, SQL steroids for Redis"
        },
        {
            "location": "/blog/release_0.8.0/#motivation",
            "text": "Being able to write the result of a query into a stream opens several possibilities.\nFirst off all allow to easily cache the result of expensive queries.\nThen, it separate the creation of a result with its consuption which is a very important step forward especially for big results.  Indeed, while the computation of a query is not done by the main redis thread but it is off-load to another thread to allow redis to keep serving the client. Returning the result must be done in the main Redis thread. \nHence a long result can take a lot of time to be returned to the client and in that time Redis cannot serve other requests.\nWriting the result into a stream make it much more efficient use of the main Redis thread time.  Moreover, on the other side of the network, a small consumer might not expect a big result and could be overlwhelmed by the size.  In standard databases this problem is usually solved using cursors, however Redis itself does not provide this facility.\nRedis provide lists, but they are simply flat list and can store only strings, it would be complex to create the cursors on top of them.  The streams however are a better fit. While also them can store only strings, they store them into entries, which are small key-values objects.\nEach entry represent a row of our result set.\nWhere we encode the column name and type into the key, and we use the value field to store the actual value of the column.  An example will be easier to follow.",
            "title": "Motivation"
        },
        {
            "location": "/blog/release_0.8.0/#how-to-use",
            "text": "An example of  REDISQL.QUERY.INTO  is the following:  REDISQL.QUERY.INTO result_stream DB \"SELECT foo, bar FROM baz WHERE n > 42\"  The command will execute the query  SELECT foo, bar FROM baz WHERE n > 42  agains the database  DB  and it will  XADD  each row of the result to the stream  result_stream .  If the result is empty, the command will return  [\"DONE\", 0]  to the Redis client.  If the result is not empty, the command will return, to the Redis client, the name of the stream used (hence  result_stream  in this example) along with the first ID added and the last ID added and the size of the cursor (the number of entries added to the stream.)  In the following example we start by creating a database, then we create a new table  foo  in the database, and we store 4 rows into the table.  Then we use the new  REDISQL.QUERY.NOW  command to store the result of the query  SELECT * FROM foo  agains the database  DB  in the stream  {DB}:all_foo .  127.0.0.1:6379> REDISQL.CREATE_DB DB\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"CREATE TABLE foo(a int, b int);\"\n1) DONE\n2) (integer) 0\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO foo(a) VALUES(1)\"\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO foo VALUES(3, 4)\"\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO foo VALUES(5, 6)\"\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO foo VALUES(10, 19)\"\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.QUERY.INTO {DB}:all_foo DB \"SELECT * FROM foo\"\n1) 1) \"{DB}:all_foo\"\n   2) \"1549811093979-0\"\n   3) \"1549811093979-3\"\n   4) (integer) 4\n127.0.0.1:6379> XRANGE {DB}:all_foo - +\n1) 1) \"1549811093979-0\"\n   2) 1) \"int:a\"\n      2) \"1\"\n      3) \"null:b\"\n      4) \"(null)\"\n2) 1) \"1549811093979-1\"\n   2) 1) \"int:a\"\n      2) \"3\"\n      3) \"int:b\"\n      4) \"4\"\n3) 1) \"1549811093979-2\"\n   2) 1) \"int:a\"\n      2) \"5\"\n      3) \"int:b\"\n      4) \"6\"\n4) 1) \"1549811093979-3\"\n   2) 1) \"int:a\"\n      2) \"10\"\n      3) \"int:b\"\n      4) \"19\"  The first thing to notice is that the stream entity contains both the type of the column and it's name as well. The format is  $column_type:$column_name . This is necessary because stream support only strings.  In the example above the string  int:a  means that, for this row, the column  a  is of type  int . Usually the type of a column is constant, however, it may be null, in that case it would be something like:  null:b .  Another interesting thing to notice is the name of the stream used which can look peculiar. Indeed it is the same name of the database  DB , between curly braces  {DB}  and then a useful identifier  {DB}:all_foo . The name of the stream can be any name, so is not important to use this schema, however this schema is useful if you use redis cluster.  Indeed, both keys, the target stream  {DB}:all_foo  and the source database  DB , need to be on the same redis cluster node. Since redis use the part of the key between curly bracket to decide in which node a key should resize, this schema allow us to make sure that this invariant is always respected.  Moreover this schema is also quite nice, allowing with a glance to know what stream refer to what database. But again, it is not necessary at all.",
            "title": "How to use"
        },
        {
            "location": "/blog/release_0.7.0/",
            "text": "Release 0.7.0 of RediSQL, SQL steroids for Redis\n\n\nRediSQL, Redis on SQL steroids.\n\n\nRediSQL is a Redis module that provides full SQL capabilities to Redis, it is the simplest and fastest way to get an SQL database up and running, without incurring in difficult operational issues and it can scale quite well with your business.\n\n\nThe fastest introduction to RediSQL is \nour homepage\n\n\ntl;dr\n This release introduce a new commands \nREDISQL.COPY\n that copy the content from a source database into a destination database.\n\n\nMotivations\n\n\nSince from the very first release and the very first user, we have been asked a lot about the possibility to copy SQLite database into disk or into memory.\n\n\nIt is definitely an useful feature, suppose to already have the database and you simply want to make it available to some of your services.\n\n\nWe wait a bit before to incorporate on RediSQL such capabilities, mostly because we weren\u2019t sure about the API to offer.\n\n\nFinally we decide to pull the trigger and we implemented a new command \nREDISQL.COPY\n.\n\n\nThe \nREDISQL.COPY\n command takes two parameters as input, a \nsource\n database and a \ndestination\n database and it overwrite the content of the \nsource\n database into the \ndestination\n database.\n\n\nIt is important to understand that the content of the destination database is completely lost after a \nREDISQL.COPY\n\n\nThe \nREDISQL.COPY\n command takes as input two databases, both of them must be created using the \nREDISQL.CREATE_DB\n command. \nThis API allows several use cases that are quite interesting.\n\n\n\n\nMake a backup/copy of your database\n\n\nSplit load to multiple threads\n\n\nMove a database from a in-memory database to a disk-based database\n\n\nMove a database from  a disk-based database to a in-memory database\n\n\n\n\nFew Examples\n\n\nI will show briefly some examples of those use cases.\n\n\nMaking a backup/copy \n\n\nBackups are already provided by the internal of Redis itself, all the database will be copied into the RDB files.\nHowever you may be interested in having just a copy of your database, so that you can archive it in a different way, or just explore it offline.\n\n\nSuppose you have your database \nDB\n running with some table and some data:\n\n\n> REDISQL.CREATE_DB DB\nOK\n> REDISQL.EXEC DB \"CREATE TABLE foo( ... )\"\nDONE\n0L\n> REDISQL.EXEC DB \"INSERT INTO foo VALUES ( ... )\"\nDONE\n1L\n\n\n\nNow you will like to transfer that same database into a file, so that you can archive it or analyze it.\n\n\nThe first step would be to create another database backed by a file.\n\n\n> REDISQL.CREATE_DB BACKUP \"/home/foo/backup.sqlite\"\nOK\n\n\n\nIn this way we have created a new, empty database that is backed by a file.\n\n\nYou will see the small file \nhome/foo/backup.sqlite\n\n\nAt this point you just need to make a copy of it.\n\n\n> REDISQL.COPY DB BACKUP\nOK\n\n\n\nNow the file \n/home/foo/backup.sqlite\n will contains all the data that were originally on the \nDB\n database.\n\n\nLoad a database\n\n\nNow, suppose that the data you want to serve via RediSQL are already inside a SQLite database, or suppose that you are recovering from a previous backup. However you would like to have the database in memory, since we know the load will be quite high.\n\n\nAssuming  your database is stored into \n/home/foo/recover.sqlite\n we start by loading it, and then move it into an in-memory database, and finally we can also delete the database we used for recovering.\n\n\n> REDISQL.CREATE_DB TO_RECOVER \"/home/foo/recover.sqlite\"\nOK\n> REDISQL.CREATE_DB DB\nOK\n> REDISQL.COPY TO_RECOVER DB\nOK\n> DEL TO_RECOVER\nOK\n\n\n\nAt this point we have only one database \nDB\n that is an in-memory one and we have used the \nTO_RECOVER\n database to load the recovering file.\n\n\nSpread load\n\n\nAnother quite interesting use case is about load spreading.\n\n\nSuppose to have a read-only database \nDB1\n that makes quite complex and long queries, if that start to be a problem we could spread the load into two identical databases.\n\n\n> REDISQL.CREATE_DB DB2\nOK\n> REDISQL.COPY DB1 DB2\nOK\n\n\n\nNow we have the same dataset in two different database, each one of them with its own thread of execution. This will allow us to round robin between the two databases and achieve smaller latencies.\n\n\nEnd\n\n\nWith this post we showed the newest features of RediSQL.\n\n\nThe product start to be quite stable, more performance test will come in the next release but we don\u2019t plan to touch the API.\n\n\nIf we don\u2019t change the API the next release will be the v1.0.0\n\n\nAs always you can find all the public releases on the \ngithub page\n, you can openly access the same public release on the \nopen page of our shop\n or you can buy the complete PRO package \nsigning up in the shop\n.\n\n\nRemember that signing up for the PRO product also provide you free support from us, the creator of the project, so that we can point you to the right direction and suggest the best use cases for our product.",
            "title": "Release 0.7.0"
        },
        {
            "location": "/blog/release_0.7.0/#release-070-of-redisql-sql-steroids-for-redis",
            "text": "RediSQL, Redis on SQL steroids.  RediSQL is a Redis module that provides full SQL capabilities to Redis, it is the simplest and fastest way to get an SQL database up and running, without incurring in difficult operational issues and it can scale quite well with your business.  The fastest introduction to RediSQL is  our homepage  tl;dr  This release introduce a new commands  REDISQL.COPY  that copy the content from a source database into a destination database.",
            "title": "Release 0.7.0 of RediSQL, SQL steroids for Redis"
        },
        {
            "location": "/blog/release_0.7.0/#motivations",
            "text": "Since from the very first release and the very first user, we have been asked a lot about the possibility to copy SQLite database into disk or into memory.  It is definitely an useful feature, suppose to already have the database and you simply want to make it available to some of your services.  We wait a bit before to incorporate on RediSQL such capabilities, mostly because we weren\u2019t sure about the API to offer.  Finally we decide to pull the trigger and we implemented a new command  REDISQL.COPY .  The  REDISQL.COPY  command takes two parameters as input, a  source  database and a  destination  database and it overwrite the content of the  source  database into the  destination  database.  It is important to understand that the content of the destination database is completely lost after a  REDISQL.COPY  The  REDISQL.COPY  command takes as input two databases, both of them must be created using the  REDISQL.CREATE_DB  command. \nThis API allows several use cases that are quite interesting.   Make a backup/copy of your database  Split load to multiple threads  Move a database from a in-memory database to a disk-based database  Move a database from  a disk-based database to a in-memory database   Few Examples  I will show briefly some examples of those use cases.  Making a backup/copy   Backups are already provided by the internal of Redis itself, all the database will be copied into the RDB files.\nHowever you may be interested in having just a copy of your database, so that you can archive it in a different way, or just explore it offline.  Suppose you have your database  DB  running with some table and some data:  > REDISQL.CREATE_DB DB\nOK\n> REDISQL.EXEC DB \"CREATE TABLE foo( ... )\"\nDONE\n0L\n> REDISQL.EXEC DB \"INSERT INTO foo VALUES ( ... )\"\nDONE\n1L  Now you will like to transfer that same database into a file, so that you can archive it or analyze it.  The first step would be to create another database backed by a file.  > REDISQL.CREATE_DB BACKUP \"/home/foo/backup.sqlite\"\nOK  In this way we have created a new, empty database that is backed by a file.  You will see the small file  home/foo/backup.sqlite  At this point you just need to make a copy of it.  > REDISQL.COPY DB BACKUP\nOK  Now the file  /home/foo/backup.sqlite  will contains all the data that were originally on the  DB  database.  Load a database  Now, suppose that the data you want to serve via RediSQL are already inside a SQLite database, or suppose that you are recovering from a previous backup. However you would like to have the database in memory, since we know the load will be quite high.  Assuming  your database is stored into  /home/foo/recover.sqlite  we start by loading it, and then move it into an in-memory database, and finally we can also delete the database we used for recovering.  > REDISQL.CREATE_DB TO_RECOVER \"/home/foo/recover.sqlite\"\nOK\n> REDISQL.CREATE_DB DB\nOK\n> REDISQL.COPY TO_RECOVER DB\nOK\n> DEL TO_RECOVER\nOK  At this point we have only one database  DB  that is an in-memory one and we have used the  TO_RECOVER  database to load the recovering file.  Spread load  Another quite interesting use case is about load spreading.  Suppose to have a read-only database  DB1  that makes quite complex and long queries, if that start to be a problem we could spread the load into two identical databases.  > REDISQL.CREATE_DB DB2\nOK\n> REDISQL.COPY DB1 DB2\nOK  Now we have the same dataset in two different database, each one of them with its own thread of execution. This will allow us to round robin between the two databases and achieve smaller latencies.",
            "title": "Motivations"
        },
        {
            "location": "/blog/release_0.7.0/#end",
            "text": "With this post we showed the newest features of RediSQL.  The product start to be quite stable, more performance test will come in the next release but we don\u2019t plan to touch the API.  If we don\u2019t change the API the next release will be the v1.0.0  As always you can find all the public releases on the  github page , you can openly access the same public release on the  open page of our shop  or you can buy the complete PRO package  signing up in the shop .  Remember that signing up for the PRO product also provide you free support from us, the creator of the project, so that we can point you to the right direction and suggest the best use cases for our product.",
            "title": "End"
        },
        {
            "location": "/blog/release_0.6.0/",
            "text": "Release 0.6.0 of RediSQL, SQL steroids for Redis\n\n\nRediSQL, Redis on SQL steroids.\n\n\nRediSQL is a Redis module that provides full SQL capabilities to Redis, it is the simplest and fastest way to get an SQL database up and running, without incurring in difficult operational issues and it can scale quite well with your business.\n\n\nThe fastest introduction to RediSQL is \nour homepage\n\n\ntl;dr\n This release does not introduce new commands, but it provides a SQLite virtual table implementation that allows making SQL queries against Redis Hashes.\nThe release is important because set the foundation to write more complex commands or SQLite functions.\nPossible ideas could be SQLite functions that append to a list or to a stream, these functions could be used inside triggers to generate an event log of all the operation that happened to a particular table.\n\n\nVirtual Table\n\n\nInside RediSQL is now possible to use the virtual table: \nREDISQL_TABLES_BRUTE_HASH\n.\n\n\nThis virtual table allows to only query Redis hashes that follow a common structure.\n\n\nThe understood structure is:\n\n\nHSET $tableName:$id $col1 $val1 $col2 $val2 ... $colN $valN\n\n\n\n\nWhere the \n$col\ns are constant in the hashes and, of course, the \n$val\ns change from row to row.\n\n\nIn order to create a \nREDISQL_TABLES_BRUTE_HASH\n the syntax is the following:\n\n\nCREATE VIRTUAL TABLE funny_cats USING REDISQL_TABLES_BRUTE_HASH($tableName, $col1, $col2, ..., $colN);\n\n\n\n\nPlease note that the first parameter of the virtual table is not, as we could expect, the first column of the table, but is the name of hashes that we want to use as table, of course without specifying any \n$id\n.\n\n\nAlso note that is pointless to provide a type to the columns since Redis does store only strings inside the hashes, hence you will get only strings from the virtual table as well.\n\n\nWhat you can do to get numbers, integer or floats, is to exploit the \nCAST\n capabilities of SQLite.\n\n\nYou can find examples of this feature in \nthe documentation.\n\n\nLet me make clear that this virtual table does \nnot\n implements updates, inserts or deletes, at the moment you can only query this type of virtual tables.\n\n\nThe implementation of update and inserts and deletes should not pose significant challenges.\n\n\nImportance of this release\n\n\nThis release is extremely important for architectural reasons inside the module itself.\n\n\nIn order to implement the above virtual table was necessary to keep a pointer to an internal structure of Redis that actually allow calling any Redis command from inside a module.\n\n\nIncluding this pointer into the RediSQL structures make possible to call arbitrary Redis commands.\n\n\nThis opens the gate to quite interesting features, as an example, imagine to be able to call \nLPUSH\n or \nXADD\n inside a trigger.\n\n\nThis will allow to log every operation you are doing against your dataset. You could replay them later in a different instance of RediSQL or maybe also against a different database.\n\n\nYou could write all you operation very fast in memory using RediSQL and when you have enough of them write them to disk against PostgreSQL, MySQL or any other database.\n\n\nEnd\n\n\nAs always you can find all the public releases on the \ngithub page\n, you can openly access the same public release on the \nopen page of our shop\n or you can buy the complete PRO package \nsigning up in the shop\n.\n\n\nRemember that signing up for the PRO product also provide you free support from us, the creator of the project, so that we can point you to the right direction and suggest the best use cases for our product.",
            "title": "Release 0.6.0"
        },
        {
            "location": "/blog/release_0.6.0/#release-060-of-redisql-sql-steroids-for-redis",
            "text": "RediSQL, Redis on SQL steroids.  RediSQL is a Redis module that provides full SQL capabilities to Redis, it is the simplest and fastest way to get an SQL database up and running, without incurring in difficult operational issues and it can scale quite well with your business.  The fastest introduction to RediSQL is  our homepage  tl;dr  This release does not introduce new commands, but it provides a SQLite virtual table implementation that allows making SQL queries against Redis Hashes.\nThe release is important because set the foundation to write more complex commands or SQLite functions.\nPossible ideas could be SQLite functions that append to a list or to a stream, these functions could be used inside triggers to generate an event log of all the operation that happened to a particular table.",
            "title": "Release 0.6.0 of RediSQL, SQL steroids for Redis"
        },
        {
            "location": "/blog/release_0.6.0/#virtual-table",
            "text": "Inside RediSQL is now possible to use the virtual table:  REDISQL_TABLES_BRUTE_HASH .  This virtual table allows to only query Redis hashes that follow a common structure.  The understood structure is:  HSET $tableName:$id $col1 $val1 $col2 $val2 ... $colN $valN  Where the  $col s are constant in the hashes and, of course, the  $val s change from row to row.  In order to create a  REDISQL_TABLES_BRUTE_HASH  the syntax is the following:  CREATE VIRTUAL TABLE funny_cats USING REDISQL_TABLES_BRUTE_HASH($tableName, $col1, $col2, ..., $colN);  Please note that the first parameter of the virtual table is not, as we could expect, the first column of the table, but is the name of hashes that we want to use as table, of course without specifying any  $id .  Also note that is pointless to provide a type to the columns since Redis does store only strings inside the hashes, hence you will get only strings from the virtual table as well.  What you can do to get numbers, integer or floats, is to exploit the  CAST  capabilities of SQLite.  You can find examples of this feature in  the documentation.  Let me make clear that this virtual table does  not  implements updates, inserts or deletes, at the moment you can only query this type of virtual tables.  The implementation of update and inserts and deletes should not pose significant challenges.",
            "title": "Virtual Table"
        },
        {
            "location": "/blog/release_0.6.0/#importance-of-this-release",
            "text": "This release is extremely important for architectural reasons inside the module itself.  In order to implement the above virtual table was necessary to keep a pointer to an internal structure of Redis that actually allow calling any Redis command from inside a module.  Including this pointer into the RediSQL structures make possible to call arbitrary Redis commands.  This opens the gate to quite interesting features, as an example, imagine to be able to call  LPUSH  or  XADD  inside a trigger.  This will allow to log every operation you are doing against your dataset. You could replay them later in a different instance of RediSQL or maybe also against a different database.  You could write all you operation very fast in memory using RediSQL and when you have enough of them write them to disk against PostgreSQL, MySQL or any other database.",
            "title": "Importance of this release"
        },
        {
            "location": "/blog/release_0.6.0/#end",
            "text": "As always you can find all the public releases on the  github page , you can openly access the same public release on the  open page of our shop  or you can buy the complete PRO package  signing up in the shop .  Remember that signing up for the PRO product also provide you free support from us, the creator of the project, so that we can point you to the right direction and suggest the best use cases for our product.",
            "title": "End"
        },
        {
            "location": "/blog/release_0.5.0/",
            "text": "Release 0.5.0 of RediSQL, SQL steroids for Redis\n\n\nRediSQL, Redis on SQL steroids.\n\n\nRediSQL is a Redis module that provides full SQL capabilities to Redis, it is the simplest and fastest way to get an SQL database up and running, without incurring in difficult operational issues and it can scale quite well with your business.\n\n\nThe fastest introduction to RediSQL is \nour homepage\n\n\ntl;dr;\n This release does not introduce any new features but it does improve the performances significantly. \nMoreover, we are releasing for multiple platforms, notably for ARMv7 (Rasberry PI), for CentOS7 (Linux AMI on AWS) and of course for Linux generic. \nFinally, we introduce also the TRIAL executable which can be freely downloaded and used, it provides all the functionality of the PRO version but it is limited for evaluation purposes, after ~2 hours it will shut down itself.\n\n\nPerformance Improvement ~20%\n\n\nWe are registering an improvement in performance of roughly 20% with a similar load.\n\n\nOf course, performance inside an SQL database varies a lot depending on the query you are executing.\n\n\nIn our evaluation, we are focusing on a simple query that inserts or updates values in the database.\n\n\nWe decided to focus on \ninsert\ns because is the simplest write operation, hence it cannot be distributed to different instances, and the performance of the single instance will limit the performance of the overall system.\n\n\nHowever, \ninsert\n operations, need to allocate new memory, the allocator used by SQLite is very efficient but we still wanted to see what would happen without the need of allocation, hence we tested also \nupdate\ns\n\n\nWe are seeing an improvement of roughly the 20% in \ninsert\n/\nupsert\n throughput.\n\n\nThe increase in throughput is driven by the switch to a zero-copy architecture.\n\n\nIn Rust, the language in which RediSQL is written is usual to start dealing with lifetime issues simply by copying memory, this, of course, comes with a penalty in performances.\n\n\nHowever, as long as this performance penalty is not an issue is better to just leave as it is and work on the more important parts of the project.\nFor one of our user it was a problem and so we decide to fix it by bringing performance improvements to all. \nMore about this story here.\n\n\nReleases\n\n\nRust produce in general static linked objects, so everything you need is already inside your object and you do not depends on any external library that must be installed in your host system.\n\n\nThis has several advantages, as long as the architecture of your host is the correct one your executable will most likely run.\n\n\nThere is an exception to that, \nlibc\n given its ubiquity and size is compiled dynamically, so your object will need it to be present in your host machine. Which usually is not an issue.\n\n\nUnfortunately is some machine \nlibc\n is present in an older version that the one we are expecting, so the module will not be able to run.\n\n\nVery old systems have this issues as well as CentOS 7 and the Linux AMI on AWS.\n\n\nUnfortunately, cross-compile for a different version of glibc is not as simple as it may seem, but we finally manage :)\n\n\nTrial\n\n\nFinally, we decide to provide open access to the PRO version for evaluation purposes.\n\n\nHence we created a third release that is called TRIAL.\n\n\nThe releases are exactly the same as the PRO one, except that it shuts itself down after ~2 hours.\n\n\nIt is supposed to let you test the PRO version before to commit to buy it, still, you have 14 days of money back guarantee if you don't like the product.\n\n\nClearly, the TRIAL version is not supposed to be used in production.\n\n\nEnd\n\n\nAs always you can find all the public releases on the \ngithub page\n, you can openly access the same public release on the \nopen page of our shop\n or you can buy the complete PRO package \nsigning up in the shop\n.\n\n\nRemember that signing up for the PRO product also provide you free support from us, the creator of the project, so that we can point you to the right direction and suggest the best use cases for our product.",
            "title": "Release 0.5.0"
        },
        {
            "location": "/blog/release_0.5.0/#release-050-of-redisql-sql-steroids-for-redis",
            "text": "RediSQL, Redis on SQL steroids.  RediSQL is a Redis module that provides full SQL capabilities to Redis, it is the simplest and fastest way to get an SQL database up and running, without incurring in difficult operational issues and it can scale quite well with your business.  The fastest introduction to RediSQL is  our homepage  tl;dr;  This release does not introduce any new features but it does improve the performances significantly. \nMoreover, we are releasing for multiple platforms, notably for ARMv7 (Rasberry PI), for CentOS7 (Linux AMI on AWS) and of course for Linux generic. \nFinally, we introduce also the TRIAL executable which can be freely downloaded and used, it provides all the functionality of the PRO version but it is limited for evaluation purposes, after ~2 hours it will shut down itself.",
            "title": "Release 0.5.0 of RediSQL, SQL steroids for Redis"
        },
        {
            "location": "/blog/release_0.5.0/#performance-improvement-20",
            "text": "We are registering an improvement in performance of roughly 20% with a similar load.  Of course, performance inside an SQL database varies a lot depending on the query you are executing.  In our evaluation, we are focusing on a simple query that inserts or updates values in the database.  We decided to focus on  insert s because is the simplest write operation, hence it cannot be distributed to different instances, and the performance of the single instance will limit the performance of the overall system.  However,  insert  operations, need to allocate new memory, the allocator used by SQLite is very efficient but we still wanted to see what would happen without the need of allocation, hence we tested also  update s  We are seeing an improvement of roughly the 20% in  insert / upsert  throughput.  The increase in throughput is driven by the switch to a zero-copy architecture.  In Rust, the language in which RediSQL is written is usual to start dealing with lifetime issues simply by copying memory, this, of course, comes with a penalty in performances.  However, as long as this performance penalty is not an issue is better to just leave as it is and work on the more important parts of the project.\nFor one of our user it was a problem and so we decide to fix it by bringing performance improvements to all.  More about this story here.",
            "title": "Performance Improvement ~20%"
        },
        {
            "location": "/blog/release_0.5.0/#releases",
            "text": "Rust produce in general static linked objects, so everything you need is already inside your object and you do not depends on any external library that must be installed in your host system.  This has several advantages, as long as the architecture of your host is the correct one your executable will most likely run.  There is an exception to that,  libc  given its ubiquity and size is compiled dynamically, so your object will need it to be present in your host machine. Which usually is not an issue.  Unfortunately is some machine  libc  is present in an older version that the one we are expecting, so the module will not be able to run.  Very old systems have this issues as well as CentOS 7 and the Linux AMI on AWS.  Unfortunately, cross-compile for a different version of glibc is not as simple as it may seem, but we finally manage :)",
            "title": "Releases"
        },
        {
            "location": "/blog/release_0.5.0/#trial",
            "text": "Finally, we decide to provide open access to the PRO version for evaluation purposes.  Hence we created a third release that is called TRIAL.  The releases are exactly the same as the PRO one, except that it shuts itself down after ~2 hours.  It is supposed to let you test the PRO version before to commit to buy it, still, you have 14 days of money back guarantee if you don't like the product.  Clearly, the TRIAL version is not supposed to be used in production.",
            "title": "Trial"
        },
        {
            "location": "/blog/release_0.5.0/#end",
            "text": "As always you can find all the public releases on the  github page , you can openly access the same public release on the  open page of our shop  or you can buy the complete PRO package  signing up in the shop .  Remember that signing up for the PRO product also provide you free support from us, the creator of the project, so that we can point you to the right direction and suggest the best use cases for our product.",
            "title": "End"
        },
        {
            "location": "/blog/analytics/",
            "text": "RediSQL for analytics\n\n\nRediSQL is a module for Redis that embed a completely functional SQLite database. \n\n\nRediSQL enables new paradigm where is possible to have several smaller decentralized databases instead of a single giant one.\n\n\nIn this blog post, we are going to explore how RediSQL can be used for storing analytics data.\n\n\nRedis is always been used for storing fast data and so it is an extremely interesting software for analytics solution.\n\n\nWe are now going to describe the problem, explore some data structures that may help and finally sketch a possible solution using RediSQL.\n\n\nAt the end of the article, there is actual python code that you can run.\n\n\nProblem\n\n\nSuppose you are interested in following the user around your website, and you will like to know what buttons they click, what events they trigger, what form the focus on and so on and so forth.\n\n\nAll these events are quite simple to catch using javascript and client-side code, but then you need to store them in your database to analyze them further and extract new information and value for your business.\n\n\nHowever, you would prefer to avoid to put too much pressure on your main database that is already busy storing all the essential information for the business.\n\n\nData Structure\n\n\nOne of the advantages of using SQL is the possibility to use and declare the shape of your data.\n\n\nFor this specific problem, our data are quite simple.\nWe want to store a user identifier (it may be its alias, nickname, ID in the main database or even something else), the IP address of the user, the timestamp when the event was triggered and finally the event itself.\n\n\nWe are going to represent the identifier, the IP address and the timestamp as strings.\nYes, unfortunately, SQLite does not provide a time type, to use a string is quite a reasonable choice, another one could be to use integers and to save the timestamp as Unix epoch of the event.\n\n\nEvents\n\n\nRepresenting the events may be a little complex and it really depends on your use case.\nSuppose you are just listening to specific events like \"Sales\", \"Register\", \"Login\" or \"Submit form\" you could simply store them as strings.\n\n\nHowever you can be a little more sophisticated as well, and associate to every Sales some other data like \"amount\", \"shipping cost\" or \"total elements sold\" or again improve the \"Submit form\" with information about the web page, like the URL of the page or if it was the A or the B version of your A/B test. And so on and so forth.\n\n\nJSON or Tables\n\n\nIf your events are quite static and you already know what you are going to store the best approach is to use tables.\n\n\nAn idea could be to use this representation for the table \nEvents\n:\n\n\n| event_id | user_id | ip_address | timestamp |\n|----------|---------|------------|-----------|\n\n\n\n\nAnd then different tables for each type of events, like:\n\n\nSales\n:\n\n\n| event_id | amount  | shipping_cost | total_elements_sold |\n|----------|---------|---------------|---------------------|\n\n\n\n\nSubmits\n:\n\n\n| event_id | url_page | A/B_version |\n|----------|----------|-------------|\n\n\n\n\nWhere \nevent_id\n is a Primary key to the table \nEvents\n and a Foreign key on the table \nSales\n and \nSubmits\n.\n\n\nThis approach works really well, the shape of your data will be always known and it will be fast, however, you actually need to know what you are saving in your DB and change the structure of the table is quite complex.\n\n\nA different approach will be to store directly JSON in your table.\n\n\nThe new schema will be only a single table, \nEvents\n:\n\n\n| event_id | user_id | ip_address | timestamp | data |\n|----------|---------|------------|-----------|------|\n\n\n\n\nThe column data will be of type \ntext\n and it will store anything you want if encoded in JSON.\n\n\nOf course, it is also possible to run any kind of computation on the JSON data including filters and selection.\n\n\nUsing JSON you gain a lot of flexibility but you are not sure anymore of the shape of your data and if you are not careful it may cause some headaches.\n\n\nSolution Sketch\n\n\nIn this section we are going to get through a possible implementation of the above solution, we are going to use the JSON variant since I believe that not everybody knew that SQLite could handle JSON so well.\n\n\nI am assuming you already know how to get a Redis instance and how to load a module into it, if not make sure to check out \nthe readme of the project\n\n\nWe are going to automate as much as possible in this tutorial, in this way your analytic script will just run.\n\n\nThe very first thing to do is to get a working connection to your Redis instance, any Redis binding should make this process quite simple, here an example in python.\n\n\nimport redis\nr = redis.StrictRedis(host='localhost', port=6379, db=0)\n\n\n\n\nNow that you have established a connection the next step is to create a RediSQL database, RediSQL can manage multiple, completely independent databases, each associated with a Redis key, for this simple example we are going to use only one database that, with a lot of fantasy, \nDB\n.\n\n\nok = r.execute_command(\"REDISQL.CREATE_DB\", \"DB\")\nassert ok == \"OK\"\n\n\n\n\nNow that we have created our database we can go ahead and create the table that will contain our data. We are going to create the table if and only if it does not exists yet.\n\n\ndone = r.execute_command(\"REDISQL.EXEC\", \"DB\", \n                         \"\"\"CREATE TABLE\n                            IF NOT EXISTS \n                            Events(\n                                event_id INTEGER PRIMARY KEY,\n                                user_id STRING,\n                                ip_address STRING,\n                                timestamp STRING,\n                                data JSON\n                            );\"\"\")\nassert done == [\"DONE\", 0]\n\n\n\n\nSetting the type of \nevent_id\n as \nINTEGER PRIMARY KEY\n is synonymous with \nROWID\n which is an autoincrement fields that do not need to be set during insert.\n\n\nAt this point, the only thing left to do is to listen for events in your code and write them into the database.\n\n\nThe simplest, and insecure, way to write the data is to use the \nEXEC\n function like so:\n\n\n# import datetime\nuser_id = \"user_1234\"\nip_address = \"a.simple.ip.address\"\nnow = datetime.datetime.now()\ndata = {\"type\" : \"sales\", \"total\": 1999, \"shipping_address\" : \"...\"}\nstatement = \"\"\"INSERT INTO Events (user_id, ip_address, timestamp, data) \n               VALUES(\\\"{}\\\", \\\"{}\\\", \\\"{}\\\", \\\"{}\\\")\"\"\" \\\n               .format(user_id, ip_address, now, data)\ndone = r.execute_command(\"REDISQL.EXEC\", \"DB\", statement)\nassert done == [\"DONE\", 1]\n\n\n\n\nAs you may have guessed already the return value of \nREDISQL.EXEC\n is a list of two elements, the string \nDONE\n and the integer representing the number of rows modified (inserted, deleted or updated).\n\n\nHowever, this way of inserting data into the database is not optimal, especially if the same operation will be performed several times. And also because it is vulnerable to SQL injections attacks.\n\n\nThe better and safer way to do this kind of operation is to define \nstatements\n.\n\n\nok = r.execute_command(\"REDISQL.CREATE_STATEMENT\", \"DB\", \"insert_event\",\n                       \"\"\"INSERT INTO Events \n                          (user_id, ip_address, timestamp, data) \n                          VALUES(?1, ?2, ?3, ?4)\"\"\")\nassert ok == \"OK\"\n\n\n\n\nOnce a statement is defined you can execute it using the following commands.\n\n\n# import datetime\nuser_id = \"user_1234\"\nip_address = \"a.simple.ip.address\"\nnow = datetime.datetime.now()\ndata = {\"type\" : \"sales\", \"total\": 1999, \"shipping_address\" : \"...\"}\ndone = r.execute_command(\"REDISQL.EXEC_STATEMENT\", \"DB\", \"insert_event\", user_id, ip_address, now, data)\nassert done == [\"DONE\", 1]\n\n\n\n\nThe use of statements brings some benefits.\n\n\n\n\nIt reduces code deduplication in your code base\n\n\nIt puts a name on a particular procedure, decoupling the implementation and the goal\n\n\nIt allows different microservices to invoke the always the exact same procedure\n\n\nIt is faster to execute\n\n\n\n\nUse the JSON1 SQLite module\n\n\nNow that we have covered how to execute SQL against RediSQL let me quickly introduce you to the JSON1 syntax provide by SQLite.\n\n\nThe ones that follow are plain SQL statements that you can execute \nREDISQL.EXEC\n against the database or that you can embed into a statement.\n\n\nThe most interesting function provide is \njson_extract\n.\n\n\nSELECT user_id, json_extract(data, '$.total')\nFROM Events\nWHERE json_extract(data, '$.type') = \"sales\";\n\n\n\n\nThis query will look inside the field \ntype\n of the JSON stored into the columns \ndata\n if this fields contains the string \"sales\" it will return the user who bought something and total of the sale. \n\n\njson_extract\n works also on array using a simple syntax: \n$.array[2]\n (eg. extract the third element of the array)\n\n\nMove the data\n\n\nRunning the above script will be extremely fast, I am talking about 10ks inserts per second fast.\n\n\nHowever, it is so fast for a variety of reason but maybe the most important is that it keeps all the data in memory and does not write them on disk.\n\n\nThis can be just fine for some application (think about storing data that become useless in few days time) or it can be a big issue for some other use case, luckily there is a very simple solution.\n\n\nThe simplest thing to do when you decide to dump the data in your persistent storage is just to query them all and push them, in batch, to your persistent system. Moving the data in all together will allow having an extremely high throughput and it will take a fraction of the time than if you moved just a row at the time.\n\n\nA quite simple practice is to simply dump all the content of your database in a CSV file and then let your RDBMS load it.\n\n\nThis operation is quite simple and it can be done like so.\n\n\n# get the data\nvalues = r.execute_command(\"REDISQL.EXEC\", \"DB\", \"SELECT * FROM Events;\")\n# iterate throught the list writing on file\nwith open('csv_file', 'w') as csv_file:\n    # write the csv header\n    csv_file.write(\"event_id,user_id,ip_address,timestamp,data\\n\")\n    for row in values:\n        # create a single string with all the fields separated by a comma\n        elements = \",\".join(row) + \"\\n\"\n        # write the result on the csv_file\n        csv_file.write(elements)\n\n\n\n\nNow you can use tools like PostgreSQL COPY to load all the data into your database.\n\n\nThis solution is not perfect and in a distributed setting with several concurrent workers it may result in some data duplication, however, we are getting ahead of ourselves and this topic will go far ahead of the scope of this post.\n\n\nRecap\n\n\nIn this blog post, we explored how to write a quite sophisticated analytics infrastructure using nothing more than RediSQL.\n\n\nAdding this tool to your existing infrastructure should be quite simple and painless while it provides a simple way to do powerful things in a fast and reliable way.\n\n\nIs worth to remember that RediSQL already provide RDB persistency so you already have some interesting level of safeness embed into this architecture.",
            "title": "Analytics"
        },
        {
            "location": "/blog/analytics/#redisql-for-analytics",
            "text": "RediSQL is a module for Redis that embed a completely functional SQLite database.   RediSQL enables new paradigm where is possible to have several smaller decentralized databases instead of a single giant one.  In this blog post, we are going to explore how RediSQL can be used for storing analytics data.  Redis is always been used for storing fast data and so it is an extremely interesting software for analytics solution.  We are now going to describe the problem, explore some data structures that may help and finally sketch a possible solution using RediSQL.  At the end of the article, there is actual python code that you can run.",
            "title": "RediSQL for analytics"
        },
        {
            "location": "/blog/analytics/#problem",
            "text": "Suppose you are interested in following the user around your website, and you will like to know what buttons they click, what events they trigger, what form the focus on and so on and so forth.  All these events are quite simple to catch using javascript and client-side code, but then you need to store them in your database to analyze them further and extract new information and value for your business.  However, you would prefer to avoid to put too much pressure on your main database that is already busy storing all the essential information for the business.",
            "title": "Problem"
        },
        {
            "location": "/blog/analytics/#data-structure",
            "text": "One of the advantages of using SQL is the possibility to use and declare the shape of your data.  For this specific problem, our data are quite simple.\nWe want to store a user identifier (it may be its alias, nickname, ID in the main database or even something else), the IP address of the user, the timestamp when the event was triggered and finally the event itself.  We are going to represent the identifier, the IP address and the timestamp as strings.\nYes, unfortunately, SQLite does not provide a time type, to use a string is quite a reasonable choice, another one could be to use integers and to save the timestamp as Unix epoch of the event.  Events  Representing the events may be a little complex and it really depends on your use case.\nSuppose you are just listening to specific events like \"Sales\", \"Register\", \"Login\" or \"Submit form\" you could simply store them as strings.  However you can be a little more sophisticated as well, and associate to every Sales some other data like \"amount\", \"shipping cost\" or \"total elements sold\" or again improve the \"Submit form\" with information about the web page, like the URL of the page or if it was the A or the B version of your A/B test. And so on and so forth.  JSON or Tables  If your events are quite static and you already know what you are going to store the best approach is to use tables.  An idea could be to use this representation for the table  Events :  | event_id | user_id | ip_address | timestamp |\n|----------|---------|------------|-----------|  And then different tables for each type of events, like:  Sales :  | event_id | amount  | shipping_cost | total_elements_sold |\n|----------|---------|---------------|---------------------|  Submits :  | event_id | url_page | A/B_version |\n|----------|----------|-------------|  Where  event_id  is a Primary key to the table  Events  and a Foreign key on the table  Sales  and  Submits .  This approach works really well, the shape of your data will be always known and it will be fast, however, you actually need to know what you are saving in your DB and change the structure of the table is quite complex.  A different approach will be to store directly JSON in your table.  The new schema will be only a single table,  Events :  | event_id | user_id | ip_address | timestamp | data |\n|----------|---------|------------|-----------|------|  The column data will be of type  text  and it will store anything you want if encoded in JSON.  Of course, it is also possible to run any kind of computation on the JSON data including filters and selection.  Using JSON you gain a lot of flexibility but you are not sure anymore of the shape of your data and if you are not careful it may cause some headaches.",
            "title": "Data Structure"
        },
        {
            "location": "/blog/analytics/#solution-sketch",
            "text": "In this section we are going to get through a possible implementation of the above solution, we are going to use the JSON variant since I believe that not everybody knew that SQLite could handle JSON so well.  I am assuming you already know how to get a Redis instance and how to load a module into it, if not make sure to check out  the readme of the project  We are going to automate as much as possible in this tutorial, in this way your analytic script will just run.  The very first thing to do is to get a working connection to your Redis instance, any Redis binding should make this process quite simple, here an example in python.  import redis\nr = redis.StrictRedis(host='localhost', port=6379, db=0)  Now that you have established a connection the next step is to create a RediSQL database, RediSQL can manage multiple, completely independent databases, each associated with a Redis key, for this simple example we are going to use only one database that, with a lot of fantasy,  DB .  ok = r.execute_command(\"REDISQL.CREATE_DB\", \"DB\")\nassert ok == \"OK\"  Now that we have created our database we can go ahead and create the table that will contain our data. We are going to create the table if and only if it does not exists yet.  done = r.execute_command(\"REDISQL.EXEC\", \"DB\", \n                         \"\"\"CREATE TABLE\n                            IF NOT EXISTS \n                            Events(\n                                event_id INTEGER PRIMARY KEY,\n                                user_id STRING,\n                                ip_address STRING,\n                                timestamp STRING,\n                                data JSON\n                            );\"\"\")\nassert done == [\"DONE\", 0]  Setting the type of  event_id  as  INTEGER PRIMARY KEY  is synonymous with  ROWID  which is an autoincrement fields that do not need to be set during insert.  At this point, the only thing left to do is to listen for events in your code and write them into the database.  The simplest, and insecure, way to write the data is to use the  EXEC  function like so:  # import datetime\nuser_id = \"user_1234\"\nip_address = \"a.simple.ip.address\"\nnow = datetime.datetime.now()\ndata = {\"type\" : \"sales\", \"total\": 1999, \"shipping_address\" : \"...\"}\nstatement = \"\"\"INSERT INTO Events (user_id, ip_address, timestamp, data) \n               VALUES(\\\"{}\\\", \\\"{}\\\", \\\"{}\\\", \\\"{}\\\")\"\"\" \\\n               .format(user_id, ip_address, now, data)\ndone = r.execute_command(\"REDISQL.EXEC\", \"DB\", statement)\nassert done == [\"DONE\", 1]  As you may have guessed already the return value of  REDISQL.EXEC  is a list of two elements, the string  DONE  and the integer representing the number of rows modified (inserted, deleted or updated).  However, this way of inserting data into the database is not optimal, especially if the same operation will be performed several times. And also because it is vulnerable to SQL injections attacks.  The better and safer way to do this kind of operation is to define  statements .  ok = r.execute_command(\"REDISQL.CREATE_STATEMENT\", \"DB\", \"insert_event\",\n                       \"\"\"INSERT INTO Events \n                          (user_id, ip_address, timestamp, data) \n                          VALUES(?1, ?2, ?3, ?4)\"\"\")\nassert ok == \"OK\"  Once a statement is defined you can execute it using the following commands.  # import datetime\nuser_id = \"user_1234\"\nip_address = \"a.simple.ip.address\"\nnow = datetime.datetime.now()\ndata = {\"type\" : \"sales\", \"total\": 1999, \"shipping_address\" : \"...\"}\ndone = r.execute_command(\"REDISQL.EXEC_STATEMENT\", \"DB\", \"insert_event\", user_id, ip_address, now, data)\nassert done == [\"DONE\", 1]  The use of statements brings some benefits.   It reduces code deduplication in your code base  It puts a name on a particular procedure, decoupling the implementation and the goal  It allows different microservices to invoke the always the exact same procedure  It is faster to execute   Use the JSON1 SQLite module  Now that we have covered how to execute SQL against RediSQL let me quickly introduce you to the JSON1 syntax provide by SQLite.  The ones that follow are plain SQL statements that you can execute  REDISQL.EXEC  against the database or that you can embed into a statement.  The most interesting function provide is  json_extract .  SELECT user_id, json_extract(data, '$.total')\nFROM Events\nWHERE json_extract(data, '$.type') = \"sales\";  This query will look inside the field  type  of the JSON stored into the columns  data  if this fields contains the string \"sales\" it will return the user who bought something and total of the sale.   json_extract  works also on array using a simple syntax:  $.array[2]  (eg. extract the third element of the array)",
            "title": "Solution Sketch"
        },
        {
            "location": "/blog/analytics/#move-the-data",
            "text": "Running the above script will be extremely fast, I am talking about 10ks inserts per second fast.  However, it is so fast for a variety of reason but maybe the most important is that it keeps all the data in memory and does not write them on disk.  This can be just fine for some application (think about storing data that become useless in few days time) or it can be a big issue for some other use case, luckily there is a very simple solution.  The simplest thing to do when you decide to dump the data in your persistent storage is just to query them all and push them, in batch, to your persistent system. Moving the data in all together will allow having an extremely high throughput and it will take a fraction of the time than if you moved just a row at the time.  A quite simple practice is to simply dump all the content of your database in a CSV file and then let your RDBMS load it.  This operation is quite simple and it can be done like so.  # get the data\nvalues = r.execute_command(\"REDISQL.EXEC\", \"DB\", \"SELECT * FROM Events;\")\n# iterate throught the list writing on file\nwith open('csv_file', 'w') as csv_file:\n    # write the csv header\n    csv_file.write(\"event_id,user_id,ip_address,timestamp,data\\n\")\n    for row in values:\n        # create a single string with all the fields separated by a comma\n        elements = \",\".join(row) + \"\\n\"\n        # write the result on the csv_file\n        csv_file.write(elements)  Now you can use tools like PostgreSQL COPY to load all the data into your database.  This solution is not perfect and in a distributed setting with several concurrent workers it may result in some data duplication, however, we are getting ahead of ourselves and this topic will go far ahead of the scope of this post.",
            "title": "Move the data"
        },
        {
            "location": "/blog/analytics/#recap",
            "text": "In this blog post, we explored how to write a quite sophisticated analytics infrastructure using nothing more than RediSQL.  Adding this tool to your existing infrastructure should be quite simple and painless while it provides a simple way to do powerful things in a fast and reliable way.  Is worth to remember that RediSQL already provide RDB persistency so you already have some interesting level of safeness embed into this architecture.",
            "title": "Recap"
        },
        {
            "location": "/blog/JaaS/",
            "text": "JSON on Redis via RediSQL, SQL steroids for Redis\n\n\nRediSQL, Redis on SQL steroids.\n\n\nRediSQL is a redis module that embeds SQLite to provide full SQL capabilities to redis.\n\n\nThe fastest introduction to RediSQL is \nour homepage\n\n\ntl;dr; We build a \nJSON as a Service\n in less than 500 lines of javascript + RediSQL, you can check out the \nwhole source file here.\n\n\nJSON as a Service in 500 lines of code + RediSQL\n\n\nWhile building web services is common to have the need to store some un-structured or semi-structured data (aka \nJSON\n) somewhere.\n\n\nUnfortunately, it is not always so easy.\n\n\nIf you are using a SQL database, think about postgres, you need to add a column or even a table to your database, you need to decide how to encode the data and to be sure that your drivers work correctly with this new type.\n\n\nIf you are already using some kind of NoSQL database you may be a little luckier, but nevertheless, you should be sure that your database support all the operation you may need on JSON and still you need your team on-board to add a new collection/fields/column to your actual database.\n\n\nA faster solution\n\n\nA faster solution could be to use RediSQL exploiting the \nJSON1\n extension.\n\n\nSQLite provides several interesting extensions and one of our favourites is JSON1 that allow an efficient and fast manipulation of JSON data, all inside a full SQL engine.\n\n\nWe include this extension by default in RediSQL, so, if you are using RediSQL, you already have all the necessary function.\n\n\nDesiderata\n\n\nIn this example we assume that you are sharing your JSON data store between different part of the system, hence you need some form of hierarchy.\n\n\nWe will create JSON object that will have names and then each object will live inside a namespace, the couple \n(namespace, name)\n will be unique while name could be repeated inside different namespaces.\n\n\nThen we will like to have a simple RediSQL interface like this one:\n\n\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB create_namespace noises\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB upsert_object noises animals '{\"cat\": \"meeow\", \"dog\": \"woof\", \"goldfish\": \"...\"}'\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB upsert_object noises humans '{\"extrovert\": \"blablabla\", \"introverse\": \"bla\", \"programmer\": \"tap tap tap\"}'\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB extract noises humans $.extrovert\n1) 1) \"blablabla\"\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB extract noises animals $.dog\n1) 1) \"woof\"\n127.0.0.1:6379> \n\n\n\n\nOf course, we would also like to navigate complex JSONs and to add fields and values at will.\n\n\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB create_namespace foo\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB upsert_object foo bar '{\"a\": {\"quite\": [\"\", {\"complex\": {\"json\": [1, 2, \"object\"]}}, \"\"]}}'\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB extract foo bar $.a.quite[1].complex.json[2]\n1) 1) \"object\"\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB set foo bar $.a.quite[1].complex.json[3] '[\"even\", \"more\", \"complex\"]'\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB extract foo bar $.a.quite[1].complex.json[3] \n1) 1) \"[\\\"even\\\",\\\"more\\\",\\\"complex\\\"]\"\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB extract foo bar $.a.quite[1].complex.json[3][0]\n1) 1) \"even\"\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB extract foo bar $.a.quite[1].complex.json[3][1]\n1) 1) \"more\"\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB extract foo bar $.a.quite[1].complex.json[3][2]\n1) 1) \"complex\"\n\n\n\n\nIn this specific example we are only showing JSON, but keep in mind that the JSON field can be stored alongside the regular SQL fields as an extra field to hold any kind of unstructured data.\n\n\nAlso please note how these APIs are quite pleasant to work with, they seem almost native to redis and thanks to redis-module we have the possibility to simply create more powerful commands. \n\n\nImplementation\n\n\nNow that we know what we are trying to achieve let's proceed to the implementation that you will see is quite simple.\n\n\nUsually is a good idea to start from the data structure, and in our simple, but powerful, example, we need only a single table:\n\n\nCREATE TABLE IF NOT EXISTS namespace ( \n    namespace TEXT PRIMARY KEY \n); \n\nCREATE TABLE IF NOT EXISTS json_data (\n    namespace STRING,\n    object_name STRING,\n    data JSON,\n    PRIMARY KEY (namespace, object_name),\n    FOREIGN KEY(namespace) REFERENCES namespace(namespace) ON UPDATE CASCADE ON DELETE CASCADE\n);\n\n\n\n\nWe could have done everything with just \njson_data\n and without \nnamespace\n, but that would force to have the namespace that always contains at least a single object and everything would become more complex.\n\n\nNow that we have our data structure we can proceed with the procedures that I have show you above:\n\n\n-- create_namespace\nINSERT INTO namespace VALUES(?1);\n\n-- upsert_object\nINSERT OR REPLACE \n        INTO json_data (namespace, object_name, data)\n        VALUES (?1, ?2, json(?3))\n\n-- get_object\nSELECT data \n        FROM json_data \n        WHERE namespace = ?1 AND\n        object_name = ?2;\n\n-- extract\nSELECT json_extract(data, ?3) \n        FROM json_data \n        WHERE namespace = ?1 AND \n        object_name = ?2;\n\n-- set\nUPDATE json_data \n        SET data = json_set(data, ?3, json(?4))\n        WHERE namespace = ?1 AND \n        object_name = ?2 AND\n        data != json_set(data, ?3, json(?4)); -- if no modification, don't change the object\n\n\n\n\nIn order to actually create those table here is an example on RediSQL that is more difficult to read but simpler to just copy and paste into the redis-cli.\n\n\n127.0.0.1:6379> REDISQL.CREATE_DB DB\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"CREATE TABLE IF NOT EXISTS namespace (namespace TEXT PRIMARY KEY);\" \n1) DONE\n2) (integer) 0\n127.0.0.1:6379> REDISQL.EXEC DB \"CREATE TABLE IF NOT EXISTS json_data (namespace STRING, object_name STRING, data JSON, PRIMARY KEY (namespace, object_name));\"\n1) DONE\n2) (integer) 0\n127.0.0.1:6379> REDISQL.CREATE_STATEMENT DB create_namespace \"INSERT INTO namespace VALUES(?1);\"\nOK\n127.0.0.1:6379> REDISQL.CREATE_STATEMENT DB upsert_object \"INSERT OR REPLACE INTO json_data (namespace, object_name, data) VALUES (?1, ?2, json(?3))\"\nOK\n127.0.0.1:6379> REDISQL.CREATE_STATEMENT DB get_object \"SELECT data FROM json_data WHERE namespace = ?1 AND object_name = ?2;\"\nOK\n127.0.0.1:6379> REDISQL.CREATE_STATEMENT DB extract \"SELECT json_extract(data, ?3) FROM json_data WHERE namespace = ?1 AND object_name = ?2;\"\nOK\n127.0.0.1:6379> REDISQL.CREATE_STATEMENT DB set \"UPDATE json_data SET data = json_set(data, ?3, json(?4)) WHERE namespace = ?1 AND object_name = ?2 AND data != json_set(data, ?3, json(?4));\"\nOK\n\n\n\n\nOf course, there are a lot more commands in JSON1 API to use and explore, so I will simply \nleave you the reference\n.\n\n\nI also prepare a simple node application which exposes this exact same interface via REST API, it is a single, ~500 LOC, file that you can find \nhere\n\n\nFeel free to use the node application as a blueprint for your next project.\n\n\nRecap\n\n\nIn this brief tutorial, we have shown how quickly and easily is possible to build a fairly complex JSON store using Redis and RediSQL.\n\n\nOf course, similar structures, procedure and ideas can be used inside bigger structures and data table yielding powerful primitives for your application capable of sustain quite reasonable load without incurring in any extra operational cost.\n\n\nQuestion?\n\n\nOf course, if you have any question on RediSQL either open a public issue or write me, siscia, a private email.\n\n\nCheers,\n\n\n;)",
            "title": "JSON on Redis using RediSQL, SQL steroids for Redis"
        },
        {
            "location": "/blog/JaaS/#json-on-redis-via-redisql-sql-steroids-for-redis",
            "text": "RediSQL, Redis on SQL steroids.  RediSQL is a redis module that embeds SQLite to provide full SQL capabilities to redis.  The fastest introduction to RediSQL is  our homepage  tl;dr; We build a  JSON as a Service  in less than 500 lines of javascript + RediSQL, you can check out the  whole source file here.",
            "title": "JSON on Redis via RediSQL, SQL steroids for Redis"
        },
        {
            "location": "/blog/JaaS/#json-as-a-service-in-500-lines-of-code-redisql",
            "text": "While building web services is common to have the need to store some un-structured or semi-structured data (aka  JSON ) somewhere.  Unfortunately, it is not always so easy.  If you are using a SQL database, think about postgres, you need to add a column or even a table to your database, you need to decide how to encode the data and to be sure that your drivers work correctly with this new type.  If you are already using some kind of NoSQL database you may be a little luckier, but nevertheless, you should be sure that your database support all the operation you may need on JSON and still you need your team on-board to add a new collection/fields/column to your actual database.",
            "title": "JSON as a Service in 500 lines of code + RediSQL"
        },
        {
            "location": "/blog/JaaS/#a-faster-solution",
            "text": "A faster solution could be to use RediSQL exploiting the  JSON1  extension.  SQLite provides several interesting extensions and one of our favourites is JSON1 that allow an efficient and fast manipulation of JSON data, all inside a full SQL engine.  We include this extension by default in RediSQL, so, if you are using RediSQL, you already have all the necessary function.",
            "title": "A faster solution"
        },
        {
            "location": "/blog/JaaS/#desiderata",
            "text": "In this example we assume that you are sharing your JSON data store between different part of the system, hence you need some form of hierarchy.  We will create JSON object that will have names and then each object will live inside a namespace, the couple  (namespace, name)  will be unique while name could be repeated inside different namespaces.  Then we will like to have a simple RediSQL interface like this one:  127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB create_namespace noises\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB upsert_object noises animals '{\"cat\": \"meeow\", \"dog\": \"woof\", \"goldfish\": \"...\"}'\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB upsert_object noises humans '{\"extrovert\": \"blablabla\", \"introverse\": \"bla\", \"programmer\": \"tap tap tap\"}'\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB extract noises humans $.extrovert\n1) 1) \"blablabla\"\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB extract noises animals $.dog\n1) 1) \"woof\"\n127.0.0.1:6379>   Of course, we would also like to navigate complex JSONs and to add fields and values at will.  127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB create_namespace foo\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB upsert_object foo bar '{\"a\": {\"quite\": [\"\", {\"complex\": {\"json\": [1, 2, \"object\"]}}, \"\"]}}'\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB extract foo bar $.a.quite[1].complex.json[2]\n1) 1) \"object\"\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB set foo bar $.a.quite[1].complex.json[3] '[\"even\", \"more\", \"complex\"]'\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB extract foo bar $.a.quite[1].complex.json[3] \n1) 1) \"[\\\"even\\\",\\\"more\\\",\\\"complex\\\"]\"\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB extract foo bar $.a.quite[1].complex.json[3][0]\n1) 1) \"even\"\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB extract foo bar $.a.quite[1].complex.json[3][1]\n1) 1) \"more\"\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB extract foo bar $.a.quite[1].complex.json[3][2]\n1) 1) \"complex\"  In this specific example we are only showing JSON, but keep in mind that the JSON field can be stored alongside the regular SQL fields as an extra field to hold any kind of unstructured data.  Also please note how these APIs are quite pleasant to work with, they seem almost native to redis and thanks to redis-module we have the possibility to simply create more powerful commands.",
            "title": "Desiderata"
        },
        {
            "location": "/blog/JaaS/#implementation",
            "text": "Now that we know what we are trying to achieve let's proceed to the implementation that you will see is quite simple.  Usually is a good idea to start from the data structure, and in our simple, but powerful, example, we need only a single table:  CREATE TABLE IF NOT EXISTS namespace ( \n    namespace TEXT PRIMARY KEY \n); \n\nCREATE TABLE IF NOT EXISTS json_data (\n    namespace STRING,\n    object_name STRING,\n    data JSON,\n    PRIMARY KEY (namespace, object_name),\n    FOREIGN KEY(namespace) REFERENCES namespace(namespace) ON UPDATE CASCADE ON DELETE CASCADE\n);  We could have done everything with just  json_data  and without  namespace , but that would force to have the namespace that always contains at least a single object and everything would become more complex.  Now that we have our data structure we can proceed with the procedures that I have show you above:  -- create_namespace\nINSERT INTO namespace VALUES(?1);\n\n-- upsert_object\nINSERT OR REPLACE \n        INTO json_data (namespace, object_name, data)\n        VALUES (?1, ?2, json(?3))\n\n-- get_object\nSELECT data \n        FROM json_data \n        WHERE namespace = ?1 AND\n        object_name = ?2;\n\n-- extract\nSELECT json_extract(data, ?3) \n        FROM json_data \n        WHERE namespace = ?1 AND \n        object_name = ?2;\n\n-- set\nUPDATE json_data \n        SET data = json_set(data, ?3, json(?4))\n        WHERE namespace = ?1 AND \n        object_name = ?2 AND\n        data != json_set(data, ?3, json(?4)); -- if no modification, don't change the object  In order to actually create those table here is an example on RediSQL that is more difficult to read but simpler to just copy and paste into the redis-cli.  127.0.0.1:6379> REDISQL.CREATE_DB DB\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"CREATE TABLE IF NOT EXISTS namespace (namespace TEXT PRIMARY KEY);\" \n1) DONE\n2) (integer) 0\n127.0.0.1:6379> REDISQL.EXEC DB \"CREATE TABLE IF NOT EXISTS json_data (namespace STRING, object_name STRING, data JSON, PRIMARY KEY (namespace, object_name));\"\n1) DONE\n2) (integer) 0\n127.0.0.1:6379> REDISQL.CREATE_STATEMENT DB create_namespace \"INSERT INTO namespace VALUES(?1);\"\nOK\n127.0.0.1:6379> REDISQL.CREATE_STATEMENT DB upsert_object \"INSERT OR REPLACE INTO json_data (namespace, object_name, data) VALUES (?1, ?2, json(?3))\"\nOK\n127.0.0.1:6379> REDISQL.CREATE_STATEMENT DB get_object \"SELECT data FROM json_data WHERE namespace = ?1 AND object_name = ?2;\"\nOK\n127.0.0.1:6379> REDISQL.CREATE_STATEMENT DB extract \"SELECT json_extract(data, ?3) FROM json_data WHERE namespace = ?1 AND object_name = ?2;\"\nOK\n127.0.0.1:6379> REDISQL.CREATE_STATEMENT DB set \"UPDATE json_data SET data = json_set(data, ?3, json(?4)) WHERE namespace = ?1 AND object_name = ?2 AND data != json_set(data, ?3, json(?4));\"\nOK  Of course, there are a lot more commands in JSON1 API to use and explore, so I will simply  leave you the reference .  I also prepare a simple node application which exposes this exact same interface via REST API, it is a single, ~500 LOC, file that you can find  here  Feel free to use the node application as a blueprint for your next project.",
            "title": "Implementation"
        },
        {
            "location": "/blog/JaaS/#recap",
            "text": "In this brief tutorial, we have shown how quickly and easily is possible to build a fairly complex JSON store using Redis and RediSQL.  Of course, similar structures, procedure and ideas can be used inside bigger structures and data table yielding powerful primitives for your application capable of sustain quite reasonable load without incurring in any extra operational cost.",
            "title": "Recap"
        },
        {
            "location": "/blog/JaaS/#question",
            "text": "Of course, if you have any question on RediSQL either open a public issue or write me, siscia, a private email.  Cheers,  ;)",
            "title": "Question?"
        },
        {
            "location": "/blog/performances/",
            "text": "Doubling the performances of RediSQL, SQL steroids for Redis.\n\n\nRediSQL provides SQL steroids for Redis\n\n\nRediSQL is a redis module that embeds SQLite to provide full SQL capabilities to redis.\n\n\nThe fastest introduction to RediSQL is \nour homepage\n\n\ntl;dr; We double the performance of RediSQL switching to a zero-copy use of the input arguments.\n\n\nBackground\n\n\nDuring the development of RediSQL we always kept in mind performance, but only up to a degree.\n\n\nAs Donal Knuth says \"premature optimization is the root of all evil\", but he also added, \"Yet we should not pass up our opportunities in that critical 3%.\"\n\n\nFor us not pass up opportunities was more about using the correct data structure and algorithm when and where they make sense.\n\n\nOverall the performances were quite good, on my old personal machine I could get 30k/inserts per second in a very simple table (few numeric value and small texts).\n\n\nThis number is really small compared to Redis that can \nSET\n keys up to 100k/set per second, but we are also doing more work and we have always considered this figures good enough, at least as long as nobody complains.\n\n\nThe complains\n\n\nFortunately\n somebody \ncomplains about the insertion rates\n.\n\n\nHis requirements were a little different from the assumption that we had when testing the performance. He needed to insert a lot of data ~100kB in each row. And to do it fast.\n\n\nFirst tests were not so good, showing just 2000 insertions per second. Definitely not good.\n\n\nLooking for the causes\n\n\nRust, the system language in which RediSQL is built, is peculiar in the management of memory.\n\n\nThe type system must be sure that every reference that you are using is valid and that you will never deference stuff out of your memory space.\n\n\nOf course, this gives you a lot of safety but introduces quite a bit of complexity.\n\n\nFortunately, there are ways to manage this complexity: is possible to trade complexity for performances or, the other way around, performances for complexity.\n\n\nHigh complexity with high performance means that you are using references (pointers) everywhere it is possible, so you never copy memory around if it is not necessary, you pass a pointer to that memory location and the type system assure you that it is safe to deference such pointer.\n\n\nLow complexity with low performance implies to copy areas of memory multiple times so that the type system is always happy. Instead of using a pointer to a piece of memory I will just copy everything I need and pass it around functions.\n\n\nSince the product was new, it made sense for us to get as low complexity as possible in such a way that it is possible to move faster understanding what our clients need and what we want to build.\n\n\nUntil now.\n\n\nThe problem\n\n\nThe biggest problem we identified was that we were copying all the input parameter, so when a client was sending as a request like \nREDISQL.EXEC_STATEMENT DB insert 1 2 3\n we were copying 6 (insert) + 3 (1, 2, 3) = 9 bytes of memory.\n\n\n(Redis string are a little particular since they don't have a null '\\0' terminator and carry along their size.)\n\n\nNobody will complain about copying just ~10 bytes of memory, especially using slab allocator it is still some work but it is quite fast to do.\n\n\nHowever, when we start to ingest 100k bytes this will really impact negatively the performance.\n\n\nNeed for Speed\n\n\nWe could get away with just copying and freeing few bytes, especially using jemalloc, however as soon as the payload start increasing in size copying it every time started to impact negatively the performance of the module.\n\n\nWas time to buy some performances paying our share price in complexity.\n\n\nThe process was a little complex because the data lived outside the Rust code, inside Redis itself.\nIt was necessary to use \nunsafe\n code that in normal Rust you can avoid, but finally, we were able to see the Redis string as a slice (array) of chars and get a reference to it to pass around.\n\n\nResult\n\n\nBefore to release the code I obviously tested it. I used a c4.8xlarge from AWS.\n\n\nThat machine before the patch could ingest 4000 request / second each of ~100k bytes. After the patch, it was able to get 8000 requests/second.\n\n\nFinally, the latency was pretty much the same with the 99.9 percentile at ~50 milliseconds.\n\n\nXin, the gentleman who brought the issues to our attention, went even further setting several parameters available in \nredis-benchmark\n, notably the number of pipelined requests, and he reached 17000 requests per second.\n\n\nBeing conservative we can claim that our works made redisql twice (from 4000 req/s to 8000 req/s) as fast at ingesting big amount of data.\n\n\nIt is definitely necessary more testing to see the impact on different workloads, smaller payload. Fortunately, our preliminary results seem quite good.\n\n\nWrapping up\n\n\nWe showed how was possible to get a lot of performance out of Rust and RediSQL switching to a zero copy approach.\n\n\nWe also showed that our solution is very efficient, being able to ingest 800 MB / s of data without any sort of tuning.\n\n\nLooking for beta tester\n\n\nWe are looking also for tester for the PRO version of RediSQL, if you would like to test the PRO module without paying anything this is your occasion.\nYou can either open an issues on github or write me (siscia) directly (email on github).",
            "title": "Double performances of RediSQL going zero copy"
        },
        {
            "location": "/blog/performances/#doubling-the-performances-of-redisql-sql-steroids-for-redis",
            "text": "RediSQL provides SQL steroids for Redis  RediSQL is a redis module that embeds SQLite to provide full SQL capabilities to redis.  The fastest introduction to RediSQL is  our homepage  tl;dr; We double the performance of RediSQL switching to a zero-copy use of the input arguments.",
            "title": "Doubling the performances of RediSQL, SQL steroids for Redis."
        },
        {
            "location": "/blog/performances/#background",
            "text": "During the development of RediSQL we always kept in mind performance, but only up to a degree.  As Donal Knuth says \"premature optimization is the root of all evil\", but he also added, \"Yet we should not pass up our opportunities in that critical 3%.\"  For us not pass up opportunities was more about using the correct data structure and algorithm when and where they make sense.  Overall the performances were quite good, on my old personal machine I could get 30k/inserts per second in a very simple table (few numeric value and small texts).  This number is really small compared to Redis that can  SET  keys up to 100k/set per second, but we are also doing more work and we have always considered this figures good enough, at least as long as nobody complains.",
            "title": "Background"
        },
        {
            "location": "/blog/performances/#the-complains",
            "text": "Fortunately  somebody  complains about the insertion rates .  His requirements were a little different from the assumption that we had when testing the performance. He needed to insert a lot of data ~100kB in each row. And to do it fast.  First tests were not so good, showing just 2000 insertions per second. Definitely not good.",
            "title": "The complains"
        },
        {
            "location": "/blog/performances/#looking-for-the-causes",
            "text": "Rust, the system language in which RediSQL is built, is peculiar in the management of memory.  The type system must be sure that every reference that you are using is valid and that you will never deference stuff out of your memory space.  Of course, this gives you a lot of safety but introduces quite a bit of complexity.  Fortunately, there are ways to manage this complexity: is possible to trade complexity for performances or, the other way around, performances for complexity.  High complexity with high performance means that you are using references (pointers) everywhere it is possible, so you never copy memory around if it is not necessary, you pass a pointer to that memory location and the type system assure you that it is safe to deference such pointer.  Low complexity with low performance implies to copy areas of memory multiple times so that the type system is always happy. Instead of using a pointer to a piece of memory I will just copy everything I need and pass it around functions.  Since the product was new, it made sense for us to get as low complexity as possible in such a way that it is possible to move faster understanding what our clients need and what we want to build.  Until now.",
            "title": "Looking for the causes"
        },
        {
            "location": "/blog/performances/#the-problem",
            "text": "The biggest problem we identified was that we were copying all the input parameter, so when a client was sending as a request like  REDISQL.EXEC_STATEMENT DB insert 1 2 3  we were copying 6 (insert) + 3 (1, 2, 3) = 9 bytes of memory.  (Redis string are a little particular since they don't have a null '\\0' terminator and carry along their size.)  Nobody will complain about copying just ~10 bytes of memory, especially using slab allocator it is still some work but it is quite fast to do.  However, when we start to ingest 100k bytes this will really impact negatively the performance.",
            "title": "The problem"
        },
        {
            "location": "/blog/performances/#need-for-speed",
            "text": "We could get away with just copying and freeing few bytes, especially using jemalloc, however as soon as the payload start increasing in size copying it every time started to impact negatively the performance of the module.  Was time to buy some performances paying our share price in complexity.  The process was a little complex because the data lived outside the Rust code, inside Redis itself.\nIt was necessary to use  unsafe  code that in normal Rust you can avoid, but finally, we were able to see the Redis string as a slice (array) of chars and get a reference to it to pass around.",
            "title": "Need for Speed"
        },
        {
            "location": "/blog/performances/#result",
            "text": "Before to release the code I obviously tested it. I used a c4.8xlarge from AWS.  That machine before the patch could ingest 4000 request / second each of ~100k bytes. After the patch, it was able to get 8000 requests/second.  Finally, the latency was pretty much the same with the 99.9 percentile at ~50 milliseconds.  Xin, the gentleman who brought the issues to our attention, went even further setting several parameters available in  redis-benchmark , notably the number of pipelined requests, and he reached 17000 requests per second.  Being conservative we can claim that our works made redisql twice (from 4000 req/s to 8000 req/s) as fast at ingesting big amount of data.  It is definitely necessary more testing to see the impact on different workloads, smaller payload. Fortunately, our preliminary results seem quite good.",
            "title": "Result"
        },
        {
            "location": "/blog/performances/#wrapping-up",
            "text": "We showed how was possible to get a lot of performance out of Rust and RediSQL switching to a zero copy approach.  We also showed that our solution is very efficient, being able to ingest 800 MB / s of data without any sort of tuning.",
            "title": "Wrapping up"
        },
        {
            "location": "/blog/performances/#looking-for-beta-tester",
            "text": "We are looking also for tester for the PRO version of RediSQL, if you would like to test the PRO module without paying anything this is your occasion.\nYou can either open an issues on github or write me (siscia) directly (email on github).",
            "title": "Looking for beta tester"
        },
        {
            "location": "/blog/python/using-redisql-with-python/",
            "text": "Using RediSQL with Python\n\n\nThis tutorial will help you to get start to use RediSQL with Python3.\n\n\nIn this tutorial we will scrape the content of Hacker News using their \nAPI documented here\n.\n\n\nWe will use async python with \nasyncio\n to manage the event loop, \naiohttp\n to retrieve data from a public API and \naioredis\n to communicate with Redis.\n\n\nTo follow this tutorial you will need a modern (> v4.0) instance of Redis running RediSQL.\nYou can obtain RediSQL from \nour shop\n or from the \ngithub releases\n.\n\n\nTo load RediSQL is sufficient to pass it as argument to the redis-server: \n./redis-server --loadmodule /path/to/redisql.so\n\n\nThe whole code show in this example is reachable \nhere\n while we also created a \nmore sophisticate example\n that stress much more the infrastructure to show that the bottle neck is not RediSQL but python and the network.\n\n\nRediSQL and aioredis\n\n\nMost Redis library implements methods to call the standard Redis command like \nSET\n or \nGET\n or \nRPOP\n and aioredis is not an exception.\nThis is generally a problem for Redis modules like RediSQL that instead defined their own commands.\nFortunately most libraries usually expose also a lower level method that is used to implement most of the other Redis command.\nFor what concern \naioredis\n the lower level method that we can use is \n.execute\n that is implemented for both \nsingle connection\n and for a \npool of connections\n.\n\n\nIndeed is possible to implement all the other high level command using the low level \n.execute\n method.\n\n\nRediSQL and redis\n\n\nWhile in this article we will talk about \naioredis\n, another, not asynchronous library for using Redis with python is \nredis\n library\n.\n\n\nIn the \nredis\n library, the low level method is \n.execute_command\n and not \n.execute\n as for \naioredis\n, other than this difference everything will apply just the same.\n\n\nCreating a Redis connection\n\n\nThe very first thing to do is to connect to Redis, in our case we use a connection pool that has the same interface of a simple connection but is backed by a pool of different connections.\n\n\nCreating the pool can be done like so:\n\n\nloop = asyncio.get_event_loop()\nconn_co = aioredis.create_pool('redis://localhost', minsize=10, maxsize=300, loop = loop)\nredis_co = asyncio.gather(*[conn_co])\nredis = loop.run_until_complete(redis_co)\nredis = redis[0]\n\n\n\n\nand now the variable \nredis\n refer to a \naioredis\n pool.\n\n\nWhen we will need a new connection, the pool will either give us an idle connection or open a new connection to Redis and give us the new one.\n\n\nSetting up RediSQL\n\n\nNow that we have a pool of connections before to get the data into RediSQL we need to set up RediSQL.\nThe first step is to create a database in RediSQL, this can be done easily with a call like\n\n\nawait redis.execute(\"REDISQL.CREATE_DB\", \"HN\")\n\n\n\n\nthis call will create a new RediSQL database and it will call it \nHN\n. If the key \nHN\n already exists the call will return an error.\n\n\nThe next step is to create the structure to hold our data. In our case we will stick to something simple, a single table where we store the identifier of each item (comment or story) from HN, the author of such item, when the item was created and finally we will store the whole item as json structure in a text field.\n\n\nquery = \"\"\"CREATE TABLE IF NOT EXISTS hn(id integer primary key, author text, time int, item text);\"\"\"\nawait redis.execute(\"REDISQL.EXEC\", \"HN\", query) \n\n\n\n\nFinally, since we storing data from the open internet inside our database, is wise to create an SQL statement to execute when doing an insert.\nThe advantage of the statement is that is safe from SQL injections and is usually faster than re-compile the same query each time.\n\n\nTo create a statement we can proceed as following:\n\n\nstatement = \"INSERT INTO hn VALUES(?1, ?2, ?3, json(?4));\"\nawait redis.execute(\"REDISQL.CREATE_STATEMENT\", \"HN\", \"insert_item\", statement)\n\n\n\n\nThe last command create a new statement in the \nHN\n database and associate it with the string \ninsert_item\n so that we can refer to it later.\n\n\nAlso note the use of the \njson(?4)\n function, this is a function provided by the \nJSON1 module\n of SQLite and exposed by RediSQL that allow fast and efficient manipulation of json object. \nUsing the JSON1 module is possible to have a lot of flexibility even inside a rigid SQL schema.\n\n\nIs usually wise to wrap those command into a \ntry: except:\n block. Hence the final function will look like this:\n\n\nasync def set_up(redis):\n    try:\n        await redis.execute(\"REDISQL.CREATE_DB\", \"HN\")\n    except Exception as e:\n        print(e)\n\n    query = \"\"\"CREATE TABLE IF NOT EXISTS hn(id integer primary key, author text, time int, item text);\"\"\"\n    try:\n        await redis.execute(\"REDISQL.EXEC\", \"HN\", query)\n    except Exception as e:\n        print(e)\n\n    statement = \"INSERT INTO hn VALUES(?1, ?2, ?3, json(?4));\"\n    try:\n        await redis.execute(\"REDISQL.CREATE_STATEMENT\", \"HN\", \"insert_item\", statement)\n    except Exception as e:\n        print(e)\n\n\n\n\nRunning the loop\n\n\nNow that we have set up our environment we can go on and start to listen for new items posted on HN.\n\n\nThe API provides a simple endpoint \nmaxitem.json\n that returns the id of the latest item posted on HN.\nWhen the loop start we get maxitem and we store it into Redis. \nThen, when the maxitem get updated we download each of the items between the \nold maxitem\n and the \nnew maxitem\n. \n\n\nWe repeat the loop forever with a sleep to avoid hammering the API endpoint.\n\n\nasync def main(redis, http):\n    max_item = await get_max_item(http)\n    await redis.execute(\"SET\", \"max-item\", max_item)\n    old_max_item = max_item\n    while True:\n        # we download the new maxitem\n        max_item = await get_max_item(http)\n        # if the new maxitem is actually bigger than the old one\n        if max_item > old_max_item:\n            # for each new item...\n            for i in range(old_max_item, max_item):\n                # we start a new Task that store the item in our database\n                store = store_item(http, redis, str(i))\n                asyncio.ensure_future(store)\n            await redis.execute(\"SET\", \"max-item\", max_item)\n            old_max_item = max_item\n        asyncio.sleep(1)\n\n\n\n\nStoring the data into RediSQL\n\n\nThe last interesting bit is about the \nstore_item\n function that is the one that download the item from the API and store it into RediSQL.\n\n\nasync def store_item(http, redis, item_id):\n    item = await get_hn_item(http, item_id)\n    await store_on_db(redis, item)\n\nasync def get_hn_item(http, item_id):\n    while True:\n        async with http.get(get_item_url(item_id)) as item:\n            if 200 <= item.status < 300:\n                data = await item.text()\n                item = json.loads(data)\n                if item:\n                    return item\n\n# In this function we store the item into the RediSQL database\nasync def store_on_db(redis, item):\n    try:\n        # execute the statement passing the necessary parameters\n        await redis.execute(\"REDISQL.EXEC_STATEMENT\", \"HN\", \"insert_item\", \n                item[\"id\"], item.get(\"by\", \"_no_author_\"), item[\"time\"], json.dumps(item))\n    except Exception as e:\n        print(e)\n        print(item[\"id\"])\n\n\n\n\nDownloading the item from the API is a simple HTTP GET request, then we simply check if it returns a successful status code and that it actually returns valid json.\n\n\nFinally to store the element into RediSQL we execute the statement that we have create before during the set up phase.\nIndeed we are executing the command \nREDISQL.EXEC_STATEMENT HN insert_item $item_id $item_author $item_time $item\n.\nThis command will find inside the database \nHN\n the statement \ninsert_item\n that we have previously defined as \nINSERT INTO hn VALUES(?1, ?2, ?3, json(?4));\n.\nNow the item id will be substituted to \n?1\n, the item author will substitute \n?2\n, the creation time of the item will take the place of \n?3\n and the whole json string of the item will substitute \n?4\n, finally the statement is executed agains RediSQL and its result returned.\n\n\nIf everything went right, we have just added our first row to the database using async python.\n\n\nConcluding\n\n\nIn this tutorial we took a rather simple problem and we use it to show how to use RediSQL with async python.\n\n\nWe started by setting up the database, we show how to create a database and tables inside it. Then we also show how to create statements to avoid SQL injections attack and improve the efficiency of repeated queries.\n\n\nThen we obtain the data from the Hacker News API and we show how to insert the data into RediSQL using the statement that we have just created.\n\n\nHopefully this tutorial will be helpful and sufficient to get started, but if you have any question feel free to get in touch or to open an issue.\n\n\nIf you wish to see a similar tutorial for a different language, \nopen an issue on github.",
            "title": "Using RediSQL with Python"
        },
        {
            "location": "/blog/python/using-redisql-with-python/#using-redisql-with-python",
            "text": "This tutorial will help you to get start to use RediSQL with Python3.  In this tutorial we will scrape the content of Hacker News using their  API documented here .  We will use async python with  asyncio  to manage the event loop,  aiohttp  to retrieve data from a public API and  aioredis  to communicate with Redis.  To follow this tutorial you will need a modern (> v4.0) instance of Redis running RediSQL.\nYou can obtain RediSQL from  our shop  or from the  github releases .  To load RediSQL is sufficient to pass it as argument to the redis-server:  ./redis-server --loadmodule /path/to/redisql.so  The whole code show in this example is reachable  here  while we also created a  more sophisticate example  that stress much more the infrastructure to show that the bottle neck is not RediSQL but python and the network.",
            "title": "Using RediSQL with Python"
        },
        {
            "location": "/blog/python/using-redisql-with-python/#redisql-and-aioredis",
            "text": "Most Redis library implements methods to call the standard Redis command like  SET  or  GET  or  RPOP  and aioredis is not an exception.\nThis is generally a problem for Redis modules like RediSQL that instead defined their own commands.\nFortunately most libraries usually expose also a lower level method that is used to implement most of the other Redis command.\nFor what concern  aioredis  the lower level method that we can use is  .execute  that is implemented for both  single connection  and for a  pool of connections .  Indeed is possible to implement all the other high level command using the low level  .execute  method.",
            "title": "RediSQL and aioredis"
        },
        {
            "location": "/blog/python/using-redisql-with-python/#redisql-and-redis",
            "text": "While in this article we will talk about  aioredis , another, not asynchronous library for using Redis with python is  redis  library .  In the  redis  library, the low level method is  .execute_command  and not  .execute  as for  aioredis , other than this difference everything will apply just the same.",
            "title": "RediSQL and redis"
        },
        {
            "location": "/blog/python/using-redisql-with-python/#creating-a-redis-connection",
            "text": "The very first thing to do is to connect to Redis, in our case we use a connection pool that has the same interface of a simple connection but is backed by a pool of different connections.  Creating the pool can be done like so:  loop = asyncio.get_event_loop()\nconn_co = aioredis.create_pool('redis://localhost', minsize=10, maxsize=300, loop = loop)\nredis_co = asyncio.gather(*[conn_co])\nredis = loop.run_until_complete(redis_co)\nredis = redis[0]  and now the variable  redis  refer to a  aioredis  pool.  When we will need a new connection, the pool will either give us an idle connection or open a new connection to Redis and give us the new one.",
            "title": "Creating a Redis connection"
        },
        {
            "location": "/blog/python/using-redisql-with-python/#setting-up-redisql",
            "text": "Now that we have a pool of connections before to get the data into RediSQL we need to set up RediSQL.\nThe first step is to create a database in RediSQL, this can be done easily with a call like  await redis.execute(\"REDISQL.CREATE_DB\", \"HN\")  this call will create a new RediSQL database and it will call it  HN . If the key  HN  already exists the call will return an error.  The next step is to create the structure to hold our data. In our case we will stick to something simple, a single table where we store the identifier of each item (comment or story) from HN, the author of such item, when the item was created and finally we will store the whole item as json structure in a text field.  query = \"\"\"CREATE TABLE IF NOT EXISTS hn(id integer primary key, author text, time int, item text);\"\"\"\nawait redis.execute(\"REDISQL.EXEC\", \"HN\", query)   Finally, since we storing data from the open internet inside our database, is wise to create an SQL statement to execute when doing an insert.\nThe advantage of the statement is that is safe from SQL injections and is usually faster than re-compile the same query each time.  To create a statement we can proceed as following:  statement = \"INSERT INTO hn VALUES(?1, ?2, ?3, json(?4));\"\nawait redis.execute(\"REDISQL.CREATE_STATEMENT\", \"HN\", \"insert_item\", statement)  The last command create a new statement in the  HN  database and associate it with the string  insert_item  so that we can refer to it later.  Also note the use of the  json(?4)  function, this is a function provided by the  JSON1 module  of SQLite and exposed by RediSQL that allow fast and efficient manipulation of json object. \nUsing the JSON1 module is possible to have a lot of flexibility even inside a rigid SQL schema.  Is usually wise to wrap those command into a  try: except:  block. Hence the final function will look like this:  async def set_up(redis):\n    try:\n        await redis.execute(\"REDISQL.CREATE_DB\", \"HN\")\n    except Exception as e:\n        print(e)\n\n    query = \"\"\"CREATE TABLE IF NOT EXISTS hn(id integer primary key, author text, time int, item text);\"\"\"\n    try:\n        await redis.execute(\"REDISQL.EXEC\", \"HN\", query)\n    except Exception as e:\n        print(e)\n\n    statement = \"INSERT INTO hn VALUES(?1, ?2, ?3, json(?4));\"\n    try:\n        await redis.execute(\"REDISQL.CREATE_STATEMENT\", \"HN\", \"insert_item\", statement)\n    except Exception as e:\n        print(e)",
            "title": "Setting up RediSQL"
        },
        {
            "location": "/blog/python/using-redisql-with-python/#running-the-loop",
            "text": "Now that we have set up our environment we can go on and start to listen for new items posted on HN.  The API provides a simple endpoint  maxitem.json  that returns the id of the latest item posted on HN.\nWhen the loop start we get maxitem and we store it into Redis. \nThen, when the maxitem get updated we download each of the items between the  old maxitem  and the  new maxitem .   We repeat the loop forever with a sleep to avoid hammering the API endpoint.  async def main(redis, http):\n    max_item = await get_max_item(http)\n    await redis.execute(\"SET\", \"max-item\", max_item)\n    old_max_item = max_item\n    while True:\n        # we download the new maxitem\n        max_item = await get_max_item(http)\n        # if the new maxitem is actually bigger than the old one\n        if max_item > old_max_item:\n            # for each new item...\n            for i in range(old_max_item, max_item):\n                # we start a new Task that store the item in our database\n                store = store_item(http, redis, str(i))\n                asyncio.ensure_future(store)\n            await redis.execute(\"SET\", \"max-item\", max_item)\n            old_max_item = max_item\n        asyncio.sleep(1)",
            "title": "Running the loop"
        },
        {
            "location": "/blog/python/using-redisql-with-python/#storing-the-data-into-redisql",
            "text": "The last interesting bit is about the  store_item  function that is the one that download the item from the API and store it into RediSQL.  async def store_item(http, redis, item_id):\n    item = await get_hn_item(http, item_id)\n    await store_on_db(redis, item)\n\nasync def get_hn_item(http, item_id):\n    while True:\n        async with http.get(get_item_url(item_id)) as item:\n            if 200 <= item.status < 300:\n                data = await item.text()\n                item = json.loads(data)\n                if item:\n                    return item\n\n# In this function we store the item into the RediSQL database\nasync def store_on_db(redis, item):\n    try:\n        # execute the statement passing the necessary parameters\n        await redis.execute(\"REDISQL.EXEC_STATEMENT\", \"HN\", \"insert_item\", \n                item[\"id\"], item.get(\"by\", \"_no_author_\"), item[\"time\"], json.dumps(item))\n    except Exception as e:\n        print(e)\n        print(item[\"id\"])  Downloading the item from the API is a simple HTTP GET request, then we simply check if it returns a successful status code and that it actually returns valid json.  Finally to store the element into RediSQL we execute the statement that we have create before during the set up phase.\nIndeed we are executing the command  REDISQL.EXEC_STATEMENT HN insert_item $item_id $item_author $item_time $item .\nThis command will find inside the database  HN  the statement  insert_item  that we have previously defined as  INSERT INTO hn VALUES(?1, ?2, ?3, json(?4)); .\nNow the item id will be substituted to  ?1 , the item author will substitute  ?2 , the creation time of the item will take the place of  ?3  and the whole json string of the item will substitute  ?4 , finally the statement is executed agains RediSQL and its result returned.  If everything went right, we have just added our first row to the database using async python.",
            "title": "Storing the data into RediSQL"
        },
        {
            "location": "/blog/python/using-redisql-with-python/#concluding",
            "text": "In this tutorial we took a rather simple problem and we use it to show how to use RediSQL with async python.  We started by setting up the database, we show how to create a database and tables inside it. Then we also show how to create statements to avoid SQL injections attack and improve the efficiency of repeated queries.  Then we obtain the data from the Hacker News API and we show how to insert the data into RediSQL using the statement that we have just created.  Hopefully this tutorial will be helpful and sufficient to get started, but if you have any question feel free to get in touch or to open an issue.  If you wish to see a similar tutorial for a different language,  open an issue on github.",
            "title": "Concluding"
        },
        {
            "location": "/blog/golang/using-redisql-with-golang/",
            "text": "Using RediSQL with Go(lang)\n\n\nThis tutorial will help you to get start to use RediSQL with Go(lang).\n\n\nIn this tutorial we will scrape the content of Hacker News using their \nAPI documented here\n.\n\n\nTo communicate with Redis we will use the popular \nradix\n library wich is the most suitable to communicate with Redis Modules and RediSQL. Other libraries can be used as well, but some more work will be necessary.\n\n\nTo follow this tutorial you will need a modern (> v4.0) instance of Redis running RediSQL.\nYou can obtain RediSQL from \nour shop\n or from the \ngithub releases\n.\n\n\nTo load RediSQL is sufficient to pass it as argument to the redis-server: \n./redis-server --loadmodule /path/to/redisql.so\n\n\nThe whole code show in this example is reachable \nhere\n\n\nCreating a Redis Pooled Connection\n\n\nUsing \nradix\n is quite simple to use a pooled connection to Redis, indeed \nradix\n provide the \nNewPool\n function that creates a pool of connection to Redis. Then it is possible to use that pool as a client and have the library allocate a client for us.\n\n\nredis, err := radix.NewPool(\"tcp\", \"localhost:6379\", 10)\nif err != nil {\n    fmt.Println(err)\n        return\n}\n\n\n\n\nSetting up the database\n\n\nIn order to work with RediSQL is necessary to do a small setup. \nThe first step is always to create a database, then we create the tables inside the databases and finally the different statements if they are necessary.\n\n\nIt is always a good idea to use statements instead of building query by hand, but it is not mandatory. \nThe use of statements eliminate the risk of SQL injection and it is more performant, since the query is parsed only once and not every time it get executed.\n\n\nIn our case we create a simple database that we will call \nHN\n.\n\n\nr.Do(radix.Cmd(nil, \"REDISQL.CREATE_DB\", \"HN\"))\n\n\n\n\nThen we create a single table \nhn\n inside the \nHN\n database.\n\n\ntable := \"CREATE TABLE IF NOT EXISTS hn(id integer primary key, author text, time int, item text);\"\nr.Do(radix.Cmd(nil, \"REDISQL.EXEC\", \"HN\", table))\n\n\n\n\nThe table will contains the \nid\n of each item we are getting from HN, along with the author of the item, when the item was posted and finally the last field will contains the whole item as a \njson\n string.\n\n\nThe last step is to create a statement to easily insert the data inside our table.\n\n\nstmt := `INSERT INTO hn VALUES(\n    json_extract(json(?1),'$.id'), \n    json_extract(json(?1),'$.by'), \n    json_extract(json(?1),'$.time'), \n    json(?1));`\nr.Do(radix.Cmd(nil, \"REDISQL.CREATE_STATEMENT\", \"HN\", \"insert_item\", stmt))\n\n\n\n\nThe statement is a little complex. \nIt exploit the \nJSON1\n sqlite extension to extract the necessary fields from a JSON string. \nIn particular we extract the \nid\n, the \nby\n (author) and the \ntime\n fields.\n\n\nAfter that those fields are extracted from the JSON string we store all of them into the database along with the whole item.\n\n\nThe loop\n\n\nAfter the database is ready to accept data, we start to poll the HN API in order to fetch the newest item. \nEach item is then pushed into the \nitemIds\n channel that is later consumed.\n\n\nitemIds := make(chan int, 10)\n\ngo func() {\n    oldMaxItemId := getMaxItem()\n    for {\n        newMaxItemId := getMaxItem()\n        for ; oldMaxItemId < newMaxItemId; oldMaxItemId++ {\n            itemIds <- oldMaxItemId\n        }\n        time.Sleep(5 * time.Second)\n    }\n}()\n\n\n\n\nThe API provide an endpoint that show the biggest element in HN at the moment, it is a simple auto-incremental id that we can fetch using the \ngetMaxItem()\n function implemented as:\n\n\nfunc getMaxItem() int {\n    resp, _ := http.Get(\"https://hacker-news.firebaseio.com/v0/maxitem.json\")\n    defer resp.Body.Close()\n    body, _ := ioutil.ReadAll(resp.Body)\n    n, _ := strconv.Atoi(string(body))\n    return n\n}\n\n\n\n\nFinally the main loop iterate through the \nitemIds\n channel.\nFor each new item we use again the HN API to get the content of the items and then we store it into RediSQL.\n\n\nfor itemId := range itemIds {\n    go func() {\n        item := getItem(itemId)\n        err := redis.Do(radix.Cmd(nil, \"REDISQL.EXEC_STATEMENT\", \"HN\", \"insert_item\", item))\n        if err != nil {\n            fmt.Println(err)\n        }\n    }()\n}\n\n\n\n\nThe \ngetitem()\n functions implement a trivial error recovery strategy. \nIndeed, after some trial and error, was clear that, sometimes, the element \nn\n is not ready yet even if the element \nn+1\n was published as \nmaxitem\n and the API returns the simple string \"null\", if that is the case we simply repeat the call.\n\n\nfunc getItem(id int) string {\n    for {\n        url := fmt.Sprintf(\"https://hacker-news.firebaseio.com/v0/item/%d.json\", id)\n        resp, _ := http.Get(url)\n        defer resp.Body.Close()\n        body, _ := ioutil.ReadAll(resp.Body)\n        result := string(body)\n        if result != \"null\" {\n            return result\n        }\n    }\n}\n\n\n\n\n\nConcluding\n\n\nThis small example (less than 80 lines) show how simple is to quickly get value from RediSQL.\nIndeed is sufficient to set up the database following always the same steps:\n\n\n\n\nCreate the database with \nREDISQL.CREATE_DB $db_name\n\n\nCreate the schema inside your database \nREDISQL.EXEC $db_name \"CREATE TABLE ... etc\"\n and, if you want, the statements: \nREDISSQL.CREATE_STATEMENT $db_name $statement_name \"INSERT INTO ... etc\"\n\n\nStart inserting data, with or without a statement: \nREDISQL.EXEC_STATEMENT\n or simply \nREDISQL.EXEC\n\n\n\n\nFinally to query back the data is possible to use:\n\n\n\n\nqueries \nREDISQL.QUERY $db_name \"SELECT * FROM ...\"\n,\n\n\nstatements \nREDISQL.CREATE_STATEMENT $db_name $query_name \"SELECT * FROM ... WHERE foo = ?1\"\n and the \nREDISQL.QUERY_STATEMENTS $db_name $query_name \"paramenters\"\n\n\nsimple exec \nREDISQL.EXEC $db_name \"SELECT * FROM ... etc\"\n\n\n\n\nFeel free to explore our \nreferences documentation\n to understand better what capabilities RediSQL provides you.\n\n\nThe complete code of this example is \navailable here.\n\n\nIf you wish to see a similar tutorial for a different language, \nopen an issue on github.",
            "title": "Using RediSQL with Go(lang)"
        },
        {
            "location": "/blog/golang/using-redisql-with-golang/#using-redisql-with-golang",
            "text": "This tutorial will help you to get start to use RediSQL with Go(lang).  In this tutorial we will scrape the content of Hacker News using their  API documented here .  To communicate with Redis we will use the popular  radix  library wich is the most suitable to communicate with Redis Modules and RediSQL. Other libraries can be used as well, but some more work will be necessary.  To follow this tutorial you will need a modern (> v4.0) instance of Redis running RediSQL.\nYou can obtain RediSQL from  our shop  or from the  github releases .  To load RediSQL is sufficient to pass it as argument to the redis-server:  ./redis-server --loadmodule /path/to/redisql.so  The whole code show in this example is reachable  here",
            "title": "Using RediSQL with Go(lang)"
        },
        {
            "location": "/blog/golang/using-redisql-with-golang/#creating-a-redis-pooled-connection",
            "text": "Using  radix  is quite simple to use a pooled connection to Redis, indeed  radix  provide the  NewPool  function that creates a pool of connection to Redis. Then it is possible to use that pool as a client and have the library allocate a client for us.  redis, err := radix.NewPool(\"tcp\", \"localhost:6379\", 10)\nif err != nil {\n    fmt.Println(err)\n        return\n}",
            "title": "Creating a Redis Pooled Connection"
        },
        {
            "location": "/blog/golang/using-redisql-with-golang/#setting-up-the-database",
            "text": "In order to work with RediSQL is necessary to do a small setup. \nThe first step is always to create a database, then we create the tables inside the databases and finally the different statements if they are necessary.  It is always a good idea to use statements instead of building query by hand, but it is not mandatory. \nThe use of statements eliminate the risk of SQL injection and it is more performant, since the query is parsed only once and not every time it get executed.  In our case we create a simple database that we will call  HN .  r.Do(radix.Cmd(nil, \"REDISQL.CREATE_DB\", \"HN\"))  Then we create a single table  hn  inside the  HN  database.  table := \"CREATE TABLE IF NOT EXISTS hn(id integer primary key, author text, time int, item text);\"\nr.Do(radix.Cmd(nil, \"REDISQL.EXEC\", \"HN\", table))  The table will contains the  id  of each item we are getting from HN, along with the author of the item, when the item was posted and finally the last field will contains the whole item as a  json  string.  The last step is to create a statement to easily insert the data inside our table.  stmt := `INSERT INTO hn VALUES(\n    json_extract(json(?1),'$.id'), \n    json_extract(json(?1),'$.by'), \n    json_extract(json(?1),'$.time'), \n    json(?1));`\nr.Do(radix.Cmd(nil, \"REDISQL.CREATE_STATEMENT\", \"HN\", \"insert_item\", stmt))  The statement is a little complex. \nIt exploit the  JSON1  sqlite extension to extract the necessary fields from a JSON string. \nIn particular we extract the  id , the  by  (author) and the  time  fields.  After that those fields are extracted from the JSON string we store all of them into the database along with the whole item.",
            "title": "Setting up the database"
        },
        {
            "location": "/blog/golang/using-redisql-with-golang/#the-loop",
            "text": "After the database is ready to accept data, we start to poll the HN API in order to fetch the newest item. \nEach item is then pushed into the  itemIds  channel that is later consumed.  itemIds := make(chan int, 10)\n\ngo func() {\n    oldMaxItemId := getMaxItem()\n    for {\n        newMaxItemId := getMaxItem()\n        for ; oldMaxItemId < newMaxItemId; oldMaxItemId++ {\n            itemIds <- oldMaxItemId\n        }\n        time.Sleep(5 * time.Second)\n    }\n}()  The API provide an endpoint that show the biggest element in HN at the moment, it is a simple auto-incremental id that we can fetch using the  getMaxItem()  function implemented as:  func getMaxItem() int {\n    resp, _ := http.Get(\"https://hacker-news.firebaseio.com/v0/maxitem.json\")\n    defer resp.Body.Close()\n    body, _ := ioutil.ReadAll(resp.Body)\n    n, _ := strconv.Atoi(string(body))\n    return n\n}  Finally the main loop iterate through the  itemIds  channel.\nFor each new item we use again the HN API to get the content of the items and then we store it into RediSQL.  for itemId := range itemIds {\n    go func() {\n        item := getItem(itemId)\n        err := redis.Do(radix.Cmd(nil, \"REDISQL.EXEC_STATEMENT\", \"HN\", \"insert_item\", item))\n        if err != nil {\n            fmt.Println(err)\n        }\n    }()\n}  The  getitem()  functions implement a trivial error recovery strategy. \nIndeed, after some trial and error, was clear that, sometimes, the element  n  is not ready yet even if the element  n+1  was published as  maxitem  and the API returns the simple string \"null\", if that is the case we simply repeat the call.  func getItem(id int) string {\n    for {\n        url := fmt.Sprintf(\"https://hacker-news.firebaseio.com/v0/item/%d.json\", id)\n        resp, _ := http.Get(url)\n        defer resp.Body.Close()\n        body, _ := ioutil.ReadAll(resp.Body)\n        result := string(body)\n        if result != \"null\" {\n            return result\n        }\n    }\n}",
            "title": "The loop"
        },
        {
            "location": "/blog/golang/using-redisql-with-golang/#concluding",
            "text": "This small example (less than 80 lines) show how simple is to quickly get value from RediSQL.\nIndeed is sufficient to set up the database following always the same steps:   Create the database with  REDISQL.CREATE_DB $db_name  Create the schema inside your database  REDISQL.EXEC $db_name \"CREATE TABLE ... etc\"  and, if you want, the statements:  REDISSQL.CREATE_STATEMENT $db_name $statement_name \"INSERT INTO ... etc\"  Start inserting data, with or without a statement:  REDISQL.EXEC_STATEMENT  or simply  REDISQL.EXEC   Finally to query back the data is possible to use:   queries  REDISQL.QUERY $db_name \"SELECT * FROM ...\" ,  statements  REDISQL.CREATE_STATEMENT $db_name $query_name \"SELECT * FROM ... WHERE foo = ?1\"  and the  REDISQL.QUERY_STATEMENTS $db_name $query_name \"paramenters\"  simple exec  REDISQL.EXEC $db_name \"SELECT * FROM ... etc\"   Feel free to explore our  references documentation  to understand better what capabilities RediSQL provides you.  The complete code of this example is  available here.  If you wish to see a similar tutorial for a different language,  open an issue on github.",
            "title": "Concluding"
        },
        {
            "location": "/blog/node/using-redisql-with-node/",
            "text": "Using RediSQL with Node.js\n\n\nThis tutorial will help you to get start to use RediSQL with Node.js\n\n\nIn this tutorial we will scrape the content of Hacker News using their \nAPI documented here\n.\n\n\nTo communicate with Redis we will use the popular \nnode_redis\n library wich is the most suitable to communicate with Redis Modules and RediSQL. Other libraries can be used as well, but some more work will be necessary.\n\n\nTo follow this tutorial you will need a modern (> v4.0) instance of Redis running RediSQL.\nYou can obtain RediSQL from \nour shop\n or from the \ngithub releases\n.\n\n\nTo load RediSQL is sufficient to pass it as argument to the redis-server: \n./redis-server --loadmodule /path/to/redisql.so\n\n\nThe whole code show in this example is reachable \nhere.\n\n\nDependencies\n\n\nThe first step is always to load the dependencies, for this little script we will need just 3 dependencies:\n\n\n\n\nutil\n for formatting strings and promisify functions\n\n\naxios\n for making HTTP requests\n\n\nredis\n for actually talking with RediSQL\n\n\n\n\nconst util = require('util');\nconst axios = require('axios');\nconst redis = require('redis');\n\n\n\n\nConnect to Redis and make it asycn/await ready.\n\n\nRediSQL works on a normal Redis instance, hence we need to create a connection to our Redis.\n\n\nIn this tutorial we are going to use the async/await syntax that is not natively supported by \nnode_redis\n but that it can easily added using \npromisify\n.\n\n\nWe first create a new connection to Redis, just one that is enough, and then we promisify the \nsend_command\n method in order to give us the nice async/await syntax.\n\n\nconst client = redis.createClient();\nconst send_command = util.promisify(client.send_command).bind(client); \n\n\n\n\nPolling HN API to get the newest items\n\n\nThe API of HN provides an endpoint to retrieve the ID of the latest element added to the website.\nThe ID are auto-incremental, hence if the ID = \nn\n exists, it means that also the ID = \nn - 1\n exists as well.\n\n\nHowever is necessary a little of cautions, indeed, is possible that some items are not yet available if they exists, in such case they return the string \nnull\n instead of a JSON object.\nWe take care of this with a simple loop and an \nif\n.\n\n\nconst getMaxItem = async () => {\n        let response = await axios.get(\"https://hacker-news.firebaseio.com/v0/maxitem.json\");\n        return response.data;\n};\n\nconst getItem = async id => {\n        let url = util.format(\"https://hacker-news.firebaseio.com/v0/item/%s.json\", id);\n        while (true) {\n                let response = await axios.get(url);\n                let data = response.data;\n                if (data != \"null\") {\n                        return data;\n                }\n        }\n};\n\n\n\n\nThe RediSQL structure\n\n\nNow that we have removed all the boilerplate let's get down to business. We need to:\n\n\n\n\nCreate our database in RediSQL using the \nREDISQL.CREATE_DB\n command.\n\n\nCreate the table that will contains our data using the \nREDISQL.EXEC\n command.\n\n\nCreate the statement to actually insert the data into the database using the \nREDISQL.CREATE_STATEMENT\n command. \n\n\n\n\nWe will store in our table the \nid\n of the item we are adding, the author of the item, when the item was posted on HN and finally the whole item as a JSON structure.\n\n\nThe third step is not strictly needed, but it provide defense against SQL-injections, is more performant, and it is just a cleaner way to do it. \nThe alternative would be to just use \nREDISQL.EXEC\n every time we want to add a new row to the database.\n\n\nAll those steps are done in the \nsetUp\n functions.\n\n\nconst setUp = async () => {\n        await send_command(\"REDISQL.CREATE_DB\", [\"HN\"]).catch( err => console.log(err) );\n        table = \"CREATE TABLE IF NOT EXISTS hn(id integer primary key, author text, time int, item text);\"\n        await send_command(\"REDISQL.EXEC\", ['HN', table]).catch( err => console.log(err) );\n        stmt = \"INSERT INTO hn VALUES(\" + \n        \"json_extract(json(?1),'$.id'),\" +\n        \"json_extract(json(?1),'$.by'),\" +\n        \"json_extract(json(?1),'$.time'),\" +\n        \"json(?1));\";\n        await send_command(\"REDISQL.CREATE_STATEMENT\", ['HN', 'insert_item', stmt])\n                .catch( err => console.log(err) );\n};\n\n\n\n\nNote how nicely the \nJSON1\n modules help us. \nIt extracts for us the \nid\n of the item we want to add, the author of the item (the \nby\n field) and the time when the item was created.\nWithout it we would be force to do that operation ourselves and pass more parameters to the statement.\n\n\nInsert data into the database\n\n\nFinally let's make a simple function that will gets an item from HN and stores it into our database executing the statement we just created.\n\n\nconst storeItem = async id => {\n        let item = await getItem(id);\n        console.log(item);\n        await send_command(\"REDISQL.EXEC_STATEMENT\", ['HN', 'insert_item', JSON.stringify(item)])\n                .catch( err => console.log(err) );\n}\n\n\n\n\nRunning it\n\n\nNow that we have all our piece in order we can just combine them together.\n\n\nWe will start by creating the database, table and statements.\n\n\nThen a simple infinite loop will simply keep pooling the API.\nAs soon as it detects new items available, it download them, and store those into the database.\n\n\nWe also include a small throttling mechanism to avoid hammering the API, which is not needed using the \nsleep\n function.\n\n\nconst sleep = (waitTimeInMs) => new Promise(resolve => setTimeout(resolve, waitTimeInMs));\n\n(async () => {\n        setUp();\n        let maxItem = await getMaxItem();\n        while (true) {\n                let newMaxItem = await getMaxItem();\n                for (; maxItem < newMaxItem; maxItem += 1) {\n                        storeItem(maxItem);\n                }\n                await sleep(5 * 1000);\n        }\n})()\n\n\n\n\nConcluding\n\n\nIn this small example (less than 60 lines) we show how simple and easy is to get started with RediSQL. We just set up the database and table once, along with the statement and that's it.\nA much quicker set up, especially for testing, than using classical databases as \nPostgres\n or \nMySQL\n.\n\n\nIndeed is sufficient to set up the database following always the same steps:\n\n\n\n\nCreate the database with \nREDISQL.CREATE_DB $db_name\n\n\nCreate the schema inside your database \nREDISQL.EXEC $db_name \"CREATE TABLE ... etc\"\n and, if you want, the statements: \nREDISSQL.CREATE_STATEMENT $db_name $statement_name \"INSERT INTO ... etc\"\n\n\nStart inserting data, with or without a statement: \nREDISQL.EXEC_STATEMENT\n or simply \nREDISQL.EXEC\n\n\n\n\nFinally to query back the data is possible to use:\n\n\n\n\nqueries \nREDISQL.QUERY $db_name \"SELECT * FROM ...\"\n,\n\n\nstatements \nREDISQL.CREATE_STATEMENT $db_name $query_name \"SELECT * FROM ... WHERE foo = ?1\"\n and the \nREDISQL.QUERY_STATEMENTS $db_name $query_name \"paramenters\"\n\n\nsimple exec \nREDISQL.EXEC $db_name \"SELECT * FROM ... etc\"\n\n\n\n\nFeel free to explore our \nreferences documentation\n to understand better what capabilities RediSQL provides you.\n\n\nThe complete code of this example is \navailable here.\n\n\nIf you wish to see a similar tutorial for a different language, \nopen an issue on github.",
            "title": "Using RediSQL with Node.js"
        },
        {
            "location": "/blog/node/using-redisql-with-node/#using-redisql-with-nodejs",
            "text": "This tutorial will help you to get start to use RediSQL with Node.js  In this tutorial we will scrape the content of Hacker News using their  API documented here .  To communicate with Redis we will use the popular  node_redis  library wich is the most suitable to communicate with Redis Modules and RediSQL. Other libraries can be used as well, but some more work will be necessary.  To follow this tutorial you will need a modern (> v4.0) instance of Redis running RediSQL.\nYou can obtain RediSQL from  our shop  or from the  github releases .  To load RediSQL is sufficient to pass it as argument to the redis-server:  ./redis-server --loadmodule /path/to/redisql.so  The whole code show in this example is reachable  here.",
            "title": "Using RediSQL with Node.js"
        },
        {
            "location": "/blog/node/using-redisql-with-node/#dependencies",
            "text": "The first step is always to load the dependencies, for this little script we will need just 3 dependencies:   util  for formatting strings and promisify functions  axios  for making HTTP requests  redis  for actually talking with RediSQL   const util = require('util');\nconst axios = require('axios');\nconst redis = require('redis');",
            "title": "Dependencies"
        },
        {
            "location": "/blog/node/using-redisql-with-node/#connect-to-redis-and-make-it-asycnawait-ready",
            "text": "RediSQL works on a normal Redis instance, hence we need to create a connection to our Redis.  In this tutorial we are going to use the async/await syntax that is not natively supported by  node_redis  but that it can easily added using  promisify .  We first create a new connection to Redis, just one that is enough, and then we promisify the  send_command  method in order to give us the nice async/await syntax.  const client = redis.createClient();\nconst send_command = util.promisify(client.send_command).bind(client);",
            "title": "Connect to Redis and make it asycn/await ready."
        },
        {
            "location": "/blog/node/using-redisql-with-node/#polling-hn-api-to-get-the-newest-items",
            "text": "The API of HN provides an endpoint to retrieve the ID of the latest element added to the website.\nThe ID are auto-incremental, hence if the ID =  n  exists, it means that also the ID =  n - 1  exists as well.  However is necessary a little of cautions, indeed, is possible that some items are not yet available if they exists, in such case they return the string  null  instead of a JSON object.\nWe take care of this with a simple loop and an  if .  const getMaxItem = async () => {\n        let response = await axios.get(\"https://hacker-news.firebaseio.com/v0/maxitem.json\");\n        return response.data;\n};\n\nconst getItem = async id => {\n        let url = util.format(\"https://hacker-news.firebaseio.com/v0/item/%s.json\", id);\n        while (true) {\n                let response = await axios.get(url);\n                let data = response.data;\n                if (data != \"null\") {\n                        return data;\n                }\n        }\n};",
            "title": "Polling HN API to get the newest items"
        },
        {
            "location": "/blog/node/using-redisql-with-node/#the-redisql-structure",
            "text": "Now that we have removed all the boilerplate let's get down to business. We need to:   Create our database in RediSQL using the  REDISQL.CREATE_DB  command.  Create the table that will contains our data using the  REDISQL.EXEC  command.  Create the statement to actually insert the data into the database using the  REDISQL.CREATE_STATEMENT  command.    We will store in our table the  id  of the item we are adding, the author of the item, when the item was posted on HN and finally the whole item as a JSON structure.  The third step is not strictly needed, but it provide defense against SQL-injections, is more performant, and it is just a cleaner way to do it. \nThe alternative would be to just use  REDISQL.EXEC  every time we want to add a new row to the database.  All those steps are done in the  setUp  functions.  const setUp = async () => {\n        await send_command(\"REDISQL.CREATE_DB\", [\"HN\"]).catch( err => console.log(err) );\n        table = \"CREATE TABLE IF NOT EXISTS hn(id integer primary key, author text, time int, item text);\"\n        await send_command(\"REDISQL.EXEC\", ['HN', table]).catch( err => console.log(err) );\n        stmt = \"INSERT INTO hn VALUES(\" + \n        \"json_extract(json(?1),'$.id'),\" +\n        \"json_extract(json(?1),'$.by'),\" +\n        \"json_extract(json(?1),'$.time'),\" +\n        \"json(?1));\";\n        await send_command(\"REDISQL.CREATE_STATEMENT\", ['HN', 'insert_item', stmt])\n                .catch( err => console.log(err) );\n};  Note how nicely the  JSON1  modules help us. \nIt extracts for us the  id  of the item we want to add, the author of the item (the  by  field) and the time when the item was created.\nWithout it we would be force to do that operation ourselves and pass more parameters to the statement.",
            "title": "The RediSQL structure"
        },
        {
            "location": "/blog/node/using-redisql-with-node/#insert-data-into-the-database",
            "text": "Finally let's make a simple function that will gets an item from HN and stores it into our database executing the statement we just created.  const storeItem = async id => {\n        let item = await getItem(id);\n        console.log(item);\n        await send_command(\"REDISQL.EXEC_STATEMENT\", ['HN', 'insert_item', JSON.stringify(item)])\n                .catch( err => console.log(err) );\n}",
            "title": "Insert data into the database"
        },
        {
            "location": "/blog/node/using-redisql-with-node/#running-it",
            "text": "Now that we have all our piece in order we can just combine them together.  We will start by creating the database, table and statements.  Then a simple infinite loop will simply keep pooling the API.\nAs soon as it detects new items available, it download them, and store those into the database.  We also include a small throttling mechanism to avoid hammering the API, which is not needed using the  sleep  function.  const sleep = (waitTimeInMs) => new Promise(resolve => setTimeout(resolve, waitTimeInMs));\n\n(async () => {\n        setUp();\n        let maxItem = await getMaxItem();\n        while (true) {\n                let newMaxItem = await getMaxItem();\n                for (; maxItem < newMaxItem; maxItem += 1) {\n                        storeItem(maxItem);\n                }\n                await sleep(5 * 1000);\n        }\n})()",
            "title": "Running it"
        },
        {
            "location": "/blog/node/using-redisql-with-node/#concluding",
            "text": "In this small example (less than 60 lines) we show how simple and easy is to get started with RediSQL. We just set up the database and table once, along with the statement and that's it.\nA much quicker set up, especially for testing, than using classical databases as  Postgres  or  MySQL .  Indeed is sufficient to set up the database following always the same steps:   Create the database with  REDISQL.CREATE_DB $db_name  Create the schema inside your database  REDISQL.EXEC $db_name \"CREATE TABLE ... etc\"  and, if you want, the statements:  REDISSQL.CREATE_STATEMENT $db_name $statement_name \"INSERT INTO ... etc\"  Start inserting data, with or without a statement:  REDISQL.EXEC_STATEMENT  or simply  REDISQL.EXEC   Finally to query back the data is possible to use:   queries  REDISQL.QUERY $db_name \"SELECT * FROM ...\" ,  statements  REDISQL.CREATE_STATEMENT $db_name $query_name \"SELECT * FROM ... WHERE foo = ?1\"  and the  REDISQL.QUERY_STATEMENTS $db_name $query_name \"paramenters\"  simple exec  REDISQL.EXEC $db_name \"SELECT * FROM ... etc\"   Feel free to explore our  references documentation  to understand better what capabilities RediSQL provides you.  The complete code of this example is  available here.  If you wish to see a similar tutorial for a different language,  open an issue on github.",
            "title": "Concluding"
        },
        {
            "location": "/blog/hierarchical_json/",
            "text": "Hierarchical JSON and RediSQL\n\n\nRediSQL is compiled including the \nJSON1\n SQLite extensions. Hence, all the functions documented in \nJSON1\n are available out of the box.\n\n\nJSON1 is extremely flexible and powerful, as an example consider a report table that track sales in a company  by year, quarter and week.\n\n\n> REDISQL.CREATE_DB DB\n> REDISQL.EXEC DB \"CREATE TABLE sales(year STRING, quarter STRING, week STRING, total INT);\"\n> REDISQL.EXEC DB \"INSERT INTO sales VALUES('2019', 'q1', '1', 100);\"\n> REDISQL.EXEC DB \"INSERT INTO sales VALUES('2019', 'q1', '2', 125);\"\n> REDISQL.EXEC DB \"INSERT INTO sales VALUES('2019', 'q2', '1', 200);\" \n> REDISQL.EXEC DB \"INSERT INTO sales VALUES('2019', 'q2', '2', 300);\" \n> REDISQL.EXEC DB \"INSERT INTO sales VALUES('2020', 'q1', '1', 400);\" \n> REDISQL.EXEC DB \"INSERT INTO sales VALUES('2020', 'q1', '2', 450);\" \n> REDISQL.EXEC DB \"INSERT INTO sales VALUES('2020', 'q2', '1', 500);\" \n\n\n\n\nFrom this table we would like to generate a JSON report in the form:\n\n\n{'2019': \n  {'q1': {'1': 100, '2': 125}, \n   'q2': {'1': 200, '2': 300}}, \n '2020': \n  {'q1': {'1': 400, '2': 450}, \n   'q2': {'1': 500}}}\n\n\n\n\nThis is not a trivial problem, because SQL generally does not like to return data in this format, just a string. However the JSON1 module is flexible enough and CTE provide us with enough expressing power.\n\n\nLet's see the final query first and then we will try to understand it piece by piece.\n\n\nWITH quarters AS (\n  WITH weeks AS (\n      SELECT year, quarter, json_group_object(week, total) AS week_json \n      FROM sales \n      GROUP BY year, quarter\n      ) \n  SELECT year, json_group_object(quarter, json(week_json)) AS quarters_json \n  FROM weeks \n  GROUP BY year\n) \nSELECT json_group_object(year, json(quarters_json)) \nFROM quarters;\"\n\n\n\n\nThis returns exactly the single line we are looking for. \n\n\nIt seems a difficult query, but working on it piece by piece we can understand it quickly.\n\n\nThe \nWITH\n constructor simply create a \"virtual table\" valid for the execution of the query.\n\n\nThe simplest way to understand this query is going inside-out.\n\n\nSELECT year, quarter, json_group_object(week, total) AS week_json \nFROM sales \nGROUP BY year, quarter\n\n\n\n\njson_group_object\n is an aggreate query and it returns a JSON string with the \nweek\ns as key and the \ntotal\ns as values.\n\n\n> REDISQL.EXEC DB \"SELECT year, quarter, json_group_object(week, total) AS week_json FROM sales GROUP BY year, quarter\" \n1) 1) (integer) 2019\n   2) \"q1\"\n   3) \"{\\\"1\\\":100,\\\"2\\\":125}\"\n2) 1) (integer) 2019\n   2) \"q2\"\n   3) \"{\\\"1\\\":200,\\\"2\\\":300}\"\n3) 1) (integer) 2020\n   2) \"q1\"\n   3) \"{\\\"1\\\":400,\\\"2\\\":450}\"\n4) 1) (integer) 2020\n   2) \"q2\"\n   3) \"{\\\"1\\\":500}\"\n\n\n\n\nIn this way we are able to create a JSON document that express the total of sales for each week. We compres the week columns in a flat JSON document.\n\n\nThe next step is similar, for the year, we compress each quarter in a JSON document, the difficulties lays in maintaining the total of the weeks.\n\n\nWITH weeks AS (\n    --- same query as above\n    SELECT year, quarter, json_group_object(week, total) AS week_json \n    FROM sales \n    GROUP BY year, quarter\n) \n  SELECT year, json_group_object(quarter, json(week_json)) AS quarters_json \n  FROM weeks \n  GROUP BY year\n\n\n\n\nWe introduce the \nWITH\n statement. \nUsing the \nWITH\n statement we treat the result of the query above as a new table that we can use in the later statement, the new table is called \nweek\n.\nNote how we conveniently associate a name (\nweek_json\n) to the result of the \njson_group_object\n aggregation. This is useful to manipulate that JSON object.\n\n\nThe rest of the query is very similar, we are compressing all the quarters into a flat JSON object.\n\n\n> REDISQL.EXEC DB \"WITH weeks AS ( SELECT year, quarter, json_group_object(week, total) AS week_json FROM sales GROUP BY year, quarter) SELECT year, json_group_object(quarter, json(week_json)) AS quarters_json FROM weeks GROUP BY year\"\n1) 1) (integer) 2019\n   2) \"{\\\"q1\\\":{\\\"1\\\":100,\\\"2\\\":125},\\\"q2\\\":{\\\"1\\\":200,\\\"2\\\":300}}\"\n2) 1) (integer) 2020\n   2) \"{\\\"q1\\\":{\\\"1\\\":400,\\\"2\\\":450},\\\"q2\\\":{\\\"1\\\":500}}\"\n\n\n\n\nThis query provided us, for each year, a JSON hierarchical structure that map quarters and weeks tp total sales.\n\n\nNow, we can guess the last step, compress the years into another hierarchical JSON structure.\n\n\nThis yield to the original query:\n\n\nWITH quarters AS (\n  --- same query as above\n  WITH weeks AS (\n      SELECT year, quarter, json_group_object(week, total) AS week_json \n      FROM sales \n      GROUP BY year, quarter\n      ) \n  SELECT year, json_group_object(quarter, json(week_json)) AS quarters_json \n  FROM weeks \n  GROUP BY year\n) \nSELECT json_group_object(year, json(quarters_json)) \nFROM quarters;\"\n\n\n\n\nAnd let's see the result:\n\n\n> REDISQL.EXEC DB \"WITH quarters AS ( WITH weeks AS ( SELECT year, quarter, json_group_object(week, total) AS week_json FROM sales GROUP BY year, quarter ) SELECT year, json_group_object(quarter, json(week_json)) AS quarters_json FROM weeks GROUP BY year) SELECT json_group_object(year, json(quarters_json)) FROM quarters;\"\n\n1) 1) \"{\\\"2019\\\":{\\\"q1\\\":{\\\"1\\\":100,\\\"2\\\":125},\\\"q2\\\":{\\\"1\\\":200,\\\"2\\\":300}},\\\"2020\\\":{\\\"q1\\\":{\\\"1\\\":400,\\\"2\\\":450},\\\"q2\\\":{\\\"1\\\":500}}}\"\n\n\n\n\nThe last result is a hierarchical JSON structure where the years map to the quartes, the quarters map to the weeks and the weeks map to the sales.",
            "title": "Hierarchical JSON with SQLite/RediSQL"
        },
        {
            "location": "/blog/hierarchical_json/#hierarchical-json-and-redisql",
            "text": "RediSQL is compiled including the  JSON1  SQLite extensions. Hence, all the functions documented in  JSON1  are available out of the box.  JSON1 is extremely flexible and powerful, as an example consider a report table that track sales in a company  by year, quarter and week.  > REDISQL.CREATE_DB DB\n> REDISQL.EXEC DB \"CREATE TABLE sales(year STRING, quarter STRING, week STRING, total INT);\"\n> REDISQL.EXEC DB \"INSERT INTO sales VALUES('2019', 'q1', '1', 100);\"\n> REDISQL.EXEC DB \"INSERT INTO sales VALUES('2019', 'q1', '2', 125);\"\n> REDISQL.EXEC DB \"INSERT INTO sales VALUES('2019', 'q2', '1', 200);\" \n> REDISQL.EXEC DB \"INSERT INTO sales VALUES('2019', 'q2', '2', 300);\" \n> REDISQL.EXEC DB \"INSERT INTO sales VALUES('2020', 'q1', '1', 400);\" \n> REDISQL.EXEC DB \"INSERT INTO sales VALUES('2020', 'q1', '2', 450);\" \n> REDISQL.EXEC DB \"INSERT INTO sales VALUES('2020', 'q2', '1', 500);\"   From this table we would like to generate a JSON report in the form:  {'2019': \n  {'q1': {'1': 100, '2': 125}, \n   'q2': {'1': 200, '2': 300}}, \n '2020': \n  {'q1': {'1': 400, '2': 450}, \n   'q2': {'1': 500}}}  This is not a trivial problem, because SQL generally does not like to return data in this format, just a string. However the JSON1 module is flexible enough and CTE provide us with enough expressing power.  Let's see the final query first and then we will try to understand it piece by piece.  WITH quarters AS (\n  WITH weeks AS (\n      SELECT year, quarter, json_group_object(week, total) AS week_json \n      FROM sales \n      GROUP BY year, quarter\n      ) \n  SELECT year, json_group_object(quarter, json(week_json)) AS quarters_json \n  FROM weeks \n  GROUP BY year\n) \nSELECT json_group_object(year, json(quarters_json)) \nFROM quarters;\"  This returns exactly the single line we are looking for.   It seems a difficult query, but working on it piece by piece we can understand it quickly.  The  WITH  constructor simply create a \"virtual table\" valid for the execution of the query.  The simplest way to understand this query is going inside-out.  SELECT year, quarter, json_group_object(week, total) AS week_json \nFROM sales \nGROUP BY year, quarter  json_group_object  is an aggreate query and it returns a JSON string with the  week s as key and the  total s as values.  > REDISQL.EXEC DB \"SELECT year, quarter, json_group_object(week, total) AS week_json FROM sales GROUP BY year, quarter\" \n1) 1) (integer) 2019\n   2) \"q1\"\n   3) \"{\\\"1\\\":100,\\\"2\\\":125}\"\n2) 1) (integer) 2019\n   2) \"q2\"\n   3) \"{\\\"1\\\":200,\\\"2\\\":300}\"\n3) 1) (integer) 2020\n   2) \"q1\"\n   3) \"{\\\"1\\\":400,\\\"2\\\":450}\"\n4) 1) (integer) 2020\n   2) \"q2\"\n   3) \"{\\\"1\\\":500}\"  In this way we are able to create a JSON document that express the total of sales for each week. We compres the week columns in a flat JSON document.  The next step is similar, for the year, we compress each quarter in a JSON document, the difficulties lays in maintaining the total of the weeks.  WITH weeks AS (\n    --- same query as above\n    SELECT year, quarter, json_group_object(week, total) AS week_json \n    FROM sales \n    GROUP BY year, quarter\n) \n  SELECT year, json_group_object(quarter, json(week_json)) AS quarters_json \n  FROM weeks \n  GROUP BY year  We introduce the  WITH  statement. \nUsing the  WITH  statement we treat the result of the query above as a new table that we can use in the later statement, the new table is called  week .\nNote how we conveniently associate a name ( week_json ) to the result of the  json_group_object  aggregation. This is useful to manipulate that JSON object.  The rest of the query is very similar, we are compressing all the quarters into a flat JSON object.  > REDISQL.EXEC DB \"WITH weeks AS ( SELECT year, quarter, json_group_object(week, total) AS week_json FROM sales GROUP BY year, quarter) SELECT year, json_group_object(quarter, json(week_json)) AS quarters_json FROM weeks GROUP BY year\"\n1) 1) (integer) 2019\n   2) \"{\\\"q1\\\":{\\\"1\\\":100,\\\"2\\\":125},\\\"q2\\\":{\\\"1\\\":200,\\\"2\\\":300}}\"\n2) 1) (integer) 2020\n   2) \"{\\\"q1\\\":{\\\"1\\\":400,\\\"2\\\":450},\\\"q2\\\":{\\\"1\\\":500}}\"  This query provided us, for each year, a JSON hierarchical structure that map quarters and weeks tp total sales.  Now, we can guess the last step, compress the years into another hierarchical JSON structure.  This yield to the original query:  WITH quarters AS (\n  --- same query as above\n  WITH weeks AS (\n      SELECT year, quarter, json_group_object(week, total) AS week_json \n      FROM sales \n      GROUP BY year, quarter\n      ) \n  SELECT year, json_group_object(quarter, json(week_json)) AS quarters_json \n  FROM weeks \n  GROUP BY year\n) \nSELECT json_group_object(year, json(quarters_json)) \nFROM quarters;\"  And let's see the result:  > REDISQL.EXEC DB \"WITH quarters AS ( WITH weeks AS ( SELECT year, quarter, json_group_object(week, total) AS week_json FROM sales GROUP BY year, quarter ) SELECT year, json_group_object(quarter, json(week_json)) AS quarters_json FROM weeks GROUP BY year) SELECT json_group_object(year, json(quarters_json)) FROM quarters;\"\n\n1) 1) \"{\\\"2019\\\":{\\\"q1\\\":{\\\"1\\\":100,\\\"2\\\":125},\\\"q2\\\":{\\\"1\\\":200,\\\"2\\\":300}},\\\"2020\\\":{\\\"q1\\\":{\\\"1\\\":400,\\\"2\\\":450},\\\"q2\\\":{\\\"1\\\":500}}}\"  The last result is a hierarchical JSON structure where the years map to the quartes, the quarters map to the weeks and the weeks map to the sales.",
            "title": "Hierarchical JSON and RediSQL"
        },
        {
            "location": "/faqs/",
            "text": "FAQs\n\n\nCommon answer and mistake quickly solved\n\n\nERR - Error the key is empty\n\n\nYou try to execute a command against a database like\n\n\nREDISQL.EXEC DB-EXAMPLE \"SELECT 1;\"\n\n\n\n\nand RediSQL returns the error: \nERR - Error the key is empty\n.\n\n\nMost likely the dabatase \nDB-EXAMPLE\n does not exists. To fix the problem you can simply create first the database with\n\n\nREDISQL.CREATE_DB DB-EXAMPLE\n\n\n\n\nDuring development is quite convenient to just delete everything from RediSQL, so it may happens that you encounter this error.\nA possible solution is to always invoke the \nREDISQL.CREATE_DB\n command, if the database is not there, it will be created, if the database is already there an error will be raise. As long as you are in a development environment just ignore the error.\n\n\nREADONLY You can't write against a read only replica.\n\n\nRedis and RediSQL supports \nreplication\n. You can have the same database in different redis instance, on different processes and potentially on different machine.\nThis means that you can read data from different instances in parallel, greatly improving reading performances.\nHowever you cannot write in parallel to different instances, otherwise we wouldn't know what data is \"real\". You can write only to the master instance.\n\n\nBy policy the \nREDISQL.EXEC\n command allow you to read and write and (due to Redis limitation) you cannot use this command on replicas. The \nREDISQL.EXEC\n command works only on the master node. This is true even if the query that you are trying to execute is an very simple read only query like \nSELECT 1;\n, you cannot \nREDISQL.EXEC\n against a replica node.\n\n\nIn order to read from the replicas, you can use the \nREDISQL.QUERY\n family of commands. This command is allowed to only read data, without modifying the database, hence you can use it also in the replica instances. Moreover it is a good idea to use it also against the master instance whenever is possible.\n\n\nIf you try to execute the \nREDISQL.EXEC\n command against a replica you will get the error \nREADONLY You can't write against a read only replica\n. To query the replicas use the \nREDISQL.QUERY\n command.",
            "title": "FAQs"
        },
        {
            "location": "/faqs/#faqs",
            "text": "",
            "title": "FAQs"
        },
        {
            "location": "/faqs/#common-answer-and-mistake-quickly-solved",
            "text": "ERR - Error the key is empty  You try to execute a command against a database like  REDISQL.EXEC DB-EXAMPLE \"SELECT 1;\"  and RediSQL returns the error:  ERR - Error the key is empty .  Most likely the dabatase  DB-EXAMPLE  does not exists. To fix the problem you can simply create first the database with  REDISQL.CREATE_DB DB-EXAMPLE  During development is quite convenient to just delete everything from RediSQL, so it may happens that you encounter this error.\nA possible solution is to always invoke the  REDISQL.CREATE_DB  command, if the database is not there, it will be created, if the database is already there an error will be raise. As long as you are in a development environment just ignore the error.  READONLY You can't write against a read only replica.  Redis and RediSQL supports  replication . You can have the same database in different redis instance, on different processes and potentially on different machine.\nThis means that you can read data from different instances in parallel, greatly improving reading performances.\nHowever you cannot write in parallel to different instances, otherwise we wouldn't know what data is \"real\". You can write only to the master instance.  By policy the  REDISQL.EXEC  command allow you to read and write and (due to Redis limitation) you cannot use this command on replicas. The  REDISQL.EXEC  command works only on the master node. This is true even if the query that you are trying to execute is an very simple read only query like  SELECT 1; , you cannot  REDISQL.EXEC  against a replica node.  In order to read from the replicas, you can use the  REDISQL.QUERY  family of commands. This command is allowed to only read data, without modifying the database, hence you can use it also in the replica instances. Moreover it is a good idea to use it also against the master instance whenever is possible.  If you try to execute the  REDISQL.EXEC  command against a replica you will get the error  READONLY You can't write against a read only replica . To query the replicas use the  REDISQL.QUERY  command.",
            "title": "Common answer and mistake quickly solved"
        }
    ]
}